\documentclass[justified, sixbynine]{tufte-book}

%
% TODO:
% - add imlementation of fit() and .predict()
% - add event loop example
% - add sparse matrix example
% - rewrite Matrix
% - dimensional analysis

\title{\LARGE Annotated Algorithms in Python$_3$}
\subtitle{with applications in Physics, Biology, Finance (2nd Ed.)}

\author{Massimo Di Pierro}
\publisher{Experts4Solutions}

% For nicely typeset tabular material
\usepackage{color}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amsthm}
\usepackage{booktabs}
\usepackage{graphicx}
\usepackage{makeidx}
\usepackage{tocloft}
\usepackage{parskip}
\usepackage{upquote}
\usepackage{verbatim}
\usepackage{listings}
\usepackage{url}
\usepackage[utf8x]{inputenc}

\sloppy
\makeindex

\def\stackunder#1#2{\mathrel{\mathop{#2}\limits_{#1}}}
\definecolor{lg}{rgb}{0.9, 0.9, 0.9}
\definecolor{dg}{rgb}{0.3, 0.3, 0.3}
\def\ft{\small\tt}
\def\func{\textrm}
\def\subsubsection#1{{\bf #1}}

\theoremstyle{plain}% default
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemmma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem * {corollary}{Corollary}
\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]
\newtheorem{conjecture}{Conjecture}[section]
\newtheorem{example}{Example}[section]
\theoremstyle{remark}
\newtheorem * {remark}{Remark}
\newtheorem * {note}{Note}
\newtheorem{case}{Case}

\lstset{language=Python, 
   breaklines=true, basicstyle=\ttfamily\color{black}\footnotesize, 
   keywordstyle=\bf\ttfamily, 
   commentstyle=\it\ttfamily, 
   stringstyle=\color{dg}\it\ttfamily, 
   numbers=left, numberstyle=\color{dg}\tiny, stepnumber=1, numbersep=5pt, 
   % frame=lr, 
   backgroundcolor=\color{lg}, 
   tabsize=4, showspaces=false, 
   showstringspaces=false, 
   aboveskip=6pt, 
   belowskip=-3pt
}

% Disable Tufte-style captions for ctables
\makeatletter % allows @ in macro names
\def\@ctblCaption{
   \ifx\@ctblcap\undefined\let\@ctblcap\@ctblcaption\fi
   \ifx\@ctblcaption\empty\else
      \gdef\@ctblcaptionarg{\ifx\@ctbllabel\empty\else\label{\@ctbllabel}\fi
         \@ctblcaption\ \@ctblcontinued\strut}
      \ifx\@ctblcap\empty
         \caption[]{\@ctblcaptionarg}
      \else
         \caption[\@ctblcap]{\@ctblcaptionarg}
      \fi
   \fi
}
\makeatother % restores original meaning of @

\setcounter{secnumdepth}{4}
\setcounter{tocdepth}{4}
% Generates the index
\begin{document}

\frontmatter

\maketitle

\thispagestyle{empty}
\setlength{\parindent}{0pt}
\setlength{\parskip}{2mm}
{\footnotesize
\vskip 1in
Copyright 2013 by Massimo Di Pierro. All rights reserved.
\vskip 1cm

THE CONTENT OF THIS BOOK IS PROVIDED UNDER THE TERMS OF THE CREATIVE COMMONS PUBLIC LICENSE BY-NC-ND 3.0.

\url{http://creativecommons.org/licenses/by-nc-nd/3.0/legalcode}

THE WORK IS PROTECTED BY COPYRIGHT AND/OR OTHER APPLICABLE LAW. ANY USE OF THE WORK OTHER THAN AS AUTHORIZED UNDER THIS LICENSE OR COPYRIGHT LAW IS PROHIBITED.

BY EXERCISING ANY RIGHTS TO THE WORK PROVIDED HERE, YOU ACCEPT AND AGREE TO BE BOUND BY THE TERMS OF THIS LICENSE. TO THE EXTENT THIS LICENSE MAY BE CONSIDERED TO BE A CONTRACT, THE LICENSOR GRANTS YOU THE RIGHTS CONTAINED HERE IN CONSIDERATION OF YOUR ACCEPTANCE OF SUCH TERMS AND CONDITIONS.

Limit of Liability/Disclaimer of Warranty: While the publisher and
author have used their best efforts in preparing this book, they
make no representations or warranties with respect to the accuracy
or completeness of the contents of this book and specifically
disclaim any implied warranties of merchantability or fitness for a
particular purpose.  No warranty may be created or extended by
sales representatives or written sales materials.
The advice and strategies contained herein may not be
suitable for your situation. You should consult with a professional
where appropriate.  Neither the publisher nor the author shall be liable
for any loss of profit or any other commercial damages, including
but not limited to special, incidental, consequential, or other damages. \\ \\

For more information about appropriate use of this material, contact:

\begin{verbatim}
Massimo Di Pierro
School of Computing
DePaul University
243 S Wabash Ave
Chicago, IL 60604 (USA)
Email: massimo.dipierro@gmail.com
\end{verbatim}

Library of Congress Cataloging-in-Publication Data: \\ \\
ISBN: 978-0-9911604-0-2 \\
Build Date: \today
}


\newpage
%\begin{center}
%\noindent\fontsize{12}{18}\selectfont\itshape
%\nohyphenation
\thispagestyle{empty}
\phantom{placeholder}
\vspace{2in}
\hskip 2in
{\it to my son}
%\end{center}
\newpage
\thispagestyle{empty}
\phantom {a}
\newpage

\setlength{\cftparskip}{\baselineskip}
\tableofcontents

\mainmatter
\begin{fullwidth}

\goodbreak\chapter{Introduction}

This book is assembled from lectures given by the author over a period of 10 years at the School of Computing of DePaul University. The lectures cover multiple classes, including Analysis and Design of Algorithms, Scientific Computing, Monte Carlo Simulations, and Parallel Algorithms. These lectures teach the core knowledge required by any scientist interested in numerical algorithms and by students interested in computational finance.

The notes are not comprehensive, yet they try to identify and describe the most important concepts taught in those courses using a few common tools and unified notation.

In particular, these notes do not include proofs; instead, they provide definitions and annotated code. The code is built in a modular way and is reused as much as possible throughout the book so that no step of the computations is left to the imagination. Each function defined in the code is accompanied by one or more examples of practical applications.

We take an interdisciplinary approach by providing examples in finance, physics, biology, and computer science. This is to emphasize that, although we often compartmentalize knowledge, there are very few ideas and methodologies that constitute the foundations of them all. Ultimately, this book is about problem solving using computers. The algorithms you will learn can be applied to different disciplines. Throughout history, it is not uncommon that an algorithm invented by a physicist would find application in, for example, biology or finance.

Almost all of the algorithms written in this book can be found in the {\ft nlib} github repository:

\url{https://github.com/mdipierro/nlib}

\section{Main Ideas}

Even if we cover many different algorithms and examples, there are a few central ideas in this book that we try to emphasize over and over.

The first idea is that we can simplify the solution of a problem by using an approximation and then systematically improve our approximation by iterating and computing corrections.

The divide-and-conquer methodology can be seen as an example of this approach. We do this with the insertion sort when we sort the first two numbers, then we sort the first three, then we sort the first four, and so on. We do it with merge sort when we sort each set of two numbers, then each set of four, then each set of eight, and so on. We do it with the Prim, Kruskal, and Dijkstra algorithms when we iterate over the nodes of a graph, and as we acquire knowledge about them, we use it to update the information about the shortest paths.

We use this approach in almost all our numerical algorithms because any differentiable function can be approximated with a linear function:
\begin{equation}
f(x+\delta x) \simeq f(x) + f'(x)\delta x
\end{equation}
We use this formula in the Newton method to solve nonlinear equations and optimization problems, in one or more dimensions.

We use the same approximation in the fix point method, which we use to solve equations like $f(x)=0$; in the minimum residual and conjugate gradient methods; and to solve the Laplace equation in the last chapter of the book. In all these algorithms, we start with a random guess for the solution, and we iteratively find a better one until convergence.

The second idea of the book is that certain quantities are random, but even random numbers have patterns that we can capture using instruments like distributions and correlations. The presence of these patterns helps us model those systems that may have a random output (e.g., nuclear reactions, financial systems) and also helps us in computations. In fact, we can use random numbers to compute quantities that are not random (Monte Carlo methods). The most common approximation that we make in different parts of the book is that when a random variable $x$ is localized at a point with a given uncertainty, $\delta x$, then its distribution is Gaussian. Thanks to the properties of Gaussian random numbers, we conclude the following:
\begin{itemize}
\item Using the linear approximation (our first big idea), if $z=f(x)$, the uncertainty in the output is
\begin{equation}
\delta z = f'(x) \delta x
\end{equation}
\item If we add two independent Gaussian random variables $z=x+y$, the uncertainty in the output is
\begin{equation}
\delta z = \sqrt{\delta x^2 + \delta y^2}
\end{equation}
\item If we add $N$ independent and identically distributed Gaussian variables $z=\sum x_i$, the uncertainty in the output is
\begin{equation}
\delta z = \sqrt{N}\delta x
\end{equation}
We use this over and over, for example, when relating the volatility over different time intervals (daily, yearly).
\item If we compute an average of $N$ independent and identically distributed Gaussian random variables, $z=1/N \sum x_i$, the uncertainty in the average is
\begin{equation}
\delta z = \delta x/\sqrt{N}
\end{equation}
We use this to estimate the error on the average in a Monte Carlo computation. In that case, we write it as $d\mu = \sigma/\sqrt{N}$, and $\sigma$ is the standard deviation of $\{ x_i\}$.
\end{itemize}

The third idea is that the time it takes to run an iterative algorithm is proportional to the number of iterations. It is therefore our goal to minimize the number of iterations required to reach a target precision. We develop a language to compare algorithms based on their running time and classify algorithms into categories. This is useful to choose the best algorithm based on the problem at hand.

In the chapter on parallel algorithms, we learn how to distribute those iterations over multiple parallel processes and how to break individual iterations into independent steps that can be executed concurrently on parallel processes, to reduce the total time required to obtain a solution within a given target precision. In the parallel case, the running time acquires an overhead that depends on the communication patterns between the parallel processes, the communication latency, and bandwidth.

In the ultimate analysis, we can even try to understand ourselves as a parallel machine that models the input from the world by approximations. The brain is a graph that can be modeled by a neural network. The learning process is an ongoing optimization process in which the brain adjusts its synapses to produce better and better responses. The decision process mimics a search tree. We solve problems by searching for the most similar problems that we have encountered before, then we refine the solution. Our DNA is a code that evolved to efficiently compress the information necessary to grow us from a single cell into a complex being. We evolved according to evolutionary mechanisms that can be modeled using genetic algorithms. We can find our similarities with other organisms using the longest common subsequence algorithm. We can reconstruct our evolutionary tree using shortest-path algorithms and find out how we came to be.

\section{About Python}

The programming language used in this book is Python~\cite{python} version 3.8. This is because Python algorithms are very similar to the corresponding pseudo-code, and therefore this language is easy to read and understand compared to other languages such as C++ or Java. Moreover, Python is a popular language in many Universities and Companies (including Google).

The goal of the book is to explain the algorithms by building them from scratch. It is not our goal to teach the user about existing libraries that may be (and often are) faster than our implementation. Two notable examples are NumPy~\cite{numpy} and SciPy~\cite{scipy}. These libraries provide a Python interface to the BLAS and LaPack libraries for linear algebra and applications. Although we wholeheartedly recommend using them when developing production code, we believe they are not appropriate for teaching the algorithms themselves because those algorithms are written in C, FORTRAN, and assembly languages and are not easy to read.

\section{Book Structure}

This book is divided into the following chapters:

\begin{itemize}
\item This introduction.
\item An introduction to the Python programming language. The introduction assumes the reader is not new to basic programming concepts, such as conditionals, loops, and function calls, and teaches the basic syntax of the Python language, with particular focus on those built-in modules that are important for scientific applications (math, cmath, decimal, random) and a few others.
\item Chapter 3 is a short review of the general theory of algorithms with applications. There we review how to determine the running time of an algorithm from simple loops to more complex recursive algorithms. We review basic data structures used to store information such as lists, arrays, stacks, queues, trees, and graphs. We also review the classification of basic algorithms such as divide-and-conquer, dynamic programming, and greedy algorithms. In the examples, we peek into complex algorithms such as Shannon--Fano compression, a maze solver, a clustering algorithm, and a neural network.
\item In chapter 4, we talk about traditional numerical algorithms, in particular, linear algebra, solvers, optimizers, integrators, and Fourier--Laplace transformations. We start by reviewing the concept of Taylor series and their convergence to understand approximations, sources of error, and convergence. We then use those concepts to build more complex algorithms by systematically improving their first-order (linear) approximation. Linear algebra serves us as a tool to approximate and implement functions of many variables.
\item In chapter 5, we provide a review of probability and statistics and implement basic Python functions to perform statistical analysis of random variables.
\item In chapter 6, we discuss algorithms to generate random numbers from many distributions. Python already has a built-in module to generate random numbers, and in subsequent chapters, we utilize it, yet in this chapter, we discuss in detail how pseudo random number generators work and their pitfalls.
\item In chapter 7, we write about Monte Carlo simulations. This is a numerical technique that utilizes random numbers to solve otherwise deterministic problems. For example, in chapter 4, we talk about numerical integration in one dimension. Those algorithms can be extended to perform numerical integration in a few (two, three, sometimes four) dimensions, but they fail for very large numbers of dimensions. That is where Monte Carlo integration comes to our rescue, as it increasingly becomes the integration method of choice as the number of variables increases. We present applications of Monte Carlo simulations.
\item In chapter 8, we discuss parallel algorithms. There are many paradigms for parallel programming these days, and the tendency is toward inhomogeneous architectures. Although we review many different types of architectures, we focus on three programming paradigms that have been very successful: message-passing, map-reduce, and multithreaded GPU programming. In the message-passing case, we create a simple ``parallel simulator'' (PSim) in Python that allows us to understand the basic ideas behind message passing and issues with different network topologies. In the GPU case, we use the pyOpenCL~\cite{pyopencl} library to run OpenCL kernels on the GPU (or CPUs).

\item Finally, in the appendix, we provide a compendium of useful formulas and definitions.
\end{itemize}

\section{Book Software}

We utilize the following software libraries developed by the author and available under an Open Source BSD License:

\begin{itemize}
\item \url{http://github.com/mdipierro/nlib}
\item \url{http://github.com/mdipierro/buckingham}
\end{itemize}

We also utilize the following third party libraries:

\begin{itemize}
\item \url{http://www.numpy.org/}
\item \url{http://matplotlib.org/}
\item \url{https://github.com/ziyuang/mincemeatpy}
\item \url{https://pypi.org/project/pyopencl/}
\end{itemize}

All the code included in these notes is released by the author under the three-clause BSD License.

\section * {Acknowledgements}

Many thanks to Alan Etkins, Brian Fox, Dan Bowker, Ethan Sudman, Holly Monteith, Konstantinos Moutselos, Luca De Alfaro, Michael Gheith, Paula Mikrut, Sean Neilan, and John Plamondon for reviewing different editions of this book. We also thank all the students of our classes for their useful comments and suggestions. Finally, we thank Wikipedia, from which we borrowed a few ideas and examples.

\goodbreak\chapter{Overview of the Python Language}

\index{Python}

\goodbreak\section{About Python}

Python is a general-purpose high-level programming language.
Its design philosophy emphasizes programmer productivity and code readability. It has a minimalist core syntax with very few basic commands and simple semantics. It also has a large and comprehensive standard library, including an Application Programming Interface (API) \index{API} to many of the underlying operating system (OS) functions. Python provides built-in objects such as linked lists ({\ft list}), tuples ({\ft tuple}), hash tables ({\ft dict}), arbitrarily long integers ({\ft long}), complex numbers, and arbitrary precision decimal numbers.

Python supports multiple programming paradigms, including object-oriented ({\ft class}), imperative ({\ft def}), and functional ({\ft lambda}) programming. Python has a dynamic type system and automatic memory management using reference counting (similar to Perl, Ruby, and Scheme).

Python was first released by Guido van Rossum in 1991~\cite{guido}. The language has an open, community-based development model managed by the nonprofit Python Software Foundation. There are many interpreters and compilers that implement the Python language, including one in Java (Jython), one built on .Net (IronPython), and one built in Python itself (PyPy). In this brief review, we refer to the reference C implementation created by Guido.

You can find many tutorials, the official documentation, and library references of the language on the official Python website.~\cite{python}

For additional Python references, we can recommend the books in ref.~\cite{guido}  and ref.~\cite{lutz}.

You may skip this chapter if you are already familiar with the Python language.

\goodbreak\subsection{Python versus Java and C++ syntax}

\index{Java}\index{C++}

\begin{center}
\begin{tabular}{|l|l|l|l|}
\hline
& {\bf Java/C++} & {\bf Python} \\ \hline
assignment & $a=b;$ & $a=b$ \\ \hline
comparison & if ($a == b$) & if $a == b$: \\ \hline
loops & for($a=0;a<n;a++)$ & for $a$ in $range(0, n)$: \\ \hline
block & Braces \{...\} & indentation \\ \hline
function & $float f$(float $a$) \{ & def $f(a)$: \\ \hline
function call & $f(a)$ & $f(a)$ \\ \hline
arrays/lists & $a[i]$ & $a[i]$ \\ \hline
member & $a$.member & $a$.member \\ \hline
nothing & $null$ / $void * $ & $None$ \\ \hline
\end{tabular}
\end{center}

As in Java, variables that are primitive types (bool, int, float) are passed by copy, but more complex types, unlike C++, are passed by reference. This means when we pass an object to a function, in Python, we do not make a copy of the object, we simply define an alternate name for referencing the object in the function.

\goodbreak\subsection{help, dir}

\index{help} \index{dir}

The Python language provides two commands to obtain documentation about objects defined in the current scope, whether the object is built in or user defined.

We can ask for {\ft help} about an object, for example, ``1'':
\begin{lstlisting}
>>> help(1)
Help on int object:

class int(object)
 |  int(x[, base]) -> integer
 |
 |  Convert a string or number to an integer, if possible.  A floating point
 |  argument will be truncated towards zero (this does not include a string
 |  representation of a floating point number!)  When converting a string, use
 |  the optional base.  It is an error to supply a base when converting a
 |  non-string. If the argument is outside the integer range a long object
 |  will be returned instead.
 |
 |  Methods defined here:
 |
 |  __abs__(...)
 |      x.__abs__() < == > abs(x)
...
\end{lstlisting}
\noindent and because ``1'' is an integer, we get a description about the {\ft int} class and all its methods. Here the output has been truncated because it is very long and detailed.

Similarly, we can obtain a list of object attributes (including methods) for any object using the command {\ft dir}. For example:
\begin{lstlisting}
>>> dir(1)
["__abs__", "__add__", "__and__", "__class__", "__cmp__", "__coerce__", 
"__delattr__", "__div__", "__divmod__", "__doc__", "__float__", 
"__floordiv__", "__getattribute__", "__getnewargs__", "__hash__", "__hex__", 
"__index__", "__init__", "__int__", "__invert__", "__long__", "__lshift__", 
"__mod__", "__mul__", "__neg__", "__new__", "__nonzero__", "__oct__", 
"__or__", "__pos__", "__pow__", "__radd__", "__rand__", "__rdiv__", 
"__rdivmod__", "__reduce__", "__reduce_ex__", "__repr__", "__rfloordiv__", 
"__rlshift__", "__rmod__", "__rmul__", "__ror__", "__rpow__", "__rrshift__", 
"__rshift__", "__rsub__", "__rtruediv__", "__rxor__", "__setattr__", 
"__str__", "__sub__", "__truediv__", "__xor__"]
\end{lstlisting}

\goodbreak\section{Types of variables}

\index{type}
Python is a dynamically typed language, meaning that variables do not have a type and therefore do not have to be declared.  Variables may also change the type of value they hold through their lives.  Values, on the other hand, do have a type. You can query a variable for the type of value it contains:

%%% META:FILE:test.py
\begin{lstlisting}
>>> a = 3
>>> type(a)
<type 'int'>
>>> a = 3.14
>>> type(a)
<type 'float'>
>>> a = "hello python"
>>> type(a)
<type 'str'>
\end{lstlisting}

Python also includes, natively, data structures such as lists and dictionaries.

\goodbreak\subsection{{\ft int} and {\ft long}}

\index{int}\index{long}

There are two types representing integer numbers: {\ft int} and {\ft long}. The difference is that {\ft int} corresponds to the microprocessor"s native bit length.  Typically, this is 32 bits and can hold signed integers in range $[-2^{31}, +2^{31})$, whereas the {\ft long} type can hold almost any arbitrary integer. It is important that Python automatically converts one into the other as necessary, and you can mix and match the two types in computations. Here is an example:

%%% META:FILE:test.py
\begin{lstlisting}
>>> a = 1024
>>> type(a)
<type 'int'>
>>> b = a ** 128
>>> b
20815864389328798163850480654728171077230524494533409610638224700807216119346720
59602447888346464836968484322790856201558276713249664692981627981321135464152584
82590187784406915463666993231671009459188410953796224233873542950969577339250027
68876520583464697770622321657076833170056511209332449663781837603694136444406281
042053396870977465916057756101739472373801429441421111406337458176
>>> type(b)
<type "long">
\end{lstlisting}

Computers represent 32-bit integer numbers by converting them to base 2. The conversion works in the following way:

%%% META:FILE:test.py
\begin{lstlisting}
def int2binary(n, nbits=32):
    if n<0:
        return [1 if bit == 0 else 0 for bit in int2binary(-n-1, nbits)]
    bits = [0] * nbits
    for i in range(nbits):
        n, bits[i] = divmod(n, 2)
    if n: raise OverflowError
    return bits
\end{lstlisting}

\index{two"s complement}

The case $n<0$ is called {\it two"s complement} and is defined as the value obtained by subtracting the number from the largest power of 2 ($2^{32}$ for 32 bits). Just by looking at the most significant bit, one can determine the sign of the binary number (1 for negative and 0 for zero or positive).

\goodbreak\subsection{{\ft float} and {\ft decimal}}

\index{float}\index{double}\index{decimal}\index{binary representation}

There are two ways to represent decimal numbers in Python: using the native double precision (64 bits) representation, {\ft float}, or using the {\ft decimal} module.

Most numerical problems are dealt with simply using {\ft float}:

%%% META:FILE:test.py
\begin{lstlisting}
>>> pi = 3.141592653589793
>>> two_pi = 2.0 * pi
\end{lstlisting}

Floating point numbers are internally represented as follows:

\begin{equation}
x = \pm m 2^e
\end{equation}

where $x$ is the number, $m$ is called the {\it mantissa} and is zero or a number in the range [1, 2), and $e$ is called the {\it exponent}. The sign, $m$, and $e$ can be computed using the following algorithm, which also writes their representation in binary:

%%% META:FILE:test.py
\begin{lstlisting}
def float2binary(x, nm=4, ne=4):
    if x == 0:
        return 0, [0] * nm, [0] * ne
    sign, mantissa, exponent = (1 if x<0 else 0), abs(x), 0
    while abs(mantissa)>=2:
        mantissa, exponent = 0.5 * mantissa, exponent+1
    while 0<abs(mantissa)<1:
        mantissa, exponent = 2.0 * mantissa, exponent-1
    mantissa = int2binary(int(2 ** (nm-1) * mantissa), nm)
    exponent = int2binary(exponent, ne)
    return sign, mantissa, exponent
\end{lstlisting}

Because the exponent is stored in a fixed number of bits (11 for a 64-bit floating point number), exponents smaller than $-$1022 and larger than 1023 cannot be represented. An arithmetic operation that returns a number smaller than $2^{-1022} \simeq 10^{-308}$ cannot be represented and results in an underflow error. An operation that returns a number larger than $2^{1023}\simeq 10^{308}$ also cannot be represented and results in an overflow error.

Here is an example of overflow:

%%% META:FILE:test.py
\begin{lstlisting}
>>> a = 10.0 ** 200
>>> a * a
inf
\end{lstlisting}

And here is an example of underflow:

%%% META:FILE:test.py
\begin{lstlisting}
>>> a = 10.0 ** -200
>>> a * a
0.0
\end{lstlisting}

Another problem with finite precision arithmetic is the loss of precision in computation. Consider the case of the difference between two numbers with very different orders of magnitude. To compute the difference, the CPU reduces them to the same exponent (the largest of the two) and then computes the difference in the two mantissas. If two numbers differ for a factor $2^k$, then the mantissa of the smallest number, in binary, needs to be shifted by $k$ positions, thus resulting in a loss of information because the $k$ least significant bits in the mantissa are ignored. If the difference between the two numbers is greater than a factor $2^{52}$, all bits in the mantissa of the smallest number are ignored, and the smallest number becomes completely invisible.

Following is a practical example that produces an incorrect result:

%%% META:FILE:test.py
\begin{lstlisting}
>>> a = 1.0
>>> b = 2.0 ** 53
>>> a+b-b
0.0
\end{lstlisting}

a simple example of what occurs internally in a processor to add two floating point numbers together. The IEEE 754 standard states that for 32-bit floating point numbers, the exponent has a range of $-$126 to +127:

\begin{lstlisting}
262 in IEEE 754: 0 10000111 00000110000000000000000  (+ e:8 m:1.0234375)
  3 in IEEE 754: 0 10000000 10000000000000000000000  (+ e:1 m:1.5)
265 in IEEE 754: 0 10000111 00001001000000000000000
\end{lstlisting}

To add 262.0 to 3.0, the exponents must be the same. The exponent of the lesser number is increased to the exponent of the greater number.  In this case, 3"s exponent must be increased by 7.  Increasing the exponent by 7 means the mantissa must be shifted seven binary digits to the right:

\begin{lstlisting}
0 10000111 00000110000000000000000
0 10000111 00000011000000000000000  (The implied ``1'' is also pushed seven places to the right)
------------------------------------
0 10000111 00001001000000000000000  which is the IEEE 754 format for 265.0
\end{lstlisting}

In the case of two numbers in which the exponent is greater than the number of digits in the mantissa, the smaller number is shifted right off the end.  The effect is a zero added to the larger number.

In some cases, only some of the bits of the smaller number"s mantissa are lost if a partial addition occurs.

This precision issue is always present but not always obvious. It may consist of a small discrepancy between the true value and the computed value. This difference may increase during the computation, in particular, in iterative algorithms, and may be sizable in the result of a complex algorithm.

Python also has a module for  decimal floating point arithmetic that allows decimal numbers to be represented exactly. The class Decimal incorporates a notion of significant places (unlike the hardware-based binary floating point, the decimal module has a user-alterable precision):

%%% META:FILE:test.py
\begin{lstlisting}
>>> from decimal import Decimal, getcontext
>>> getcontext().prec = 28  # set precision
>>> Decimal(1) / Decimal(7)
Decimal("0.1428571428571428571428571429")
\end{lstlisting}

Decimal numbers can be used almost everywhere in place of floating point number arithmetic but are slower and should be used only where arbitrary precision arithmetic is required. It does not suffer from the overflow, underflow, and precision issues described earlier:

%%% META:FILE:test.py
\begin{lstlisting}
>>> from decimal import Decimal
>>> a = Decimal(10.0) ** 300
>>> a * a
Decimal("1.000000000000000000000000000E+600")
\end{lstlisting}

\goodbreak\subsection{{\ft complex}}

\index{complex}

Python has native support for complex numbers. The imaginary unit is represented by the character {\ft j}:

%%% META:FILE:test.py
\begin{lstlisting}
>>> c = 1+2j
>>> c
(1+2j)
>>> c.real
1.0
>>> c.imag
2.0
>>> abs(c)
2.2360679775
\end{lstlisting}

The real and imaginary parts of a complex number are stored as 64-bit floating point numbers.

Normal arithmetic operations are supported. The {\ft cmath} module contains trigonometric and other functions for complex numbers. For example, 

\begin{lstlisting}
>>> phi = 1j
>>> import cmath
>>> cmath.exp(phi)
(0.540302305868+0.841470984808j)
\end{lstlisting}


\goodbreak\subsection{{\ft str}}

\index{str} \index{ASCII} \index{UTF8} \index{Unicode} \index{encode}

Python supports the use of two different types of strings: ASCII strings and Unicode strings. ASCII strings are delimited by {\ft "..."}, {\ft "..."}, {\ft """..."""}, or {\ft """..."""}. Triple quotes delimit multiline strings. Unicode strings start with a {\ft u}, followed by the string containing Unicode characters. A Unicode string can be converted into an ASCII string by choosing an encoding (e.g., UTF8):

%%% META:FILE:test.py
\begin{lstlisting}
>>> a = "this is an ASCII string"
>>> b = u"This is a Unicode string"
>>> a = b.encode("utf8")
\end{lstlisting}

After executing these three commands, the resulting {\ft a} is an ASCII string storing UTF8 encoded characters.

It is also possible to write variables into strings in various ways:

%%% META:FILE:test.py
\begin{lstlisting}
>>> "number is " + str(3)
number is 3
>>> "number is %s" % (3)
number is 3
>>> "number is %(number)s" % dict(number=3)
number is 3
\end{lstlisting}

The final notation is more explicit and less error prone and is to be preferred.

Many Python objects, for example, numbers, can be serialized into strings using {\ft str} or {\ft repr}. These two commands are very similar but produce slightly different output. For example, 

%%% META:FILE:test.py
\begin{lstlisting}
>>> for i in [3, "hello"]:
...     print(str(i), repr(i))
3 3
hello "hello"
\end{lstlisting}

For user-defined classes, {\ft str} and {\ft repr} can be defined and redefined using the special operators {\ft \_\_str\_\_} and {\ft \_\_repr\_\_}. These are briefly described later in this chapter. For more information on the topic, refer to the official Python documentation~\cite{pydocs}.

Another important characteristic of a Python string is that it is an iterable object, similar to a list:

%%% META:FILE:test.py
\begin{lstlisting}
>>> for i in "hello":
...     print(i)
h
e
l
l
o
\end{lstlisting}

\goodbreak\subsection{{\ft list} and {\ft array}}

\index{list}\index{array}

The distinction between lists and arrays is usually in their implementation and in the relative difference in speed of the operations they can perform. Python defines a type called {\ft list} that internally is implemented more like an array.

The main methods of Python lists are append, insert, and delete.  Other useful methods include count, index, reverse, and sort:

%%% META:FILE:test.py
\begin{lstlisting}
>>> b = [1, 2, 3]
>>> type(b)
<type "list">
>>> b.append(8)
>>> b.insert(2, 7)  # insert 7 at index 2 (3rd element)
>>> del b[0]
>>> b
[2, 7, 3, 8]
>>> len(b)
4
>>> b.append(3)
>>> b.reverse()
>>> b, " 3 appears ", b.count(3), " times.  The number 7 appears at index ", b.index(7)
[3, 8, 3, 7, 2] 3 appears 2 times.  The number 7 appears at index 3

\end{lstlisting}

Lists can be sliced:

%%% META:FILE:test.py
\begin{lstlisting}
>>> a= [2, 7, 3, 8]
>>> a[:3]
[2, 7, 3]
>>> a[1:]
[7, 3, 8]
>>> a[-2:]
[3, 8]
\end{lstlisting}
\noindent and concatenated/joined:

%%% META:FILE:test.py
\begin{lstlisting}
>>> a = [2, 7, 3, 8]
>>> a = [2, 3]
>>> b = [5, 6]
>>> a + b
[2, 3, 5, 6]
\end{lstlisting}

A list is iterable; you can loop over it:

%%% META:FILE:test.py
\begin{lstlisting}
>>> a = [1, 2, 3]
>>> for i in a:
...     print(i)
1
2
3
\end{lstlisting}

A list can also be sorted in place with the {\ft sort} method:

\begin{lstlisting}
>>> a.sort()
\end{lstlisting}

\index{list comprehension}

There is a very common situation for which a {\it list comprehension} can be used. Consider the following code:

%%% META:FILE:test.py
\begin{lstlisting}
>>> a = [1, 2, 3, 4, 5]
>>> b = []
>>> for x in a:
...     if x % 2 == 0:
...         b.append(x * 3)
>>> b
[6, 12]
\end{lstlisting}

This code clearly processes a list of items, selects and modifies a subset of the input list, and creates a new result list. This code can be entirely replaced with the following list comprehension:

%%% META:FILE:test.py
\begin{lstlisting}
>>> a = [1, 2, 3, 4, 5]
>>> b = [x * 3 for x in a if x % 2 == 0]
>>> b
[6, 12]
\end{lstlisting}

Python has a module called {\ft array}. It provides an efficient array implementation. Unlike lists, array elements must all be of the same type, and the type must be either a char, short, int, long, float, or double.  A type of char, short, int, or long may be either signed or unsigned. Notice these are C-types, not Python types.

%%% META:FILE:test.py
\begin{lstlisting}
>>> from array import array
>>> a = array("d", [1, 2, 3, 4, 5])
array("d", [1.0, 2.0, 3.0, 4.0, 5.0])
\end{lstlisting}

An array object can be used in the same way as a list, but its elements must all be of the same type, specified by the first argument of the constructor (``d'' for double, ``l'' for signed long, ``f'' for float, and ``c'' for character).  For a complete list of available options, refer to the official Python documentation.

Using ``array'' over ``list'' can be faster, but more important, the ``array'' storage is more compact for large arrays.

\goodbreak\subsection{{\ft tuple}}

\index{tuple}

A tuple is similar to a list, but its size and elements are immutable. If a tuple element is an object, the object itself is mutable, but the reference to the object is fixed. A tuple is defined by elements separated by a comma and optionally delimited by round parentheses:

%%% META:FILE:test.py
\begin{lstlisting}
>>> a = 1, 2, 3
>>> a = (1, 2, 3)
\end{lstlisting}

The round brackets are required for a tuple of zero elements such as
%%% META:FILE:test.py
\begin{lstlisting}
>>> a = ()  # this is an empty tuple
\end{lstlisting}

A trailing comma is required for a one-element tuple but not for two or more elements:
%%% META:FILE:test.py
\begin{lstlisting}
>>> a = (1)    # not a tuple
>>> a = (1,)   # this is a tuple of one element
>>> b = (1, 2)  # this is a tuple of two elements
\end{lstlisting}

Since lists are mutable; this works:
%%% META:FILE:test.py
\begin{lstlisting}
>>> a = [1, 2, 3]
>>> a[1] = 5
>>> a
[1, 5, 3]
\end{lstlisting}
\noindent the element assignment does not work for a tuple:
%%% META:FILE:test.py
\begin{lstlisting}
>>> a = (1, 2, 3)
>>> a[1]
2
>>> a[1] = 5
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
TypeError: "tuple" object does not support item assignment
\end{lstlisting}

A tuple, like a list, is an iterable object. Notice that a tuple consisting of a single element must include a trailing comma:
%%% META:FILE:test.py
\begin{lstlisting}
>>> a = (1)
>>> type(a)
<type 'int'>
>>> a = (1,)
>>> type(a)
<type "tuple">
\end{lstlisting}

Tuples are very useful for efficient packing of objects because of their immutability. The brackets are often optional.  You may easily get each element of a tuple by assigning multiple variables to a tuple at one time:
%%% META:FILE:test.py
\begin{lstlisting}
>>> a = (2, 3, "hello")
>>> (x, y, z) = a
>>> x
2
>>> z
hello
>>> a = "alpha", 35, "sigma"  # notice the rounded brackets are optional
>>> p, r, q = a
print(r)
35
\end{lstlisting}

\goodbreak\subsection{{\ft dict}}

\index{dict}

A Python {\ft dict}-ionary is a hash table that maps a key object to a value object:
%%% META:FILE:test.py
\begin{lstlisting}
>>> a = {"k":"v", "k2":3}
>>> a["k"]
v
>>> a["k2"]
3
>>> "k" in a
True
>>> "v" in a
False
\end{lstlisting}

You will notice that the format to define a dictionary is the same as the JavaScript Object Notation [JSON].  Dictionaries may be nested:
%%% META:FILE:test.py
\begin{lstlisting}
>>> a = {"x":3, "y":54, "z":{"a":1, "b":2}}
>>> a["z"]
{"a": 1, "b": 2}
>>> a["z"]["a"]
1
\end{lstlisting}

Keys can be of any hashable type (int, string, or any object whose class implements the {\ft \_\_hash\_\_} method). Values can be of any type. Different keys and values in the same dictionary do not have to be of the same type. If the keys are alphanumeric characters, a dictionary can also be declared with the alternative syntax:
%%% META:FILE:test.py
\begin{lstlisting}
>>> a = dict(k="v", h2=3)
>>> a["k"]
v
>>> a
{"h2": 3, "k": "v"}
\end{lstlisting}

Useful methods are {\ft has\_key}, {\ft keys}, {\ft values}, {\ft items}, and {\ft update}:
%%% META:FILE:test.py
\begin{lstlisting}
>>> a = dict(k="v", k2=3)
>>> a.keys()
["k2", "k"]
>>> a.values()
[3, "v"]
>>> a.update({"n1":"new item"})      # adding a new item
>>> a.update(dict(n2="newer item"))  # alternate method to add a new item
>>> a["n3"] = "newest item"          # another method to add a new item
>>> a.items()
[("k2", 3), ("k", "v"), ("n3", "newest item"), ("n2", "newer item"), ("n1", "new item")]
\end{lstlisting}

The {\ft items} method produces a list of tuples, each containing a key and its associated value.

Dictionary elements and list elements can be deleted with the command {\ft del}:
%%% META:FILE:test.py
\begin{lstlisting}
>>> a = [1, 2, 3]
>>> del a[1]
>>> a
[1, 3]
>>> a = dict(k="v", h2=3)
>>> del a["h2"]
>>> a
{"k": "v"}
\end{lstlisting}

Internally, Python uses the {\ft hash} operator to convert objects into integers and uses that integer to determine where to store the value.  Using a key that is not hashable will cause an {\ft un-hashable type} error:
%%% META:FILE:test.py
\begin{lstlisting}
>>> hash("hello world")
-1500746465
>>> k = [1, 2, 3]
>>> a = {k:"4"}
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
TypeError: unhashable type: "list"
\end{lstlisting}

\goodbreak\subsection{{\ft set}}

\index{set}

A set is something between a list and a dictionary. It represents a non-ordered list of unique elements.  Elements in a set cannot be repeated.  Internally, it is implemented as a hash table, similar to a set of keys in a dictionary.  A set is created using the {\ft set} constructor.  Its argument can be a list, a tuple, or an iterator:

%%% META:FILE:test.py
\begin{lstlisting}
>>> s = set([1, 2, 3, 4, 5, 5, 5, 5])   # notice duplicate elements are removed
>>> s
set([1, 2, 3, 4, 5])
>>> s = set((1, 2, 3, 4, 5))
>>> s
set([1, 2, 3, 4, 5])
>>> s = set(i for i in range(1, 6))
>>> s
set([1, 2, 3, 4, 5])
\end{lstlisting}

Sets are not ordered lists therefore appending to the end is not applicable.  Instead of {\ft append}, add elements to a set using the {\ft add} method:

%%% META:FILE:test.py
\begin{lstlisting}
>>> s = set()
>>> s.add(2)
>>> s.add(3)
>>> s.add(2)
>>> s
set([2, 3])
\end{lstlisting}

Notice that the same element cannot be added twice (2 in the example). There is no exception or error thrown when trying to add the same element more than once.

Because sets are not ordered, the order in which you add items is not necessarily the order in which they will be returned:

%%% META:FILE:test.py
\begin{lstlisting}
>>> s = set([6, "b", "beta", -3.4, "a", 3, 5.3])
>>> (s)
set(["a", 3, 6, 5.3, "beta", "b", -3.4])
\end{lstlisting}


The {\ft set} object supports normal set operations like union, intersection, and difference:

%%% META:FILE:test.py
\begin{lstlisting}
>>> a = set([1, 2, 3])
>>> b = set([2, 3, 4])
>>> c = set([2, 3])
>>> a.union(b)
set([1, 2, 3, 4])
>>> a.intersection(b)
set([2, 3])
>>> a.difference(b)
set([1])
>>> if len(c) == len(a.intersection(c)):
...     print("c is a subset of a")
... else:
...     print("c is not a subset of a")
...
c is a subset of a
\end{lstlisting}

To check for membership, 

%%% META:FILE:test.py
\begin{lstlisting}
>>> 2 in a
True
\end{lstlisting}

\goodbreak\section{Python control flow statements}

Python uses indentation to delimit blocks of code. A block starts with a line ending with colon and continues for all lines that have a similar or higher indentation as the next line:

%%% META:FILE:test.py
\begin{lstlisting}
>>> i = 0
>>> while i < 3:
...    print(i)
...    i = i + 1
0
1
2
\end{lstlisting}

It is common to use four spaces for each level of indentation.
It is a good policy not to mix tabs with spaces, which can result in (invisible) confusion.

\goodbreak\subsection{{\ft for...in}}

\index{for}
In Python, you can loop over iterable objects:

%%% META:FILE:test.py
\begin{lstlisting}
>>> a = [0, 1, "hello", "python"]
>>> for i in a:
...     print(i)
0
1
hello
python
\end{lstlisting}

In the preceding example, you will notice that the loop index ``i'' takes on the values of each element in the list [0, 1, "hello", "python"] sequentially.  The Python {\ft range} keyword creates a list of integers automatically that may be used in a ``for'' loop without manually creating a long list of numbers.

%%% META:FILE:test.py
\begin{lstlisting}
>>> a = range(0, 5)
>>> a
[0, 1, 2, 3, 4]
>>> for i in a:
...     print(i)
0
1
2
3
4
\end{lstlisting}

The parameters for {\ft range(a, b, c)} are as follows: the first parameter is the starting value of the list.  The second parameter is the next value if the list contains one more element.  The third parameter is the increment value.

The keyword {\ft range} can also be called with one parameter. It is matched to ``b'' with the first parameter defaulting to 0 and the third to 1:

%%% META:FILE:test.py
\begin{lstlisting}
>>> range(5)
[0, 1, 2, 3, 4]
>>> range(53, 57)
[53, 54, 55, 56]
>>> range(102, 200, 10)
[102, 112, 122, 132, 142, 152, 162, 172, 182, 192]
>>> range(0, -10, -1)
[0, -1, -2, -3, -4, -5, -6, -7, -8, -9]
\end{lstlisting}

The keyword {\ft range} is very convenient for iterating over a list of numbers.

This is equivalent to the C/C++/C\#/Java syntax:

\begin{lstlisting}
for(int i=0; i<4; i=i+1) { ... }
\end{lstlisting}

Another useful command is {\ft enumerate}, which counts while looping and returns a tuple consisting of (index, value):
%%% META:FILE:test.py
\begin{lstlisting}
>>> a = [0, 1, "hello", "python"]
>>> for (i, j) in enumerate(a):    # the ( ) around i, j are optional
...     print(i, j)
0 0
1 1
2 hello
3 python
\end{lstlisting}

There is also a keyword {\ft range(a, b, c)} that returns a list of integers starting with the value {\ft a}, incrementing by {\ft c}, and ending with the last value smaller than {\ft b}, where {\ft a} defaults to 0 and {\ft c} defaults to 1.

You can jump out of a loop using {\ft break}:
%%% META:FILE:test.py
\begin{lstlisting}
>>> for i in [1, 2, 3]:
...      print(i)
...      break
1
\end{lstlisting}

You can jump to the next loop iteration without executing the entire code block with {\ft continue}:
%%% META:FILE:test.py
\begin{lstlisting}
>>> for i in [1, 2, 3]:
...      print(i)
...      continue
...      print("test")
1
2
3
\end{lstlisting}

Python also supports list comprehensions, and you can build lists using the following syntax:
%%% META:FILE:test.py
\begin{lstlisting}
>>> a = [i * i for i in [0, 1, 2, 3]:
>>> a
[0, 1, 4, 9]
\end{lstlisting}

Sometimes you may need a counter to ``count'' the elements of a list while looping:
%%% META:FILE:test.py
\begin{lstlisting}
>>> a = [e * (i+1) for (i, e) in enumerate(["a", "b", "c", "d"])]
>>> a
["a", "bb", "ccc", "dddd"]
\end{lstlisting}


\goodbreak\subsection{{\ft while}}

\index{while}
Comparison operators in Python follow the C/C++/Java operators of == , !=, ..., and so on.  However, Python also accepts the <> operator as not equal to and is equivalent to !=.  Logical operators are {\ft and}, {\ft or}, and {\ft not}.

The {\ft while} loop in Python works much as it does in many other programming languages, by looping an indefinite number of times and testing a condition before each iteration. If the condition is {\ft False}, the loop ends:
%%% META:FILE:test.py
\begin{lstlisting}
>>> i = 0
>>> while i < 10:
...     i = i + 1
>>> i
10
\end{lstlisting}

The {\ft for} loop was introduced earlier in this chapter.

There is no {\ft loop...until} or {\ft do...while} construct in Python.

\goodbreak\subsection{{\ft if...elif...else}}

\index{if} \index{elif} \index{else}
The use of conditionals in Python is intuitive:
%%% META:FILE:test.py
\begin{lstlisting}
>>> for i in range(3):
...     if i == 0:
...         print("zero")
...     elif i == 1:
...         print("one")
...     else:
...         print("other")
zero
one
other
\end{lstlisting}

The {\ft elif} means ``else if.'' Both {\ft elif} and {\ft else} clauses are optional. There can be more than one {\ft elif} but only one {\ft else} statement. Complex conditions can be created using the {\ft not}, {\ft and}, and {\ft or} logical operators:
\begin{lstlisting}
>>> for i in range(3):
...     if i == 0 or (i == 1 and i + 1 == 2):
...         print("0 or 1")
\end{lstlisting}

\goodbreak\subsection{{\ft try...except...else...finally}}

\index{try} \index{except} \index{finally} \index{Exception}
Python can throw - pardon, raise - exceptions:
%%% META:FILE:test.py
\begin{lstlisting}
>>> try:
...     a = 1 / 0
... except Exception, e:
...     print("oops: %s" % e)
... else:
...     print("no problem here")
... finally:
...     print("done")
oops: integer division or modulo by zero
done
\end{lstlisting}

If an exception is raised, it is caught by the {\ft except} clause, and the {\ft else} clause is not executed.
The {\ft finally} clause is always executed.

There can be multiple {\ft except} clauses for different possible exceptions:
%%% META:FILE:test.py
\begin{lstlisting}
>>> try:
...     raise SyntaxError
... except ValueError:
...     print("value error")
... except SyntaxError:
...     print("syntax error")
syntax error
\end{lstlisting}

The {\ft finally} clause is guaranteed to be executed while the {\ft except} and {\ft else} are not.  In the following example, the function returns within a {\ft try} block.  This is bad practice, but it shows that the {\ft finally} will execute regardless of the reason the {\ft try} block is exited:
%%% META:FILE:test.py
\begin{lstlisting}
>>> def f(x):
...    try:
...        r = x * x
...        return r   # bad practice
...    except:
...        print("exception occurred %s" % e
...    else:
...        print("nothing else to do")
...    finally:
...        print("Finally we get here")
...
>>> y = f(3)
Finally we get here
>>> "result is ", y
result is  9
\end{lstlisting}

For every {\ft try}, you must have either an {\ft except} or a {\ft finally}, while the {\ft else} is optional.

Here is a list of built-in Python exceptions:
\begin{lstlisting}
BaseException
 +-- SystemExit
 +-- KeyboardInterrupt
 +-- Exception
      +-- GeneratorExit
      +-- StopIteration
      +-- StandardError
      |    +-- ArithmeticError
      |    |    +-- FloatingPointError
      |    |    +-- OverflowError
      |    |    +-- ZeroDivisionError
      |    +-- AssertionError
      |    +-- AttributeError
      |    +-- EnvironmentError
      |    |    +-- IOError
      |    |    +-- OSError
      |    |         +-- WindowsError (Windows)
      |    |         +-- VMSError (VMS)
      |    +-- EOFError
      |    +-- ImportError
      |    +-- LookupError
      |    |    +-- IndexError
      |    |    +-- KeyError
      |    +-- MemoryError
      |    +-- NameError
      |    |    +-- UnboundLocalError
      |    +-- ReferenceError
      |    +-- RuntimeError
      |    |    +-- NotImplementedError
      |    +-- SyntaxError
      |    |    +-- IndentationError
      |    |         +-- TabError
      |    +-- SystemError
      |    +-- TypeError
      |    +-- ValueError
      |    |    +-- UnicodeError
      |    |         +-- UnicodeDecodeError
      |    |         +-- UnicodeEncodeError
      |    |         +-- UnicodeTranslateError
      +-- Warning
           +-- DeprecationWarning
           +-- PendingDeprecationWarning
           +-- RuntimeWarning
           +-- SyntaxWarning
           +-- UserWarning
           +-- FutureWarning
           +-- ImportWarning
           +-- UnicodeWarning
\end{lstlisting}

For a detailed description of each of these, refer to the official Python documentation.

Any object can be raised as an exception, but it is good practice to raise objects that extend one of the built-in exception classes.

\goodbreak\subsection{{\ft def...return}}

\index{def} \index{return}

Functions are declared using {\ft def}.  Here is a typical Python function:
%%% META:FILE:test.py
\begin{lstlisting}
>>> def f(a, b):
...     return a + b
>>> f(4, 2)
6
\end{lstlisting}

There is no need (or way) to specify the type of an argument(s) or the return value(s). In this example, a function {\ft f} is defined that can take two arguments.

\index{scope}\index{namespace}

Functions are the first code syntax feature described in this chapter to introduce the concept of {\it scope}, or {\it namespace}.  In the preceding example, the identifiers {\ft a} and {\ft b} are undefined outside of the scope of function {\ft f}:
%%% META:FILE:test.py
\begin{lstlisting}
>>> def f(a):
...     return a + 1
>>> f(1)
2
>>> a
Traceback (most recent call last):
  File "<pyshell#22>", line 1, in <module>
    print(a)
NameError: name "a" is not defined
\end{lstlisting}

Identifiers defined outside of the function scope are accessible within the function; observe how the identifier {\ft a} is handled in the following code:

%%% META:FILE:test.py
\begin{lstlisting}
>>> a = 1
>>> def f(b):
...     return a + b
>>> f(1)
2
>>> a = 2
>>> f(1)  # new value of a is used
3
>>> a = 1  # reset a
>>> def g(b):
...     a = 2  # creates a new local a
...     return a + b
>>> g(2)
4
>>> a  # global a is unchanged
1
\end{lstlisting}

If {\ft a} is modified, subsequent function calls will use the new value of the global {\ft a} because the function definition binds the storage location of the identifier {\ft a}, not the value of {\ft a} itself at the time of function declaration; however, if {\ft a} is assigned-to inside function {\ft g}, the global {\ft a} is unaffected because the new local {\ft a} hides the global value.  The external-scope reference can be used in the creation of {\it closures}:

\index{closures}

%%% META:FILE:test.py
\begin{lstlisting}
>>> def f(x):
...     def g(y):
...         return x * y
...     return g
>>> doubler = f(2)  # doubler is a new function
>>> tripler = f(3)  # tripler is a new function
>>> quadrupler = f(4)  # quadrupler is a new function
>>> doubler(5)
10
>>> tripler(5)
15
>>> quadrupler(5)
20
\end{lstlisting}

Function {\ft f} creates new functions; note that the scope of the name {\ft g} is entirely internal to {\ft f}.  Closures are extremely powerful.

Function arguments can have default values and can return multiple results as a tuple (notice the parentheses are optional and are omitted in the example):

%%% META:FILE:test.py
\begin{lstlisting}
>>> def f(a, b=2):
...     return a + b, a - b
>>> x, y = f(5)
>>> x
7
>>> y
3
\end{lstlisting}

Function arguments can be passed explicitly by name; therefore the order of arguments specified in the caller can be different than the order of arguments with which the function was defined:

%%% META:FILE:test.py
\begin{lstlisting}
>>> def f(a, b=2):
...     return a + b, a - b
>>> x, y = f(b=5, a=2)
>>> x
7
>>> y
-3
\end{lstlisting}

Functions can also take a runtime-variable number of arguments.  Parameters that start with {\ft * } and {\ft ** } must be the last two parameters.  If the {\ft ** } parameter is used, it must be last in the list.  Extra values passed in will be placed in the {\ft * identifier} parameter, whereas named values will be placed into the {\ft ** identifier}.  Notice that when passing values into the function, the unnamed values must be before any and all named values:

%%% META:FILE:test.py
\begin{lstlisting}
>>> def f(a, b, * extra, ** extraNamed):
...     print("a = ", a)
...     print("b = ", b)
...     print("extra = ", extra)
...     print("extranamed = ", extraNamed)
>>> f(1, 2, 5, 6, x=3, y=2, z=6)
a =  1
b =  2
extra =  (5, 6)
extranamed =  {"y": 2, "x": 3, "z": 6}
\end{lstlisting}

Here the first two parameters (1 and 2) are matched with the parameters {\ft a} and {\ft b}, while the tuple 5, 6 is placed into {\ft extra} and the remaining items (which are in a dictionary format) are placed into {\ft extraNamed}.

In the opposite case, a list or tuple can be passed to a function that requires individual positional arguments by unpacking them:

%%% META:FILE:test.py
\begin{lstlisting}
>>> def f(a, b):
...     return a + b
>>> c = (1, 2)
>>> f( * c)
3
\end{lstlisting}
\noindent and a dictionary can be unpacked to deliver keyword arguments:

%%% META:FILE:test.py
\begin{lstlisting}
>>> def f(a, b):
...     return a + b
>>> c = {"a":1, "b":2}
>>> f( ** c)
3
\end{lstlisting}

\goodbreak\subsection{{\ft lambda}}

\index{lambda}

The keyword {\ft lambda} provides a way to define a short unnamed function:
%%% META:FILE:test.py
\begin{lstlisting}
>>> a = lambda b: b + 2
>>> a(3)
5
\end{lstlisting}

The expression ``{\ft lambda} [a]:[b]'' literally reads as ``a function with arguments [a] that returns [b].'' The {\ft lambda} expression is itself unnamed, but the function acquires a name by being assigned to identifier {\ft a}.  The scoping rules for {\ft def} apply to {\ft lambda} equally, and in fact, the preceding code, with respect to {\ft a}, is identical to the function declaration using {\ft def}:

%%% META:FILE:test.py
\begin{lstlisting}
>>> def a(b):
...     return b + 2
>>> a(3)
5
\end{lstlisting}

The only benefit of {\ft lambda} is brevity; however, brevity can be very convenient in certain situations.  Consider a function called {\ft map} that applies a function to all items in a list, creating a new list:

%%% META:FILE:test.py
\begin{lstlisting}
>>> a = [1, 7, 2, 5, 4, 8]
>>> map(lambda x: x + 2, a)
[3, 9, 4, 7, 6, 10]
\end{lstlisting}
This code would have doubled in size had {\ft def} been used instead of {\ft lambda}. The main drawback of {\ft lambda} is that (in the Python implementation) the syntax allows only for a single expression; however, for longer functions, {\ft def} can be used, and the extra cost of providing a function name decreases as the length of the function grows.

\index{lambda}

Just like {\ft def}, {\ft lambda} can be used to {\it curry} functions: new functions can be created by wrapping existing functions such that the new function carries a different set of arguments:

%%% META:FILE:test.py
\begin{lstlisting}
>>> def f(a, b): return a + b
>>> g = lambda a: f(a, 3)
>>> g(2)
5
\end{lstlisting}

Python functions created with either {\ft def} or {\ft lambda} allow refactoring of existing functions in terms of a different set of arguments.

\goodbreak\section{Classes}

\index{class}

Because Python is dynamically typed, Python classes and objects may seem odd. In fact, member variables (attributes) do not need to be specifically defined when declaring a class, and different instances of the same class can have different attributes. Attributes are generally associated with the instance, not the class (except when declared as ``class attributes, '' which is the same as ``static member variables'' in C++/Java).

Here is an example:

%%% META:FILE:test.py
\begin{lstlisting}
>>> class MyClass(object): pass
>>> myinstance = MyClass()
>>> myinstance.myvariable = 3
>>> myinstance.myvariable
3
\end{lstlisting}

Notice that {\ft pass} is a do-nothing command. In this case, it is used to define a class {\ft MyClass} that contains nothing. {\ft MyClass()} calls the constructor of the class (in this case, the default constructor) and returns an object, an instance of the class. The {\ft (object)} in the class definition indicates that our class extends the built-in {\ft object} class. This is not required, but it is good practice.

\index{class!Complex}

Here is a more involved class with multiple methods:
%%% META:FILE:test.py
\begin{lstlisting}
>>> class Complex(object):
...    z = 2
...    def __init__(self, real=0.0, imag=0.0):
...        self.real, self.imag = real, imag
...    def magnitude(self):
...        return (self.real ** 2 + self.imag ** 2) ** 0.5
...    def __add__(self, other):
...        return Complex(self.real+other.real, self.imag+other.imag)
>>> a = Complex(1, 3)
>>> b = Complex(2, 1)
>>> c = a + b
>>> c.magnitude()
5
\end{lstlisting}

Functions declared inside the class are methods. Some methods have special reserved names. For example, {\ft \_\_init\_\_} is the constructor. In the example, we created a class to store the {\ft real} and the {\ft imag} part of a complex number. The constructor takes these two variables and stores them into {\ft self} (not a keyword but a variable that plays the same role as {\ft this} in Java and {\ft ( * this)} in C++;
this syntax is necessary to avoid ambiguity when declaring nested classes, such as a class that is local to a method inside another class, something Python allows but Java and C++ do not).

The {\ft self} variable is defined by the first argument of each method. They all must have it, but they can use another variable name. Even if we use another name, the first argument of a method always refers to the object calling the method. It plays the same role as the {\ft this} keyword in Java and C++.

Method {\ft \_\_add\_\_} is also a special method (all special methods start and end in double underscore) and it overloads the {\ft +} operator between {\ft self} and {\ft other}. In the example, {\ft a+b} is equivalent to a call to {\ft a.\_\_add\_\_(b)}, and the {\ft \_\_add\_\_} method receives {\ft self=a} and {\ft other=b}.

All variables are local variables of the method, except variables declared outside methods, which are called {\it class variables}, equivalent to C++ {\it static member variables}, which hold the same value for all instances of the class.

\goodbreak\subsection{Special methods and operator overloading}

\index{operator overloading}
\index{\_\_init\_\_}\index{\_\_add\_\_}\index{\_\_sub\_\_}\index{\_\_getitem\_\_}\index{\_\_setitem\_\_}\index{\_\_mul\_\_}\index{\_\_div\_\_}



Class attributes, methods, and operators starting with a double underscore are usually intended to be private (e.g., to be used internally but not exposed outside the class), although this is a convention that is not enforced by the interpreter.

Some of them are reserved keywords and have a special meaning:
\begin{itemize}
\item {\ft \_\_len\_\_}

\item {\ft \_\_getitem\_\_}

\item {\ft \_\_setitem\_\_}
\end{itemize}
They can be used, for example, to create a container object that acts like a list:
\begin{lstlisting}
>>> class MyList(object):
>>>     def __init__(self, * a): self.a = list(a)
>>>     def __len__(self): return len(self.a)
>>>     def __getitem__(self, key): return self.a[key]
>>>     def __setitem__(self, key, value): self.a[key] = value
>>> b = MyList(3, 4, 5)
>>> b[1]
4
>>> b.a[1] = 7
>>> b.a
[3, 7, 5]
\end{lstlisting}

Other special operators include {\ft \_\_getattr\_\_} and {\ft \_\_setattr\_\_}, which define the get and set methods (getters and setters) for the class, and {\ft \_\_add\_\_}, {\ft \_\_sub\_\_}, {\ft \_\_mul\_\_}, and {\ft \_\_div\_\_}, which overload arithmetic operators. For the use of these operators, we refer the reader to the chapter on linear algebra, where they will be used to implement algebra for matrices.

\goodbreak\subsection{class Financial Transaction}

\index{present value}

As one more example of a class, we implement a class that represents a financial transaction. We can think of a simple transaction as a single money transfer of quantity {\ft a} that occurs at a given time $t$. We adopt the convention that a positive {\ft amount} represents money flowing in and a negative value represents money flowing out.

The present value (computed at time $t_0$) for a transaction occurring at time $t$ days from now of amount $A$ is defined as
\begin{equation}
\textrm{PV}(t, A) = A e^{-t r}
\end{equation}
where $r$ is the daily risk-free interest rate. If $t$ is measured in days, $r$ has to be the daily risk-free return. Here we will assume it defaults to $r=005/365$ (5\% annually).

\index{class!FinancialTransaction}

Here is a possible implementation of the transaction:

%%% META:FILE:test.py
\begin{lstlisting}
from datetime import date
from math import exp
today = date.today()
r_free = 0.05/365.0

class FinancialTransaction(object):
    def __init__(self, t, a, description=''):
        self.t= t
        self.a = a
        self.description = description
    def pv(self, t0=today, r=r_free):
        return self.a * exp(r * (t0-self.t).days)
    def __str__(self):
        return "%.2f dollars in %i days (%s)" % \
            (self.a, self.t, self.description)
\end{lstlisting}

Here we assume $t$ and $t_0$ are {\ft datetime.date} objects that store a date. The {\ft date} constructor takes the year, the month, and the day separated by a comma. The expression {\ft (t0-t).days} computes the distance in days between $t_0$ and $t$.

\index{cash flow}

Similarly, we can implement a {\it Cash Flow} class to store a list of transactions, with the {\ft add} method to add a new transaction to the list. The present value of a cash flow is the sum of the present values of each transaction:

\index{class!CashFlow}

%%% META:FILE:test.py
\begin{lstlisting}
class CashFlow(object):
    def __init__(self):
        self.transactions = []
    def add(self, transaction):
        self.transactions.append(transaction)
    def pv(self, t0, r=r_free):
        return sum(x.pv(t0, r) for x in self.transactions)
    def __str__(self):
        return "\n".join(str(x) for x in self.transactions)
\end{lstlisting}

What is the net present value at the beginning of 2012 for a bond that pays \$1000 the 20th of each month for the following 24 months (assuming a fixed interest rate of 5\% per year)?
%%% META:FILE:test.py
\begin{lstlisting}
>>> bond = CashFlow()
>>> today = date(2012, 1, 1)
>>> for year in range(2012, 2014):
...     for month in range(1, 13):
...         coupon = FinancialTransaction(date(year, month, 20), 1000)
...         bond.add(coupon)
>>> round(bond.pv(today, r=0.05/365), 0)
22826
\end{lstlisting}

This means the cost for this bond should be \$22, 826.

\goodbreak\section{File input/output}
\index{Input/Output}
\index{file.read} \index{file.write}

In Python, you can open and write in a file with
%%% META:FILE:test.py
\begin{lstlisting}
>>> file = open("myfile.txt", "w")
>>> file.write("hello world")
>>> file.close()
\end{lstlisting}

Similarly, you can read back from the file with
%%% META:FILE:test.py
\begin{lstlisting}
>>> file = open("myfile.txt", "r")
>>> file.read()
hello world
\end{lstlisting}

Alternatively, you can read in binary mode with ``rb, '' write in binary mode with ``wb, '' and open the file in append mode ``a'' using standard C notation.

The {\ft read} command takes an optional argument, which is the number of bytes. You can also jump to any location in a file using {\ft seek}
\index{file.seek}:

You can read back from the file with {\ft read}:
%%% META:FILE:test.py
\begin{lstlisting}
>>> file.seek(6)
>>> file.read()
world
\end{lstlisting}
\noindent and you can close the file with:
\begin{lstlisting}
>>> file.close()
\end{lstlisting}

\goodbreak\section{How to {\ft import} modules}

\index{import} \index{random}
The real power of Python is in its library modules. They provide a large and consistent set of application programming interfaces (APIs) to many system libraries (often in a way independent of the operating system).

For example, if you need to use a random number generator, you can do the following:
\begin{lstlisting}
>>> import random
>>> random.randint(0, 9)
5
\end{lstlisting}

This prints a random integer in the range of (0, 9], 5 in the example. The function {\ft randint} is defined in the module {\ft random}. It is also possible to import an object from a module into the current namespace:
\begin{lstlisting}
>>> from random import randint
>>> randint(0, 9)
\end{lstlisting}
\noindent or import all objects from a module into the current namespace:
\begin{lstlisting}
>>> from random import * 
>>> randint(0, 9)
\end{lstlisting}
\noindent or import everything in a newly defined namespace:
\begin{lstlisting}
>>> import random as myrand
>>> myrand.randint(0, 9)
\end{lstlisting}

In the rest of this book, we will mainly use objects defined in modules {\ft math}, {\ft cmath}, {\ft os},  {\ft sys}, {\ft datetime}, {\ft time}, and {\ft pickle}. We will also use the {\ft random} module, but we will describe it in a later chapter.

In the following subsections, we consider those modules that are most useful.

\goodbreak\subsection{{\ft math} and {\ft cmath}}

\index{math}\index{cmath}

Here is a sampling of some of the methods available in the {\ft math} and {\ft cmath} packages:
\begin{itemize}
\item {\ft math.isinf(x)} returns true if the floating point number {\ft x} is positive or negative infinity

\item {\ft math.isnan(x)} returns true if the floating point number {\ft x} is NaN; see Python documentation or IEEE 754 standards for more information

\item {\ft math.exp(x)} returns {\ft e ** x}

\item {\ft math.log(x[, base]} returns the logarithm of {\ft x} to the optional {\ft base}; if {\ft base} is not supplied, {\ft e } is assumed

\item {\ft math.cos(x)}, {\ft math.sin(x)}, {\ft math.tan(x)} returns the cos, sin, tan of the value of {\ft x};  {\ft x} is in radians

\item {\ft math.pi}, {\ft math.e} are the constants for {\ft pi} and {\ft e} to available precision

\item {\ft math.isinf(x)} can be used to check if a number is {\it infinity}.
\end{itemize}



\goodbreak\subsection{{\ft os}}

\index{os} \index{os.path.join} \index{os.unlink}

This module provides an interface for the operating system API:
\begin{lstlisting}
>>> import os
>>> os.chdir("..")
>>> os.unlink("filename_to_be_deleted")
\end{lstlisting}

Some of the {\ft os} functions, such as {\ft chdir}, are not thread safe, for example, they should not be used in a multithreaded environment.

{\ft os.path.join} is very useful; it allows the concatenation of paths in an OS-independent way:
\begin{lstlisting}
>>> import os
>>> a = os.path.join("path", "sub_path")
>>> a
path/sub_path
\end{lstlisting}

System environment variables can be accessed via
\begin{lstlisting}
>>> os.environ
\end{lstlisting}
\noindent which is a read-only dictionary.

\goodbreak\subsection{{\ft sys}}

\index{sys} \index{sys.path}

The {\ft sys} module contains many variables and functions, but used the most is {\ft sys.path}. It contains a list of paths where Python searches for modules. When we try to import a module, Python searches the folders listed in {\ft sys.path}. If you install additional modules in some location and want Python to find them, you need to append the path to that location to {\ft sys.path}:
\begin{lstlisting}
>>> import sys
>>> sys.path.append("path/to/my/modules")
\end{lstlisting}

\goodbreak\subsection{{\ft datetime}}

\index{date} \index{datetime} \index{time}

The use of the datetime module is best illustrated by some examples:
\begin{lstlisting}
>>> import datetime
>>> datetime.datetime.today()
2008-07-04 14:03:90
>>> datetime.date.today()
2008-07-04
\end{lstlisting}

Occasionally you may need to time stamp data based on the UTC time as opposed to local time. In this case, you can use the following function:
\begin{lstlisting}
>>> import datetime
>>> datetime.datetime.utcnow()
2008-07-04 14:03:90
\end{lstlisting}

The {\ft datetime} module contains various classes: {\ft date}, {\ft datetime}, {\ft time}, and {\ft timedelta}. The difference between two dates or two datetimes or two time objects is a {\ft timedelta}:
\begin{lstlisting}
>>> a = datetime.datetime(2008, 1, 1, 20, 30)
>>> b = datetime.datetime(2008, 1, 2, 20, 30)
>>> c = b - a
>>> c.days
1
\end{lstlisting}

We can also parse dates and datetimes from strings:
\begin{lstlisting}
>>> s = "2011-12-31"
>>> a = datetime.datetime.strptime(s, "%Y-%m-%d")
>>> a.year, a.day, a.month
2011 31 12
\end{lstlisting}

Notice that ``\%Y'' matches the four-digit year, ``\%m'' matches the month as a number (1--12), ``\%d'' matches the day (1--31), ``\%H'' matches the hour, ``\%M'' matches the minute, and ``\%S'' matches the seconds. Check the Python documentation for more options.

\goodbreak\subsection{{\ft time}}

\index{time}

The time module differs from {\ft date} and {\ft datetime} because it represents time as seconds from the epoch (beginning of 1970):
\begin{lstlisting}
>>> import time
>>> t = time.time()
1215138737.571
\end{lstlisting}

Refer to the Python documentation for conversion functions between time in seconds and time as a {\ft datetime}.

\goodbreak\subsection{{\ft urllib} and {\ft json}}

\index{urllib}\index{json}

The {\ft urllib} is a module to download data or a web page from a URL:

\begin{lstlisting}
>>> import urllib.request
>>> page = urllib.request.urlopen("http://www.google.com/")
>>> html = page.read()
\end{lstlisting}

Many web services return data in JSON format. JSON is slowly replacing XML as a favorite protocol for data transfer on the web. It is lighter, simpler to use, and more human readable. JSON can be thought of as serialized JavaScript. the JSON data can be converted to a Python object using a library called {\ft json}:

\begin{lstlisting}
>>> import json
>>> a = [1, 2, 3]
>>> b = json.dumps(a)
>>> type(b)
<type 'str'>
>>> c = json.loads(b)
>>> a == c
True
\end{lstlisting}

The module {\ft json} has {\ft loads} and {\ft dumps} methods which work very much as {\ft pickle}"s methods, but they serialize the objects into a string using JSON instead of the pickle protocol.

\goodbreak\subsection{{\ft pickle}}

\index{pickle}

This is a very powerful module. It provides functions that can serialize almost any Python object, including self-referential objects. For example, let"s build a weird object:
\begin{lstlisting}
>>> class MyClass(object): pass
>>> myinstance = MyClass()
>>> myinstance.x = "something"
>>> a = [1 , 2, {"hello":"world"}, [3, 4, [myinstance]]]
\end{lstlisting}
\noindent and now:
\begin{lstlisting}
>>> import pickle
>>> b = pickle.dumps(a)
>>> c = pickle.loads(b)
\end{lstlisting}

In this example, {\ft b} is a string representation of {\ft a}, and {\ft c} is a copy of {\ft a} generated by deserializing {\ft b}.
\noindent The module {\ft pickle} can also serialize to and deserialize from a file:
\begin{lstlisting}
>>> pickle.dump(a, open("myfile.pickle", "wb"))
>>> c = pickle.load(open("myfile.pickle", "rb"))
\end{lstlisting}

\goodbreak\subsection{{\ft sqlite}}

\index{databases}\index{sqlite}\index{class!PersistentDictionary}

The Python dictionary type is very useful, but it lacks persistence because it is stored in RAM (it is lost if a program ends) and cannot be shared by more than one process running concurrently. Moreover, it is not transaction safe. This means that it is not possible to group operations together so that they succeed or fail as one.

Think for example of using the dictionary to store a bank account. The key is the account number and the value is a list of transactions. We want the dictionary to be safely stored on file. We want it to be accessible by multiple processes and applications. We want transaction safety: it should not be possible for an application to fail during a money transfer, resulting in the disappearance of money.

Python provides a module called {\ft shelve} with the same interface as {\ft dict}, which is stored on disk instead of in RAM. One problem with this module is that the file is not locked when accessed. If two processes try to access it concurrently, the data become corrupted. This module also does not provide transactional safety.

The proper alternative consists of using a database. There are two types of databases: relational databases (which normally use SQL syntax) and non-relational databases (often referred to as NoSQL). Key-value persistent storage databases usually follow under the latter category. Relational databases excel at storing structured data (in the form of tables), establishing relations between rows of those tables, and searches involving multiple tables linked by references. NoSQL databases excel at storing and retrieving schemaless data and replication of data (redundancy for fail safety).

Python comes with an embedded SQL database called SQLite~\cite{sqlite}. All data in the database are stored in one single file. It supports the SQL query language and transactional safety. It is very fast and allows concurrent read (from multiple processes), although not concurrent write (the file is locked when a process is writing to the file until the transaction is committed). Concurrent write requests are queued and executed in order when the database is unlocked.

Installing and using any of these database systems is beyond the scope of this book and not necessary for our purposes. In particular, we are not concerned with relations, data replications, and speed.

As an exercise, we are going to implement a new Python class called {\ft PersistentDictionary} that exposes an interface similar to a {\ft dict} but uses the SQLite database for storage. The database file is created if it does not exist. {\ft PersistentDictionary} will use a single table (also called {\ft persistence}) to store rows containing a key ({\ft pkey}) and a value  ({\ft pvalue}).

For later convenience, we will also add a method that can generate a UUID key. A UUID is a random string that is long enough to be, most likely, unique. This means that two calls to the same function will return different values, and the probability that the two values will be the same is negligible. Python includes a library to generate UUID strings based on a common industry standard. We use the function uuid4, which also uses the time and the IP of the machine to generate the UUID. This means the UUID is unlikely to have conflicts with (be equal to) another UUID generated on other machines. The {\ft uuid} method will be useful to generate random unique keys.

We will also add a method that allows us to search for keys in the database using GLOB patterns (in a GLOB pattern, `` * '' represents a generic wildcard and ``?'' is a single-character wildcard).

Here is the code:

\index{class!PeristentDictionary}

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
import os
import uuid
import sqlite3
import pickle
import unittest

class PersistentDictionary(object):
    """
    A sqlite based key, value storage.
    The value can be any pickleable object.
    Similar interface to Python dict
    Supports the GLOB syntax in methods keys(), items(), __delitem__()

    Usage Example:
    >>> p = PersistentDictionary(path="test.sqlite")
    >>> key = "test/" + p.uuid()
    >>> p[key] = {"a": 1, "b": 2}
    >>> p[key]
    {'a': 1, 'b': 2}
    >>> len(p.keys("test/*"))
    1
    >>> del p[key]
    """

    CREATE_TABLE = "CREATE TABLE persistence (pkey, pvalue)"
    SELECT_KEYS = "SELECT pkey FROM persistence WHERE pkey GLOB ?"
    SELECT_VALUE = "SELECT pvalue FROM persistence WHERE pkey GLOB ?"
    INSERT_KEY_VALUE = "INSERT INTO persistence(pkey, pvalue) VALUES (?, ?)"
    UPDATE_KEY_VALUE = "UPDATE persistence SET pvalue = ? WHERE pkey = ?"
    DELETE_KEY_VALUE = "DELETE FROM persistence WHERE pkey LIKE ?"
    SELECT_KEY_VALUE = "SELECT pkey, pvalue FROM persistence WHERE pkey GLOB ?"

    def __init__(self, 
                 path="persistence.sqlite", 
                 autocommit=True, 
                 serializer=pickle):
        self.path = path
        self.autocommit = autocommit
        self.serializer = serializer
        create_table = not os.path.exists(path)
        self.connection = sqlite3.connect(path)
        self.connection.text_factory = str  # do not use unicode
        self.cursor = self.connection.cursor()
        if create_table:
            self.cursor.execute(self.CREATE_TABLE)
            self.connection.commit()

    def uuid(self):
        return str(uuid.uuid4())

    def keys(self, pattern=" * "):
        "returns a list of keys filtered by a pattern, * is the wildcard"
        self.cursor.execute(self.SELECT_KEYS, (pattern,))
        return [row[0] for row in self.cursor.fetchall()]

    def __contains__(self, key):
        return True if self.get(key)!=None else False

    def __iter__(self):
        for key in self:
            yield key

    def __setitem__(self, key, value):
        if key in self:
            if value is None:
                del self[key]
            else:
                svalue = self.serializer.dumps(value)
                self.cursor.execute(self.UPDATE_KEY_VALUE, (svalue, key))
        else:
            svalue = self.serializer.dumps(value)
            self.cursor.execute(self.INSERT_KEY_VALUE, (key, svalue))
        if self.autocommit: self.connection.commit()

    def get(self, key):
        self.cursor.execute(self.SELECT_VALUE, (key,))
        row = self.cursor.fetchone()
        return self.serializer.loads(row[0]) if row else None

    def __getitem__(self, key):
        self.cursor.execute(self.SELECT_VALUE, (key,))
        row = self.cursor.fetchone()
        if not row: raise KeyError
        return self.serializer.loads(row[0])

    def __delitem__(self, pattern):
        self.cursor.execute(self.DELETE_KEY_VALUE, (pattern,))
        if self.autocommit: self.connection.commit()

    def items(self, pattern=" * "):
        self.cursor.execute(self.SELECT_KEY_VALUE, (pattern,))
        return [(row[0], self.serializer.loads(row[1])) \
                    for row in self.cursor.fetchall()]

    def dumps(self, pattern=" * "):
        self.cursor.execute(self.SELECT_KEY_VALUE, (pattern,))
        rows = self.cursor.fetchall()
        return self.serializer.dumps(dict((row[0], self.serializer.loads(row[1])) 
                                          for row in rows))
            
    def loads(self, raw):
        data = self.serializer.loads(raw)
        for key, value in data.iteritems():
            self[key] = value
\end{lstlisting}

This code now allows us to do the following:
\begin{itemize}
\item Create a persistent dictionary:
\begin{lstlisting}
>>> p = PersistentDictionary(path="storage.sqlite", autocommit=False)
\end{lstlisting}
\item Store data in it:
\begin{lstlisting}
>>> p["some/key"] = "some value"
\end{lstlisting}
where ``some/key'' must be a string and ``some value'' can be any Python pickleable object.
\item Generate a UUID to be used as the key:
\begin{lstlisting}
>>> key = p.uuid()
>>> p[key] = "some other value"
\end{lstlisting}
\item Retrieve the data:
\begin{lstlisting}
>>> data = p["some/key"]
\end{lstlisting}
\item Loop over keys:
\begin{lstlisting}
>>> for key in p: print(key, p[key])
\end{lstlisting}
\item List all keys:
\begin{lstlisting}
>>> keys = p.keys()
\end{lstlisting}
\item List all keys matching a pattern:
\begin{lstlisting}
>>> keys = p.keys("some/ * ")
\end{lstlisting}
\item List all key-value pairs matching a pattern:
\begin{lstlisting}
>>> for key, value in p.items("some/ * "): print(key, value)
\end{lstlisting}
\item Delete keys matching a pattern:
\begin{lstlisting}
>>> del p["some/ * "]
\end{lstlisting}
\end{itemize}

\goodbreak\subsection{{\ft numpy}}

The library {\ft numpy}~\cite{numpy} is the Python library for efficient arrays, multidimensional arrays, and their manipulation. {\ft numpy} does not ship with Python and must be installed separately.

On most platforms, this is as easy as typing in the Bash Shell:
\begin{lstlisting}
pip install numpy
\end{lstlisting}
Yet on other platforms, it can be a more lengthy process, and we leave it to the reader to find the best installation procedure.

The basic object in {\ft numpy} is the {\ft ndarray} ($n$-dimensional array). Here we make a $10\times 4\times 3$ array of 64 bits float:

\begin{lstlisting}
>>> import numpy
>>> a = numpy.ndarray((10, 4, 3), dtype=numpy.float64)
\end{lstlisting}

The class {\ft ndarray} is more efficient than Python"s list. It takes much less space because their elements have a fixed given type (e.g., {\ft float64}). Other popular available types are: int8, int16, int32, int64, uint8, uint16, uint32, uint64, float16, float32, float64, complex64, and complex128.

We can access elements:

\begin{lstlisting}
>>> a[0, 0, 0] = 1
>>> a[0, 0, 0]
1.0
\end{lstlisting}

We can query for its size:

\begin{lstlisting}
>>> a.shape
(10, 4, 3)
\end{lstlisting}

We can reshape its elements:

\begin{lstlisting}
>>> b = a.reshape((10, 12))
>>> a.shape
(10, 12)
\end{lstlisting}

We can map one type into another
\begin{lstlisting}
>>> c = b.astype(float32)
\end{lstlisting}

We can load and save them:

\begin{lstlisting}
>>> numpy.save("array.np", a)
>>> b = numpy.load("array.np")
\end{lstlisting}

And we can perform operations on them (most operations are element-wise operations):

\begin{lstlisting}
>>> a = numpy.array([[1, 2], [3, 4]])  # converts a list into a ndarray
>>> a
[[1 2]
 [3 4]]
>>> a+1
[[2 3]
 [4 5]]
>>> a+a
[[2 4]
 [6 8]]
>>> a * 2
[[2 4]
 [6 8]]
>>> a * a
[[ 1  4]
 [ 9 16]]
>>> numpy.exp(a)
[[  2.71828183   7.3890561 ]
 [ 20.08553692  54.59815003]]
\end{lstlisting}

The {\ft numpy} module also implements common linear algebra operations:

\begin{lstlisting}
>>> from numpy import dot
>>> from numpy.linalg import inv
>>> dot(a, a)
[[ 7 10]
 [15 22]]
>>> inv(a)
[[-2.   1. ]
 [ 1.5 -0.5]]
\end{lstlisting}

These operations are particularly efficient because they are implemented on top of the BLAS and LaPack libraries.

There are many other functions in the {\ft numpy} module, and you can read more about it in the official documentation.

\goodbreak\subsection{{\ft matplotlib}}

\index{matplotlib}\index{plot}\index{hist}\index{scatter}\index{color2d}

Library {\ft matplotlib}~\cite{matplotlib} is the de facto standard plotting library for Python. It is one of the best and most versatile plotting libraries available. It has two modes of operation. One mode of operation, called {\ft pylab}, follows a Matlab-like syntax. The other mode follows a more Python-style syntax. Here we use the latter.

You can install {\ft matplotlib} with
\begin{lstlisting}
pip install matplotlib
\end{lstlisting}
and it requires {\ft numpy}.
In {\ft matplotlib}, we need to distinguish the following objects:
\begin{itemize}
\item {\ft Figure}: a blank grid that can contain pairs of $XY$ axes
\item {\ft Axes}: a pair of $XY$ axes that may contain multiple superimposed plots
\item {\ft FigureCanvas}: a binary representation of a figure with everything that it contains
\item {\ft plot}: a representation of a data set such as a line plot or a scatter plot
\end{itemize}

In {\ft matplotlib}, a canvas can be visualized in a window or serialized into an image file. Here we take the latter approach and create two helper functions that take data and configuration parameters and output PNG images.

We start by importing {\ft matplotlib} and other required libraries:

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
import math
import cmath
import random
import os
import tempfile
os.environ["MPLCONfigureDIR"] = tempfile.mkdtemp()
\end{lstlisting}

Now we define a helper that can plot lines, points with error bars, histograms, and scatter plots on a single canvas:

\index{class!Canvas}

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
import io
from matplotlib.figure import Figure
from matplotlib.backends.backend_agg import FigureCanvasAgg
from matplotlib.patches import Ellipse

class Canvas(object):

    def __init__(self, title='', xlab="x", ylab="y", xrange=None, yrange=None):
        self.fig = Figure()
        self.fig.set_facecolor("white")
        self.ax = self.fig.add_subplot(111)
        self.ax.set_title(title)
        self.ax.set_xlabel(xlab)
        self.ax.set_ylabel(ylab)
        if xrange:
            self.ax.set_xlim(xrange)
        if yrange:
            self.ax.set_ylim(yrange)
        self.legend = []

    def save(self, filename="plot.png"):
        if self.legend:
            legend = self.ax.legend([e[0] for e in self.legend], 
                                    [e[1] for e in self.legend])
            legend.get_frame().set_alpha(0.7)
        if filename:
            FigureCanvasAgg(self.fig).print_png(open(filename, "wb"))
        else:
            s = io.StringIO()
            FigureCanvasAgg(self.fig).print_png(s)
            return s.getvalue()

    def binary(self):
        return self.save(None)

    def hist(self, data, bins=20, color="blue", legend=None):
        q = self.ax.hist(data, bins)
        #if legend:
         #    self.legend.append((q[0], legend))
        return self

    def plot(self, data, color="blue", style="-", width=2, 
             legend=None, xrange=None):
        if callable(data) and xrange:
            x = [xrange[0]+0.01 * i * (xrange[1]-xrange[0]) for i in range(0, 101)]
            y = [data(p) for p in x]
        elif data and isinstance(data[0], (int, float)):
            x, y = range(len(data)), data
        else:
            x, y = [p[0] for p in data], [p[1] for p in data]
        q = self.ax.plot(x, y, linestyle=style, linewidth=width, color=color)
        if legend:
            self.legend.append((q[0], legend))
        return self

    def errorbar(self, data, color="black", marker="o", width=2, legend=None):
        x, y, dy = [p[0] for p in data], [p[1] for p in data], [p[2] for p in data]
        q = self.ax.errorbar(x, y, yerr=dy, fmt=marker, linewidth=width, color=color)
        if legend:
            self.legend.append((q[0], legend))
        return self

    def ellipses(self, data, color="blue", width=0.01, height=0.01, legend=None):
        for point in data:
            x, y = point[:2]
            dx = point[2] if len(point)>2 else width
            dy = point[3] if len(point)>3 else height
            ellipse = Ellipse(xy=(x, y), width=dx, height=dy)
            self.ax.add_artist(ellipse)
            ellipse.set_clip_box(self.ax.bbox)
            ellipse.set_alpha(0.5)
            ellipse.set_facecolor(color)
        if legend:
            self.legend.append((q[0], legend))
        return self

    def imshow(self, data, interpolation="bilinear"):
        self.ax.imshow(data).set_interpolation(interpolation)
        return self
\end{lstlisting}

Notice we only make one set of {\ft axes}.

The argument 111 of {\ft figure.add\_subplot(111)} indicates that we want a grid of $1\times 1$ axes, and we ask for the first one of them (the only one).

The {\ft linesets} parameter is a list of dictionaries. Each dictionary must have a ``data'' key corresponding to a list of $(x, y)$ values. Each dictionary is rendered by a line connecting the points. It can have a ``label, '' a ``color, '' a ``style, '' and a ``width.''

The {\ft pointsets} parameter is a list of dictionaries. Each dictionary must have a ``data'' key corresponding to a list of $(x, y, \delta y)$ values. Each dictionary is rendered by a set of circles with error bars. It can optionally have a ``label, '' a ``color, '' and a ``marker'' (symbol to replace the circle).

The {\ft histsets} parameter is a list of dictionaries. Each dictionary must have a ``data'' key corresponding to a list of $x$ values. Each dictionary is rendered by histogram. Each dictionary can optionally have a ``label'' and a ``color.''

The {\ft ellisets} parameter is also a list of dictionaries. Each dictionary must have a ``data'' key corresponding to a list of $(x, y, \delta x, \delta y)$ values. Each dictionary is rendered by a set of ellipses, one per point. It can optionally have a ``color.''

We chose to draw all these types of plots with a single function because it is common to superimpose fitting lines to histograms, points, and scatter plots.

As an example, we can plot a parabola $3 * x ** 2	-2 * x + 5$ in the interval [-3, 3] using 100 points.

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
>>> parabola = lambda x: 3 * x ** 2 -2 * x + 5
>>> points = [(i * 3/50, parabola(i * 3/50)) for i in range(-50, 51)]
>>> Canvas(title="Parabola", xlab="x", ylab="y").plot(points).save("images/parabola.png")
\end{lstlisting}

\begin{figure}[ht]
\centering\includegraphics[width=4in]{images/parabola.png}
\caption{Example of a line plot.}
\end{figure}

Here is an example of a histogram of 1000 random gaussian points with mean 3 and standard deviation 5:

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
>>> points = [random.gauss(3, 5) for d in range(1000)]
>>> Canvas(title="Gaussian", xlab="arithmetic return", ylab="frequency").hist(points).save("images/gaussian.png")
\end{lstlisting}

\begin{figure}[ht]
\centering\includegraphics[width=4in]{images/gaussian.png}
\caption{Example of a histogram plot. Distribution of daily arithmetic returns for the APPL stock in 2011 (source: Yahoo! Finance).}
\end{figure}

Here is a scatter plot for random data points:

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
>>> from random import gauss
>>> points = [(gauss(0, 1), gauss(0, 1), gauss(0, 0.2), gauss(0, 0.2))
...           for i in range(30)]
>>> Canvas(title="example scatter plot", xrange=(-2, 2), yrange=(-2, 2)
...       ).ellipses(points).save("images/scatter.png")
\end{lstlisting}

\begin{figure}[ht]
\centering\includegraphics[width=4in]{images/scatter.png}
\caption{Example of a scatter plot using some random points.}
\end{figure}

Here is a scatter plot showing a spiral:

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
>>> points = [(r/20 * math.cos(r/20), r/20 * math.sin(r/20), 1.0, 1.0)
...           for r in range(1000)]
>>> Canvas(title="Spiral", xlab="x", ylab="y",
...        xrange=(-50, 50), yrange=(-50, 50), 
...        ).ellipses(points).save("images/spiral.png")
\end{lstlisting}

\begin{figure}[ht]
\centering\includegraphics[width=4in]{images/spiral.png}
\caption{Example of a scatter plot.}
\end{figure}

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
>>> def f(x, y): return (x-1) ** 2+(y-2) ** 2
>>> points = [[f(0.1 * i-3, 0.1 * j-3) for i in range(61)] for j in range(61)]
>>> Canvas(title="example 2d function").imshow(points).save("images/color2d.png")
\end{lstlisting}

\begin{figure}[ht]
\centering\includegraphics[width=4in]{images/color2d.png}
\caption{Example of a two-dimensional color plot using for $f(x, y)=(x-1)^2+(y-2)^2$.}
\end{figure}

The class {\ft Canvas} is both in {\ft nlib.py} and in the Python module {\ft canvas}~\cite{canvas}.


\chapter{Theory of Algorithms}

An algorithm is a step-by-step procedure for solving a problem and is typically developed before doing any programming.
The word comes from {\it algorism}, from the mathematician al-Khwarizmi, and was used to refer to the rules of performing arithmetic using Hindu--Arabic numerals and the systematic solution of equations.

In fact, algorithms are independent
of any programming language. Efficient algorithms can have a dramatic effect
on our problem-solving capabilities.

The basic steps of algorithms are loops ({\ft for}, conditionals ({\ft if}), and function calls.
Algorithms also make use of arithmetic expressions, logical expressions ({\ft not}, {\ft and}, {\ft or}), and expressions that can be reduced to the other basic components.

The issues that concern us when developing and analyzing algorithms are the following:

\begin{enumerate}
\item  Correctness: of the problem specification, of the proposed algorithm, 
and of its implementation in some programming language (we will not worry
about the third one; program verification is another subject altogether)

\item  Amount of work done: for example, running time of the algorithm in terms of
the input size (independent of hardware and programming language)

\item  Amount of space used: here we mean the amount of extra space (system resources) beyond
the size of the input (independent of hardware and programming language);
we will say that an algorithm is {\em in place} if the amount of extra space
is constant with respect to input size

\item  Simplicity, clarity: unfortunately, the simplest is not always the
best in other ways

\item  Optimality: can we prove that it does as well as or better than any other algorithm?
\end{enumerate}

\goodbreak\section{Order of growth of algorithms}

\index{order or growth}\index{$O$}\index{$\Theta$}\index{$\Omega$}\index{$o$}\index{$\omega$}

\index{sort!insertion}

The {\it insertion sort} is a simple algorithm in which an array of elements is sorted in place, one entry at a time. It is not the fastest sorting algorithm, but it is simple and does not require extra memory other than the memory needed to store the input array.

The insertion sort works by iterating. Every iteration $i$ of the insertion sort removes one element from the input data and inserts it into the correct position in the already-sorted subarray {\ft A[j]} for $0 \le j < i$. The algorithm iterates $n$ times (where $n$ is the total size of the input array) until no input elements remain to be sorted:

\begin{lstlisting}
def insertion_sort(A):
    for i in range(1, len(A)):
        for j in range(i, 0, -1):
            if A[j]<A[j-1]:
                A[j], A[j-1] = A[j-1], A[j]
            else: break
\end{lstlisting}

Here is an example:

\begin{lstlisting}
>>> import random
>>> a=[random.randint(0, 100) for k in range(20)]
>>> insertion_sort(a)
>>> a
[6, 8, 9, 17, 30, 31, 45, 48, 49, 56, 56, 57, 65, 66, 75, 75, 82, 89, 90, 99]
\end{lstlisting}

One important question is, how long does this algorithm take to run? How does its running time scale with the input size?

Given any algorithm, we can define three characteristic functions:

\begin{itemize}
\item  $T_{worst}(n)$: the running time in the worst case

\item  $T_{best}(n)$: the running time in the best case

\item  $T_{average}(n)$: the running time in the average case
\end{itemize}

The best case for an insertion sort is realized when the input is already sorted. In this case, the inner for loop exits (breaks) always at the first iteration, thus only the most outer loop is important, and this is proportional to $n$; therefore $T_{best}(n) \propto n$. The worst case for the insertion sort is realized when the input is sorted in reversed order. In this case, we can prove, and we do so subsequently, that $T_{worst}(n) \propto n^2$. For this algorithm, a statistical analysis shows that the worst case is also the average case.

Often we cannot determine exactly the running time function, but we may be able to set bounds to the running time.

We define the following sets:

\begin{itemize}
\item  $O(g(n))$: the set of functions that grow no faster than $g(n)$ when $%
n\rightarrow \infty $

\item  $\Omega (g(n))$: the set of functions that grow no slower than $g(n)$ when $%
n\rightarrow \infty $

\item  $\Theta (g(n))$: the set of functions that grow at the same rate as $g(n)$ when $%
n\rightarrow \infty $

\item  $o(g(n))$: the set of functions that grow slower than $g(n)$ when $n\rightarrow
\infty $

\item  $\omega (g(n))$: the set of functions that grow faster than $g(n)$ when $n\rightarrow \infty $
\end{itemize}

We can rewrite the preceding definitions in a more formal way:

\begin{eqnarray}
&&O(g(n))\equiv \left\{ f(n):\exists n_0, c_0, \ \forall n>n_0, \
0\leq f(n)<c_0g(n)\right\} \\
&&\Omega (g(n))\equiv \left\{ f(n):\exists n_0, c_0, \ \forall
n>n_0, \ 0\leq c_0g(n)<f(n)\right\} \\
&&\Theta (g(n))\equiv O(g(n))\cap \Omega (g(n)) \\
&&o(g(n))\equiv O(g(n))-\Omega (g(n)) \\
&&\omega (g(n))\equiv \Omega (g(n))-O(g(n))
\end{eqnarray}

We can also provide a practical rule to determine if a function $f$ belongs to one of the previous sets defined by $g$.

Compute the limit
\begin{equation}
\lim_{n\rightarrow \infty }\frac{f(n)}{g(n)}=a
\end{equation}
and look up the result in the following table:

\begin{equation}
\begin{tabular}{lll}
$a$ is positive or zero & $\Longrightarrow $ & $f(n)\in O(g(n))$ $%
\Leftrightarrow $ $f\preceq g$ \\
$a$ is positive or infinity & $\Longrightarrow $ & $f(n)\in \Omega (g(n))$ $%
\Leftrightarrow $ $f\succeq g$ \\
$a$ is positive & $\Longrightarrow $ & $f(n)\in \Theta (g(n))$ $%
\Leftrightarrow $ $f\sim g$ \\
$a$ is zero & $\Longrightarrow $ & $f(n)\in o(g(n))$ $\Leftrightarrow $ $%
f\prec g$ \\
$a$ is infinity & $\Longrightarrow $ & $f(n)\in \omega (g(n))$ $%
\Leftrightarrow $ $f\succ g$%
\end{tabular}
\end{equation}

Notice the preceding practical rule assumes the limits exist.

Here is an example:

Given $f(n) = n\log n+3n$ and $g(n) = n^2$
\begin{equation}
\lim_{n\rightarrow \infty }\frac{n\log n+3n}{n^2}\stackrel{l^{\prime }Hopital%
}{\longrightarrow }\lim_{n\rightarrow \infty }\frac{1/n}2=0
\end{equation}
we conclude that $n\log n+3n$ is in $O(n^2)$.



Given an algorithm $A$ that acts on input of size $n$, we say that the algorithm is $O(g(n))$ if its worst running time as a function of $n$ is in $O(g(n))$. Similarly, we say that the algorithm is in $\Omega(g(n))$ if its best running time is in $\Omega(g(n))$. We also say that the algorithm is in $ \Theta(g(n))$ if both its best running time and its worst running time are in  $\Theta(g(n))$.

More formally, we can write the following:

\begin{eqnarray}
T_{worst}(n) \in O(g(n)) &\Rightarrow& A \in O(g(n)) \\
T_{best}(n) \in \Omega(g(n)) &\Rightarrow& A \in \Omega(g(n)) \\
A \in O(g(n)) \textrm{and} A \in O(g(n))  &\Rightarrow& A \in \Theta(g(n)) \\
\end{eqnarray}

We still have not solved the problem of computing the best, average, and worst running times.

\goodbreak\subsection{Best and worst running times}

The procedure for computing the worst and best running times is similar. It is simple in theory but difficult in practice because it requires an understanding of the algorithm"s inner workings.

Consider the following algorithm, which finds the minimum of an array or list A:
\begin{lstlisting}
def find_minimum(A):
    minimum = a[0]
    for element in A:
        if element < minimum:
            minimum = element
    return minimum
\end{lstlisting}


To compute the running time in the worst case, we assume that the maximum number of computations is performed. That happens when the if statements are always {\ft True}. To compute the best running time, we assume that the minimum number of computations is performed. That happens when the if statement is always {\ft False}.
Under each of the two scenarios, we compute the running time by counting how many times the most nested operation is performed.

In the preceding algorithm, the most nested operation is the evaluation of the {\ft if} statement, and that is executed for each element in {\ft A}; for example, assuming {\ft A} has $n$ elements, the {\ft if} statement will be executed $n$ times.

Therefore both the best and worst running times are proportional to $n$, thus making this algorithm $O(n)$, $\Omega(n)$, and $\Theta(n)$.

More formally, we can observe that this algorithm performs the following operations:

\begin{itemize}
\item  One assignment (line 2)

\item  Loops $n=${\ft len(A)} times (line 3)

\item  For each loop iteration, performs one comparison (line 4)

\item  Line 5 is executed only if the condition is true
\end{itemize}

Because there are no nested loops, the time to execute each loop iteration is about the same, and the running time is proportional to the number of loop iterations.

For a loop iteration that does not contain further loops, the time it takes to compute each iteration, its {\ft running time}, is constant (therefore equal to 1). For algorithms that contain nested loops, we will have to evaluate nested sums.

Here is the simplest example:

\begin{lstlisting}
def loop0(n):
    for i in range(0, n):
        print(i)
\end{lstlisting}

which we can map into

\begin{equation}
T(n)=\sum_{i=0}^{i<n}1=n\in \Theta (n)\Rightarrow \text{{\ft loop0}}\in
\Theta (n)
\end{equation}

Here is a similar example where we have a single loop (corresponding to a single sum) that loops $n^2$ times:

\begin{lstlisting}
def loop1(n):
    for i in range(0, n * n):
        print(i)
\end{lstlisting}

and here is the corresponding running time formula:

\begin{equation}
T(n)=\sum_{i=0}^{i<n^2}1=n^2\in \Theta (n^2)\Rightarrow \text{{\tt loop1}}%
\in \Theta (n^2)
\end{equation}

The following provides an example of nested loops:

\begin{lstlisting}
def loop2(n):
    for i in range(0, n):
        for j in range(0, n):
            print(i, j)
\end{lstlisting}

Here the time for the inner loop is directly determined by $n$ and does not depend on the outer loop"s counter; therefore

\begin{equation}
T(n)=\sum_{i=0}^{i<n}\sum_{j=0}^{j<n}1=\sum_{i=0}^{i<n}n=n^2+...\in \Theta
(n^2)\Rightarrow \text{{\tt loop2}}\in \Theta (n^2)
\end{equation}

This is not always the case. In the following code, the inner loop does depend on the value of the outer loop:

\begin{lstlisting}
def loop3(n):
    for i in range(0, n):
        for j in range(0, i):
            print(i, j)
\end{lstlisting}

Therefore, when we write its running time in terms of a sum, care must be taken that the upper limit of the inner sum is the upper limit of the outer sum:

\begin{equation}
T(n)=\sum_{i=0}^{i<n}\sum_{j=0}^{j<i}1=\sum_{i=0}^{i<n}i=\frac 12n(n-1)\in
\Theta (n^2)\Rightarrow \text{{\tt loop3}}\in \Theta (n^2)
\end{equation}

The appendix of this book provides examples of typical sums that come up in these types of formulas and their solutions.

Here is one more example falling in the same category, although the inner loop depends quadratically on the index of the outer loop:

\subsubsection{Example: loop4}
\begin{lstlisting}
def loop4(n):
    for i in range(0, n):
        for j in range(0, i * i):
            print(i, j)
\end{lstlisting}

Therefore the formula for the running time is more complicated:

\begin{eqnarray}
T(n) &=&\sum_{i=0}^{i<n}\sum_{j=0}^{j<i^2}1=\sum_{i=0}^{i<n}i^2=\frac
16n(n-1)(2n-1)\in \Theta (n^3) \\
&\Rightarrow &\text{{\tt loop4}}\in \Theta (n^3)
\end{eqnarray}

If the algorithm does not contain nested loops, then we need to compute the running time of each loop and take the maximum:

\subsubsection{Example: concatenate0}
\begin{lstlisting}
def concatenate0(n):
    for i in range(n * n):
        print(i)
    for j in range(n * n * n):
        print(j)
\end{lstlisting}

\begin{equation}
T(n)=\Theta (\max (n^2, n^3))\Rightarrow \text{{\tt concatenate0}}\in \Theta
(n^3)
\end{equation}

If there is an if statement, we need to compute the running time for each condition and pick the maximum when computing the worst running time, or the minimum for the best running time:

\begin{lstlisting}
def concatenate1(n):
    if a<0:
        for i in range(n * n):
            print(i)
    else:
        for j in range(n * n * n):
            print(j)
\end{lstlisting}

\begin{equation}
T_{worst}(n)=\Theta (\max (n^2, n^3))\Rightarrow \text{{\tt concatenate1}}\in \O(n^3)
\end{equation}

\begin{equation}
T_{best}(n)=\Theta (\min (n^2, n^3))\Rightarrow \text{{\tt concatenate1}}\in \Omega(n^2)
\end{equation}

This can be expressed more formally as follows:

\begin{eqnarray}
O(f(n))+\Theta (g(n)) &=&\Theta (g(n))\text{ iff }f(n)\in O(g(n)) \\
\Theta (f(n))+\Theta (g(n)) &=&\Theta (g(n))\text{ iff }f(n)\in O(g(n)) \\
\Omega (f(n))+\Theta (g(n)) &=&\Omega (f(n))\text{ iff }f(n)\in \Omega (g(n))
\end{eqnarray}

which we can apply as in the following example:
\begin{equation}
T(n)=[\stackunder{\Theta (n^2)}{\underbrace{n^2+n+3}}+\stackunder{\Theta
(e^n)}{\underbrace{e^n-\log n}}]\in \Theta (e^n)\text{ because }n^2\in
O(e^n)
\end{equation}

\goodbreak\section{Recurrence relations}

\index{recurrence relations}\index{mergesort}

\index{sort!merge}

The {\it merge sort}~\cite{mergesort} is another sorting algorithm. It is faster than the insertion sort. It was invented by John von Neumann, the physicist credited for inventing also modern computer architecture and game theory.

The merge sort works as follows.

If the input array has length 0 or 1, then it is already sorted, and the algorithm does not perform any other operation.

If the input array has a length greater than 1, it divides the array into two subsets of about half the size. Each subarray is sorted by applying the merge sort recursively (it calls itself!). It then merges the two subarrays back into one sorted array (this step is called {\it merge}).

Consider the following Python implementation of the merge sort:

\begin{lstlisting}
def mergesort(A, p=0, r=None):
    if r is None: r = len(A)
    if p<r-1:
        q = int((p+r)/2)
        mergesort(A, p, q)
        mergesort(A, q, r)
        merge(A, p, q, r)

def merge(A, p, q, r):
    B, i, j = [], p, q
    while True:
        if A[i]<=A[j]:
            B.append(A[i])
            i=i+1
        else:
            B.append(A[j])
            j=j+1
        if i == q:
            while j<r:
                B.append(A[j])
                j=j+1
            break
        if j == r:
            while i<q:
                B.append(A[i])
                i=i+1
            break
    A[p:r]=B
\end{lstlisting}

\index{recursion}

Because this algorithm calls itself {\it recursively}, it is more difficult to compute its running time.

Consider the {\ft merge} function first. At each step, it increases either $i$ or $j$, where $i$ is always in between $p$ and $q$ and $j$ is always in between $q$ and $r$. This means that the running time of the merge is proportional to the total number of values they can span from $p$ to $r$. This implies that
\begin{equation}
\textrm{merge} \in \Theta(r-p)
\end{equation}

We cannot compute the running time of the {\ft mergesort} function using the same direct analysis, but we can assume its running time is $T(n)$, where $n=r-p$ and $n$ is the size of the input data to be sorted and also the difference between its two arguments $p$ and $r$. We can express this running time in terms of its components:
\begin{itemize}
\item It calls itself twice on half of the input data, $2T(n/2)$
\item It calls the merge once on the entire data, $\Theta(n)$
\end{itemize}

We can summarize this into

\begin{eqnarray}
T(n) = 2T(n/2) + n
\end{eqnarray}

This is called a {\it recurrence relation}. We turned the problem of computing the running time of the algorithm into the problem of solving the recurrence relation. This is now a math problem.

Some recurrence relations can be difficult to solve, but most of them follow in one of these categories:

\begin{eqnarray}
T(n) \!\!\!\!\!&=&\!\!\!\!\!aT(n-b)+\Theta (f(n))\Rightarrow T\!\in\! \Theta (max(a^n, nf(n))) \\
T(n) \!\!\!\!\!&=&\!\!\!\!\!T(b)+T(n-b-a)+\Theta(f(n))\Rightarrow T\!\in\! \Theta (nf(n)) \\
T(n) \!\!\!\!\!&=&\!\!\!\!\!aT(n/b)+\Theta (n^m)\land a<b^m\Rightarrow T\!\in\! \Theta (n^m) \\
T(n) \!\!\!\!\!&=&\!\!\!\!\!aT(n/b)+\Theta (n^m)\land a=b^m\Rightarrow T\!\in\! \Theta
(n^m\log n) \\
T(n) \!\!\!\!\!&=&\!\!\!\!\!aT(n/b)+\Theta (n^m)\land a>b^m\Rightarrow T\!\in\! \Theta
(n^{\log _ba}) \\
T(n) \!\!\!\!\!&=&\!\!\!\!\!aT(n/b)+\Theta (n^m\log ^pn)\land a<b^m\Rightarrow T\!\in\!
\Theta (n^m\log ^pn) \\
T(n) \!\!\!\!\!&=&\!\!\!\!\!aT(n/b)+\Theta (n^m\log ^pn)\land a=b^m\Rightarrow T\!\in\!
\Theta (n^m\log ^{p+1}n) \\
T(n) \!\!\!\!\!&=&\!\!\!\!\!aT(n/b)+\Theta (n^m\log ^pn)\land a>b^m\Rightarrow T\!\in\!
\Theta (n^{\log _ba}) \\
T(n) \!\!\!\!\!&=&\!\!\!\!\!aT(n/b)+\Theta (q^n)\Rightarrow T\!\in\! \Theta (q^n) \\
T(n) \!\!\!\!\!&=&\!\!\!\!\!aT(n/a-b)+\Theta (f(n)) \Rightarrow T\!\in\! \Theta (f(n)\log(n))
\end{eqnarray}
(they work for $m\geq 0$, $p$ $\geq 0$, and $q>1$).

\index{master theorem}

These results are a practical simplification of a theorem known as the {\it master theorem}~\cite{mastertheorem}.

\goodbreak\subsection{Reducible recurrence relations}

Other recurrence relations do not immediately fit one of the preceding patterns, but often they can be reduced (transformed) to fit.

Consider the following recurrence relation:
\begin{equation}
T(n)=
2T(\sqrt{n})+\log n
\label{otherrr}
\end{equation}

We can replace $n$ with $e^k=n$ in eq. (\ref{otherrr}) and obtain
\begin{equation}
T(e^k)=
2T(e^{k/2})+k
\end{equation}
If we also replace $T(e^k)$ with $S(k)=T(e^k)$, we obtain
\begin{equation}
\stackunder{T(e^k)}{\underbrace{S(k)}}=
2\stackunder{T(e^{k/2})}{\underbrace{S(k/2)}}+k
\end{equation}
so that we can now apply the master theorem to $S$. We obtain that $S(k)\in
\Theta (k\log k)$. Once we have the order of growth of $S$, we can determine
the order of growth of $T(n)$ by substitution:

\begin{equation}
T(n)=S(\log n)\in \Theta (\stackunder{k}{\underbrace{\log n}}\log
\stackunder{k}{\underbrace{\log n}})
\end{equation}

Note that there are recurrence relations that cannot be solved with any of
the methods described.

Here are some examples of recursive algorithms and their corresponding recurrence relations with solution:

\begin{lstlisting}
def factorial1(n):
    if n == 0:
        return 1
    else:
        return n * factorial1(n-1)
\end{lstlisting}

\begin{equation}
T(n)=T(n-1)+1\Rightarrow T(n)\in \Theta (n)\Rightarrow \text{{\tt factorial1}%
}\in \Theta (n)
\end{equation}

\begin{lstlisting}
def recursive0(n):
    if n == 0:
        return 1
    else:
        loop3(n)
        return n * n * recursive0(n-1)
\end{lstlisting}

\begin{equation}
T(n)=T(n-1)+P_2(n)\Rightarrow T(n)\in \Theta (n^2)\Rightarrow \text{{\tt %
recursive0}}\in \Theta (n^3)
\end{equation}

\begin{lstlisting}
def recursive1(n):
    if n == 0:
        return 1
    else:
        loop3(n)
        return n * recursive1(n-1) * recursive1(n-1)
\end{lstlisting}

\begin{equation}
T(n)=2T(n-1)+P_2(n)\Rightarrow T(n)\in \Theta (2^n)\Rightarrow \text{{\tt %
recursive1}}\in \Theta (2^n)
\end{equation}

\begin{lstlisting}
def recursive2(n):
    if n == 0:
        return 1
    else:
        a=factorial0(n)
        return a * recursive2(n/2) * recursive1(n/2)
\end{lstlisting}

\begin{equation}
T(n) = 2 T(n/2) + P_1(n) \Rightarrow T(n)\in \Theta (n\log n)\Rightarrow \text{%
{\tt recursive2}}\in \Theta (n\log n)
\end{equation}

One example of practical interest for us is the binary search below. It finds the location of the element in a sorted input array $A$:

\begin{lstlisting}
def binary_search(A, element):
    a, b = 0, len(A)-1
    while b>=a:
        x = int((a+b)/2)
        if A[x]<element:
            a = x+1
        elif A[x]>element:
            b = x-1
        else:
            return x
    return None
\end{lstlisting}

Notice that this algorithm does not appear to be recursive, but in practice, it is because of the apparently infinite while loop. The content of the while loop runs in constant time and then loops again on a problem of half of the original size:

\begin{equation}
T(n)=T(n/2)+1\Rightarrow \text{{\tt binary\_search}}\in \Theta(\log n)
\end{equation}

The idea of the {\ft binary\_search} is used in the bisection method for solving nonlinear equations.

Do not confuse {\ft T} notation with $\Theta$ notation:

\begin{table}
\begin{tabular}{|l|l|l|}\hline
Algorithm & Recurrence Relationship & Running time \\ \hline
Binary Search & $T(n) = T(\frac n 2) + \Theta (1)$ & $\Theta(log(n))$ \\ \hline
Binary Tree Traversal & $T(n) = 2T(\frac n 2) + \Theta (1)$ & $\Theta(n)$ \\ \hline
Optimal Sorted Matrix Search & $T(n) = 2T(\frac n 2) + \Theta (log(n))$ & $\Theta(n)$ \\ \hline
Merge Sort & $T(n) = T(\frac n 2) + \Theta (n)$ & $\Theta(n log(n))$ \\ \hline
\end{tabular}
\label{table1}
\end{table}

The theta notation can also be used to describe the memory used by an algorithm as a function of the input, $T_{memory}$, as well as its running time.

\goodbreak\section{Types of algorithms}

\index{divide and conquer}

{\bf Divide-and-conquer}
\index{divide and conquer} is a method of designing algorithms that
(informally) proceeds as follows: given an instance of the problem to be
solved, split this into several, smaller sub-instances (of the same
problem), independently solve each of the sub-instances and then combine the
sub-instance solutions to yield a solution for the original instance.
This description raises the question, by what methods are the sub-instances
to be independently solved? The answer to this question is central to the
concept of the divide-and-conquer algorithm and is a key factor in gauging
their efficiency. The solution is unique for each problem.

The merge sort algorithm of the previous section is an example of a divide-and-conquer algorithm. In the merge sort, we sort an array by dividing it into two arrays and recursively sorting (conquering) each of the smaller arrays.

Most divide-and-conquer algorithms are recursive, although this is not a requirement.

{\bf Dynamic programming}
\index{dynamic programming}
is a paradigm that is most often applied in the
construction of algorithms to solve a certain class of optimization
problems, that is, problems that require the minimization or maximization of
some measure. One disadvantage of using divide-and-conquer is that the
process of recursively solving separate sub-instances can result in the same
computations being performed repeatedly because identical sub-instances may
arise. For example, if you are computing the path between two nodes in a graph, 
some portions of multiple paths will follow the same last few hops. Why compute
the last few hops for every path when you would get the same result every time?

The idea behind dynamic programming is to avoid this pathology by
obviating the requirement to calculate the same quantity twice. The method
usually accomplishes this by maintaining a table of sub-instance results. We
say that dynamic programming is a bottom-up technique in which the smallest
sub-instances are explicitly solved first and the results of these are used to
construct solutions to progressively larger sub-instances. In contrast, we
say that the divide-and-conquer is a top-down technique.


We can refactor the {\ft mergesort} algorithm to eliminate recursion in the algorithm implementation, while keeping the logic of the algorithm unchanged. Here is a possible implementation:
\begin{lstlisting}
def mergesort_nonrecursive(A):
    blocksize, n = 1, len(A)
    while blocksize<n:
        for p in range(0, n, 2 * blocksize):
            q = p+blocksize
            r = min(q+blocksize, n)
            if r>q:
                Merge(A, p, q, r)
        blocksize = 2 * blocksize
\end{lstlisting}

Notice that this has the same running time as the original {\ft mergesort} because, although it is not recursive, it performs the same operations:

\begin{eqnarray}
T_{best} &\in &\Theta (n\log n) \\
T_{average} &\in &\Theta (n\log n) \\
T_{worst} &\in &\Theta (n\log n) \\
T_{memory} &\in &\Theta (1)
\end{eqnarray}

\index{greedy algorithms}

{\bf Greedy algorithms}
\index{greedy algorithms} work in phases. In each phase, a decision is made
that appears to be good, without regard for future consequences. Generally, 
this means that some local optimum is chosen. This ``take what you can get
now'' strategy is the source of the name for this class of algorithms. When
the algorithm terminates, we hope that the local optimum is equal to the
global optimum. If this is the case, then the algorithm is correct;
otherwise, the algorithm has produced a suboptimal solution. If the best
answer is not required, then simple greedy algorithms are sometimes used to
generate approximate answers, rather than using the more complicated
algorithms generally required to generate an exact answer. Even for problems
that can be solved exactly by a greedy algorithm, establishing the
correctness of the method may be a nontrivial process.

For example, computing change for a purchase in a store is a good case of a greedy algorithm.  Assume you need to give change back for a purchase.  You would have three choices:
\begin{itemize}
\item Give the smallest denomination repeatedly until the correct amount is returned

\item Give a random denomination repeatedly until you reach the correct amount. If a random choice exceeds the total, then pick another denomination until the correct amount is returned

\item Give the largest denomination less than the amount to return repeatedly until the correct amount is returned
\end{itemize}

In this case, the third choice is the correct one.

Other types of algorithms do not fit into any of the preceding
categories. One is, for example, backtracking. Backtracking is not covered
in this course.

\goodbreak\subsection{Memoization}

\index{memoization}

One case of a top-down approach that is very general and falls under the umbrella of dynamic programming is called {\it memoization}. Memoization consists of allowing users to write algorithms using a naive divide-and-conquer approach, but functions that may be called more than once are modified so that their output is cached, and if they are called again with the same initial state, instead of the algorithm running again, the output is retrieved from the cache and returned without any computations.

\index{Fibonacci series}

Consider, for example, Fibonacci numbers:

\begin{eqnarray}
\textrm{Fib}(0)&=&0\\
\textrm{Fib}(1)&=&1\\
\textrm{Fib}(n)&=&\textrm{Fib}(n-1)+\textrm{Fib}(n-2)\textrm{ for }n>1
\end{eqnarray}

which we can implement using divide-and-conquer as follows:

\begin{lstlisting}
def fib(n):
    return n if n<2 else fib(n-1)+fib(n-2)
\end{lstlisting}

The recurrence relation for this algorithm is $T(n)=T(n-1)+T(n-2)+1$, and its solution can be proven to be exponential. This is because this algorithm calls itself more than necessary with the same input values and keeps solving the same subproblem over and over.

\index{class!Memoize}

Python can implement memoization using the following decorator:
%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
class memoize(object):
    def __init__ (self, f):
        self.f = f
        self.storage = {}
    def __call__ (self, * args, ** kwargs):
        key = str((self.f.__name__, args, kwargs))
        try:
            value = self.storage[key]
        except KeyError:
            value = self.f( * args, ** kwargs)
            self.storage[key] = value
        return value
\end{lstlisting}

and simply decorating the recursive function as follows:

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
@memoize
def fib(n):
    return n if n<2 else fib(n-1)+fib(n-2)
\end{lstlisting}

which we can call as

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
>>> fib(11)
89
\end{lstlisting}

A decorator is a Python function that takes a function and returns a callable object (or a function) to replace the one passed as input. In the previous example, we are using the {\ft @memoize} decorator to replace the {\ft fib} function with the {\ft \_\_call\_\_} argument of the {\ft memoize} class.

This makes the algorithm run much faster. Its running time goes from exponential to linear. Notice that the preceding {\ft memoize} decorator is very general and can be used to decorate any other function.

One more direct
dynamic programming approach consists in removing the recursion:

\begin{lstlisting}
def fib(n):
    if n < 2: return n
    a, b = 0, 1
    for i in range(1, n):
        a, b = b, a+b
    return b
\end{lstlisting}

This also makes the algorithm linear and $T(n) \in \Theta(n)$.

\index{memoize\_persistent}

Notice that we easily modify the memoization algorithm to store the partial results in a shared space, for example, on disk using the {\ft PersistentDictionary}:

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
class memoize_persistent(object):
    STORAGE = "memoize.sqlite"
    def __init__ (self, f):
        self.f = f
        self.storage = PersistentDictionary(memoize_persistent.STORAGE)
    def __call__ (self, * args, ** kwargs):
        key = str((self.f.__name__, args, kwargs))
        if key in self.storage:
            value = self.storage[key]
        else:
            value = self.f( * args, ** kwargs)
            self.storage[key] = value
        return value
\end{lstlisting}

We can use it as we did before, but we can now start and stop the program or run concurrent parallel programs, and as long as they have access to the ``memoize.sqlite'' file, they will share the cache.


\goodbreak\section{Timing algorithms}

The order of growth is a theoretical concept. In practice, we need to time algorithms to check if findings are correct and, more important, to determine the magnitude of the constants in the $T$ functions.

For example, consider this:
\begin{lstlisting}
def f1(n):
    return sum(g1(x) for x in range(n))

def f2(n):
    return sum(g2(x) for x in range(n ** 2))
\end{lstlisting}


Since {\ft f1} is $\Theta(n)$ and {\ft f2} is $\Theta(n^2)$, we may be led to conclude that the latter is slower. It may very well be that {\ft g1} is $10^6$ smaller than {\ft g2} and therefore $T_{f1}(n) = c_1 n$, $T_{f2}(n) = c_2 n^2$, but if $c_1 = 10^6 c_2$, then $T_{f1}(n) > T_{f2}(n)$ when $n<10^6$.

To time functions in Python, we can use this simple algorithm:

%%% META:FILE:nlib.py
\begin{lstlisting}
import time

def timef(f, ns=1000, dt = 60):
    t = t0 = time.time()
    for k in range(1, ns):
        f()
        t = time.time()
        if t - t0 > dt: break
    return (t - t0) / k
\end{lstlisting}

This function calls and averages the running time of {\ft f()} for the minimum between {\ft ns=1000} iterations and {\ft dt=60} seconds.

It is now easy, for example, to time the fib function without memoize, 
\begin{lstlisting}
>>> def fib(n):
...     return n if n<2 else fib(n-1)+fib(n-2)
>>> for k in range(15, 20):
...     print(k, timef(lambda:fib(k)))
15 0.000315684575338
16 0.000576375363706
17 0.000936052104732
18 0.00135168084153
19 0.00217730337912
\end{lstlisting}
and with memoize, 
\begin{lstlisting}
>>> @memoize
... def fib(n):
...     return n if n<2 else fib(n-1)+fib(n-2)
>>> for k in range(15, 20):
...     print(k, timef(lambda:fib(k)))
15 4.24022311802e-06
16 4.02901146386e-06
17 4.21922128122e-06
18 4.02495429084e-06
19 3.73784963552e-06
\end{lstlisting}

The former shows an exponential behavior; the latter does not.

\goodbreak\section{Data structures}

\goodbreak\subsection{Arrays}

An array is a data structure in which a series of numbers are stored contiguously in memory. The time to access each number (to read or write it) is constant. The time to remove, append, or insert an element may require moving the entire array to a more spacious memory location, and therefore, in the worst case, the time is proportional to the size of the array.

Arrays are the appropriate containers when the number of elements does not change often and when elements have to be accessed in random order.

\goodbreak\subsection{List}

A list is a data structure in which data are not stored contiguously, and each element has knowledge of the location of the next element (and perhaps of the previous element, in a doubly linked list). This means that accessing any element for (read and write) requires finding the element and therefore looping. In the worst case, the time to find an element is proportional to the size of the list. Once an element has been found, any operation on the element, including read, write, delete, and insert, before or after can be done in constant time.

Lists are the appropriate choice when the number of elements can vary often and when their elements are usually accessed sequentially via iterations.

In Python, what is called a {\ft list} is actually an array of pointers to the elements.

\goodbreak\subsection{Stack}

\index{stack}\index{push}\index{pop}

A stack data structure is a container, and it is usually implemented as a list. It has the property that the first thing you can take out is the last thing put in. This is commonly known as last-in, first-out, or LIFO. The method to insert or add data to the container is called {\it push}, and the method to extract data is called {\it pop}.

In Python, we can implement push by appending an item at the end of a list (Python already has a method for this called {\ft .append}), and we can implement pop by removing the last element of a list and returning it (Python has a method for this called {\ft .pop}).

A simple stack example is as follows:

\begin{lstlisting}
>>> stk = []
>>> stk.append("One")
>>> stk.append("Two")
>>> stk.pop()
Two
>>> stk.append("Three")
>>> stk.pop()
Three
>>> stk.pop()
One
\end{lstlisting}


\goodbreak\subsection{Queue}

A queue data structure is similar to a stack but, whereas the stack returns the most recent item added, a queue returns the oldest item in the list.  This is commonly called first-in, first-out, or FIFO.  To use Python lists to implement a queue, insert the element to add in the first position of the list as follows:

\begin{lstlisting}
>>> que = []
>>> que.insert(0, "One")
>>> que.insert(0, "Two")
>>> que.pop()
One
>>> que.insert(0, "Three")
>>> que.pop()
Two
>>> que.pop()
Three
\end{lstlisting}

Lists in Python are not an efficient mechanism for implementing queues.  Each insertion or removal of an element at the front of a list requires all the elements in the list to be shifted by one. The Python package {\ft collections.deque} is designed to implement queues and stacks.  For a stack or queue, you use the same method {\ft .append} to add items.  For a stack, {\ft .pop} is used to return the most recent item added, while to build a queue, use {\ft .popleft} to remove the oldest item in the list:

\begin{lstlisting}
>>> from collections import deque
>>> que = deque([])
>>> que.append("One")
>>> que.append("Two")
>>> que.popleft()
One
>>> que.append("Three")
>>> que.popleft()
Two
>>> que.popleft()
Three
\end{lstlisting}


\goodbreak\subsection{Sorting}

\index{sort!quicksort}

In the previous sections, we have seen the {\it insertion sort} and the {\it merge sort}. Here we consider, as examples, other sorting algorithms: the {\it quicksort}~\cite{mergesort}, the {\it randomized quicksort}, and the {\it counting sort}:

\begin{lstlisting}
def quicksort(A, p=0, r=-1):
    if r is -1:
        r=len(A)
    if p<r-1:
        q=partition(A, p, r)
        quicksort(A, p, q)
        quicksort(A, q+1, r)

def partition(A, i, j):
    x=A[i]
    h=i
    for k in range(i+1, j):
        if A[k]<x:
            h=h+1
            A[h], A[k] = A[k], A[h]
    A[h], A[i] = A[i], A[h]
    return h
\end{lstlisting}

The running time of the quicksort is given by

\begin{eqnarray}
T_{best} &\in &\Theta (n\log n) \\
T_{average} &\in &\Theta (n\log n) \\
T_{worst} &\in &\Theta (n^2) \\
\end{eqnarray}

The quicksort can also be randomized by picking the pivot, {\ft A[r]}, at random:
\begin{lstlisting}
def quicksort(A, p=0, r=-1):
    if r is -1:
        r=len(A)
    if p<r-1:
        q = random.randint(p, r-1)
        A[p], A[q] = A[q], A[p]
        q=partition(A, p, r)
        quicksort(A, p, q)
        quicksort(A, q+1, r)
\end{lstlisting}

In this case, the best and the worst running times do not change, but the average improves when the input is already almost sorted.

\index{sort!countingsort}

The {\it counting sort} algorithm is special because it only works for arrays of positive integers. This extra requirement allows it to run faster than other sorting algorithms, under some conditions. In fact, this algorithm is linear in the range span by the elements of the input array.

Here is a possible implementation:
\begin{lstlisting}
def countingsort(A):
    if min(A)<0:
        raise "_counting_sort List Unbound"
    i, n, k = 0, len(A), max(A)+1
    C = [0] * k
    for j in range(n):
        C[A[j]] = C[A[j]]+1
    for j in range(k):
        while C[j]>0:
           (A[i], C[j], i) = (j, C[j]-1, i+1)
\end{lstlisting}

If we define $k=max(A)-min(A)+1$ and $n=len(A)$, we see
\begin{eqnarray}
T_{best} &\in &\Theta (k+n) \\
T_{average} &\in &\Theta (k+n) \\
T_{worst} &\in &\Theta (k+n) \\
T_{memory} &\in &\Theta (k)
\end{eqnarray}
Notice that here we have also computed $T_{memory}$, for example, the order of growth of memory (not of time) as a function of the input size. In fact, this algorithm differs from the previous ones because it requires a temporary array $C$.

\goodbreak\section{Tree algorithms}

\index{trees}

\goodbreak\subsection{Heapsort and priority queues}

\index{heap}\index{sort!heapsort}\index{priority queue}

Consider a {\it complete binary tree} as the one in the following figure:

\begin{figure}[ht]
\centering\includegraphics[width=4in]{images/heap.png}
\caption{Example of a heap data structure. The number represents not the data in the heap but the numbering of the nodes.}
\end{figure}

It starts from the top node, called the {\it root}. Each node has zero, one, or two children. It is called complete because nodes have been added from top to bottom and left to right, filling available slots. We can think of each level of the tree as a generation, where the older generation consists of one node, the next generation of two, the next of four, and so on. We can also number nodes from top to bottom and left to right, as in the image. This allows us to map the elements of a complete binary tree into the elements of an array.

We can implement a complete binary tree using a list, and the child--parent relations are given by the following formulas:
\begin{lstlisting}
def heap_parent(i):
    return int((i-1)/2)

def heap_left_child(i):
    return 2 * i+1

def heap_right_child(i):
    return 2 * i+2
\end{lstlisting}

We can store data (e.g., numbers) in the nodes (or in the corresponding array). If the data are
stored in such a way that the value at one node is always greater or equal than the value at its children, the array is called a {\it heap} and also a {\it priority queue}.

First of all, we need an algorithm to convert a list into a heap:

\begin{lstlisting}
def heapify(A):
    for i in range(int(len(A)/2)-1, -1, -1):
        heapify_one(A, i)

def heapify_one(A, i, heapsize=None):
    if heapsize is None:
        heapsize = len(A)
    left = 2 * i+1
    right = 2 * i+2
    if left<heapsize and A[left]>A[i]:
        largest = left
    else:
        largest = i
    if right<heapsize and A[right]>A[largest]:
        largest = right
    if largest!=i:
        (A[i], A[largest]) = (A[largest], A[i])
        heapify_one(A, largest, heapsize)
\end{lstlisting}

Now we can call {\ft build\_heap} on any array or list and turn it into a heap.
Because the first element is by definition the smallest, we can use the heap to sort numbers in three steps:
\begin{itemize}
\item We turn the array into a heap
\item We extract the largest element
\item We apply recursion by sorting the remaining elements
\end{itemize}
Instead of using the preceding divide-and-conquer approach, it is better to use a dynamic programming approach. When we extract the largest element, we swap it with the last element of the array and make the heap one element shorter. The new, shorter heap does not need a full {\ft build\_heap} step because the only element out of order is the root node. We can fix this by a single call to {\ft heapify}.

This is a possible implementation for the {\ft heapsort}~\cite{heapsort}:

\begin{lstlisting}
def heapsort(A):
    heapify(A)
    n = len(A)
    for i in range(n-1, 0, -1):
        (A[0], A[i]) = (A[i], A[0])
        heapify_one(A, 0, i)
\end{lstlisting}

In the average and worst cases, it runs as fast as the quicksort, but in the best case, it is linear:

\begin{eqnarray}
T_{best} &\in &\Theta (n) \\
T_{average} &\in &\Theta (n\log n) \\
T_{worst} &\in &\Theta (n\log n) \\
T_{memory} &\in &\Theta (1)
\end{eqnarray}

\index{priority queue}

A heap can be used to implement a priority queue, for example, storage from which we can efficiently extract the largest element.

All we need is a function that allows extracting the root element from a heap (as we did in the {\ft heapsort} and {\ft heapify} of the remaining data) and a function to push a new value into the heap:

\begin{lstlisting}
def heap_pop(A):
    if len(A)<1:
        raise RuntimeError("Heap Underflow")
    largest = A[0]
    A[0] = A[len(A)-1]
    del A[len(A)-1]
    heapify_one(A, 0)
    return largest

def heap_push(A, value):
    A.append(value)
    i = len(A)-1
    while i>0:
        j = heap_parent(i)
        if A[j]<A[i]:
            (A[i], A[j], i) = (A[j], A[i], j)
        else:
            break
\end{lstlisting}

The running times for {\ft heap\_pop} and {\ft heap\_push} are the same:

\begin{eqnarray}
T_{best} &\in &\Theta (1) \\
T_{average} &\in &\Theta (\log n) \\
T_{worst} &\in &\Theta (\log n) \\
T_{memory} &\in &\Theta (1)
\end{eqnarray}

Here is an example:

\begin{lstlisting}
>>> a = [6, 2, 7, 9, 3]
>>> heap = []
>>> for element in a: heap_push(heap, element)
>>> while heap: print(heap_pop(heap))
9
7
6
3
2
\end{lstlisting}

Heaps find application in many numerical algorithms. In fact, there is a built-in Python module for them called {\ft heapq}, which provides similar functionality to the functions defined here, except that we defined a max heap (pops the max element) while {\ft heapq} is a min heap (pops the minimum):

\begin{lstlisting}
>>> from heapq import heappop, heappush
>>> a = [6, 2, 7, 9, 3]
>>> heap = []
>>> for element in a: heappush(heap, element)
>>> while heap: print(heappop(heap))
9
7
6
3
2
\end{lstlisting}

Notice {\ft heappop} instead of {\ft heap\_pop} and {\ft heappush} instead of {\ft heap\_push}.

\subsection{Binary search trees}

\index{binary tree}\index{binary search}

A binary tree is a tree in which each node has at most two children (left and right). A binary tree is called a {\it binary search tree} if the value of a node is always greater than or equal to the value of its left child and less than or equal to the value of its right child.

A binary search tree is a kind of storage that can efficiently be used for searching if a particular value is in the storage. In fact, if the value for which we are looking is less than the value of the root node, we only have to search the left branch of the tree, and if the value is greater, we only have to search the right branch. Using divide-and-conquer, searching each branch of the tree is even simpler than searching the entire tree because it is also a tree, but smaller.

This means that we can search simply by traversing the tree from top to bottom along some path down the tree. We choose the path by moving down and turning left or right at each node, until we find the element for which we are looking or we find the end of the tree. We can search $T(d)$, where $d$ is the depth of the tree. We will see later that it is possible to build binary trees where $d=\log n$.

To implement it, we need to have a class to represent a binary tree:

\begin{lstlisting}
class BinarySearchTree(object):
     def __init__(self):
         self.left = self.right = None
         self.key = self.value =  None
     def __setitem__(self, key, value):
         if self.key == None:
             self.key, self.value = key, value
         elif key == self.key:
             self.value = value
         elif key < self.key:
             if self.left:
                 self.left[key] = value
             else:
                 self.left = BinarySearchTree(key, value)
         else:
             if self.right:
                 self.right[key] = value
             else:
                 self.right = BinarySearchTree(key, value)
     def __getitem__(self, key):
         if self.key == None:
             retur None
         elif key == self.key:
             return self.value
         elif key<self.key and self.left:
             return self.left[key]
         elif key>self.key and self.right:
             return self.right[key]
         else:
             return None
     def min(self):
         node = self
         while node.left:
             node = self.left
         return node.key, node.value
     def max(self):
         node = self
         while node.right:
             node = self.right
         return node.key, node.value
\end{lstlisting}

The binary tree can be used as follows:

\begin{lstlisting}
>>> root = BinarySearchTree()
>>> root[5] = "aaa"
>>> root[3] = "bbb"
>>> root[8] = "ccc"
>>> root.left.key
3
>>> root.left.value
bbb
>>> root[3]
bbb
>>> root.max()
8 ccc
\end{lstlisting}

Notice that an empty tree is treated as an exception, where {\ft key = None}.

\goodbreak\subsection{Other types of trees}

There are many other types of trees. \index{AVL tree}

For example, AVL trees are binary search trees that are rebalanced after each
insertion or deletion. They are rebalanced in such a way that for each node, the
height of the left subtree minus the height of the right subtree is more or less the same. The rebalance operation can be done in $O(\log n)$.

For an AVL tree, the time for inserting or removing an element is given by

\begin{eqnarray}
T_{best} &\in &\Theta (1) \\
T_{average} &\in &\Theta (\log n) \\
T_{worst} &\in &\Theta (\log n) \\
\end{eqnarray}

\index{k-tree}\index{B-tree}

Until now, we have considered binary trees (each node has two children and
stores one value). We can generalize this to $k$ trees, for which each node has $k$
children and stores more than one value.

B-trees are a type of k-tree optimized to read and write large blocks of data. They are normally used to implement database indices and are designed to minimize the amount of data to move when the tree is rebalanced.

\goodbreak\section{Graph algorithms}

\index{graphs}\index{links}\index{vertices}\index{walk}\index{path}\index{cycle}

A {\it graph} $G$ is a set of {\it vertices} $V$ and a set of {\it links} (also called {\it edges}) connecting those vertices $E$. Each link connects one vertex to another.

As an example, you can think of a set of cities connected by roads. The cities are the vertices and the roads are the links.

A link may have attributes. In the case of a road, it could be the name of the road or its length.

In general, a link, indicated with the notation $e_{ij}$, connecting vertex $%
i $ with vertex $j$ is called a {\it directed link}. If the link has no
direction $e_{ij}=e_{ji}$, it is called an undirected link. A graph that
contains only undirected links is an {\it undirected graph}; otherwise, it is
a {\it directed graph}.

In the road analogy, some roads can be ``one way'' (directed links) and some can be ``two way'' (undirected links).

A {\it walk} is an alternating sequence of vertices and links, with each
link being incident to the vertices immediately preceding and succeeding it
in the sequence. A {\it trail} is a walk with no repeated links.

A {\it path} is a walk with no repeated vertices. A walk is closed if the
initial vertex is also the terminal vertex.

A {\it cycle} is a closed trail with at least one edge and with no repeated
vertices, except that the initial vertex is also the terminal vertex.

A graph that contains no cycles is an {\it acyclic graph}. Any connected
acyclic undirected graph is also a {\it tree}.

\index{graph loop}

A {\it loop} is a one-link path connecting a vertex with itself.

\index{connected graph}

A non null graph is {\it connected} if, for every pair of vertices, there is
a walk whose ends are the given vertices. Let us write $i%
\symbol{126}j$ if there is a path from $i$ to $j$. Then $\symbol{126}$ is an
equivalence relation. The equivalence classes under $\symbol{126}$ are the
vertex sets of the connected components of $G$. A connected graph is therefore
a graph with exactly one connected component.

\index{complete graph}

A graph is called {\it complete} when every pair of vertices is connected by
a link (or edge).

\index{clique}

A {\it \ clique } of a graph is a subset of vertices in which every pair is an
edge.

\index{degree of a graph}

The {\it degree} of a vertex of a graph is the number of edges incident to
it.

If $i$ and $j$ are vertices, the {\it distance} from $i$ to $j$, written $%
d_{ij}$, is the minimum length of any path from $i$ to $j$. In a connected
undirected graph, the length of links induces a metric because for every two vertices, we can define their distance as the length of the shortest path connecting them.

The {\it eccentricity}, $e(i)$, of the vertex $i$ is the maximum value of $%
d_{ij}$, where $j$ is allowed to range over all of the vertices of the graph.  This gives the largest shortest distance to any connected node in the graph.

The {\it subgraph} of $G$ induced by a subset $W$ of its vertices $V$ ($%
W\subseteq V$) is the graph formed by the vertices in $W$ and all edges
whose two endpoints are in $W$.

The graph is the more complex of the data structures considered so far because it includes the tree as a particular case (yes, a tree is also a graph, but in general, a graph is not a tree), and the tree includes a list as a particular case (yes, a list is a tree in which every node has no more than one child); therefore a list is also a particular case of a graph.

The graph is such a general data structure that it can be used to model the brain. Think of neurons as vertices and synapses as links connecting them. We push this analogy later by implementing a simple neural network simulator.

In what follows, we represent a graph in the following way, where links are edges:

\begin{lstlisting}
>>> vertices = ["A", "B", "C", "D", "E"]
>>> links = [(0, 1), (1, 2), (1, 3), (2, 5), (3, 4), (3, 2)]
>>> graph = (vertices, links)
\end{lstlisting}

Vertices are stored in a list or array and so are links. Each link is a tuple containing the ID of the source vertex, the ID of the target vertex, and perhaps optional parameters.  Optional parameters are discussed later, but for now, they may include link details such as length, speed, reliability, or billing rate.

\subsection{Breadth-first search}

\index{breadth-first search}

The breadth-first search~\cite{bfs} (BFS) is an algorithm designed to visit all vertices in a connected graph. In the cities analogy, we are looking for a travel strategy to make sure we visit every city reachable by roads, once and only once.

The algorithm begins at one vertex, the origin, and expands out, eventually visiting each node in the graph that is somehow connected to the origin vertex. Its main feature is that it explores the neighbors of the current vertex before moving on to explore remote vertices and their neighbors. It visits other vertices in the same order in which they are discovered.

The algorithm starts by building a table of neighbors so that for each vertex, it knows which other vertices it is connected to. It then maintains two lists, a list of blacknodes (defined as vertices that have been visited) and graynodes (defined as vertices that have been discovered because the algorithm has visited its neighbor). It returns a list of blacknodes in the order in which they have been visited.

Here is the algorithm:

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
def breadth_first_search(graph, start):
    vertices, links = graph
    blacknodes = []
    graynodes = [start]
    neighbors = [[] for vertex in vertices]
    for link in links:
        neighbors[link[0]].append(link[1])
    while graynodes:
        current = graynodes.pop()
        for neighbor in neighbors[current]:
            if not neighbor in blacknodes+graynodes:
                graynodes.insert(0, neighbor)
        blacknodes.append(current)
    return blacknodes
\end{lstlisting}

The BFS algorithm scales as follows:
\begin{eqnarray}
T_{best} &\in &\Theta (n_E+n_V) \\
T_{average} &\in &\Theta (n_E+n_V) \\
T_{worst} &\in &\Theta (n_E+n_V) \\
T_{memory} &\in &\Theta (n)
\end{eqnarray}

\subsection{Depth-first search}

\index{depth-first search}

The depth-first search~\cite{dfs} (DFS) algorithm is very similar to the BFS, but it takes the opposite approach and explores as far as possible along each branch before backtracking.

In the cities analogy, if the BFS was exploring cities in the neighborhood before moving farther away, the DFS does the opposite and brings us first to distant places before visiting other nearby cities.

Here is a possible implementation:

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
def depth_first_search(graph, start):
    vertices, links = graph
    blacknodes = []
    graynodes = [start]
    neighbors = [[] for vertex in vertices]
    for link in links:
        neighbors[link[0]].append(link[1])
    while graynodes:
        current = graynodes.pop()
        for neighbor in neighbors[current]:
            if not neighbor in blacknodes+graynodes:
                graynodes.append(neighbor)
        blacknodes.append(current)
    return blacknodes
\end{lstlisting}

Notice that the BFS and the DFS differ for a single line, which determines whether graynodes is a queue (BSF) or a stack (DFS). When graynodes is a queue, the first vertex discovered is the first visited. When it is a stack, the last vertex discovered is the first visited.

The DFS algorithm goes as follows:
\begin{eqnarray}
T_{best} &\in &\Theta (n_E+n_V) \\
T_{average} &\in &\Theta (n_E+n_V) \\
T_{worst} &\in &\Theta (n_E+n_V) \\
T_{memory} &\in &\Theta (1)
\end{eqnarray}

\subsection{Disjoint sets}

\index{disjoint sets}

This is a data structure that can be used to store a set of sets and implements efficiently the join operation between sets.
Each element of a set is identified by a representative element. The algorithm starts by placing each element in a set of its own, so there are $n$ initial disjoint sets. Each is represented by itself. When two sets are joined, the representative element of the latter is made to point to the representative element of the former. The set of sets is stored as an array of integers. If at position $i$ the array stores a negative number, this number is interpreted as being the representative element of its own set. If the number stored at position $i$ is instead a nonnegative number $j$, it means that it belongs to a set that was joined with the set containing $j$.

Here is the implementation:

\index{class!DisjointSets}

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
class DisjointSets(object):
    def __init__(self, n):
        self.sets = [-1] * n
        self.counter = n
    def parent(self, i):
        while True:
            j = self.sets[i]
            if j<0:
                return i
            i = j
    def join(self, i, j):
        i, j = self.parent(i), self.parent(j)
        if i!=j:
            self.sets[i] += self.sets[j]
            self.sets[j] = i
            self.counter-=1
            return True  # they have been joined
        return False     # they were already joined
    def joined(self, i, j):
       return self.parent(i) == self.parent(j)
    def __len__(self):
        return self.counter
\end{lstlisting}

Notice that we added a member variable counter that is initialized to the number of disjoint sets and is decreased by one every time two sets are merged. This allows us to keep track of how many disjoint sets exist at each time. We also override the {\ft \_\_len\_\_} operator so that we can check the value of the counter using the {\ft len} function on a {\ft DisjointSet}.

As an example of application, here is a code that builds a $n^d$ maze. It may be easier to picture it with $d=2$, a two-dimensional maze. The algorithm works by assuming there is a wall connecting any couple of two adjacent cells. It labels the cells using an integer index.
It puts all the cells into a {\ft DisjointSets} data structure and then keeps tearing down walls at random. Two cells on the maze belong to the same set if they are connected, for example, if there is a path that connects them. At the beginning, each cell is its own set because it is isolated by walls.
Walls are torn down by being removed from the list {\ft wall} if the wall was separating two disjoint sets of cells. Walls are torn down until all cells belong to the same set, for example, there is a path connecting any cell to any cell:

%%% META:FILE:nlib.py
\begin{lstlisting}
def make_maze(n, d):
    walls = [(i, i+n ** j) for i in range(n ** 2) for j in range(d) if (i/n ** j)%n+1<n]
    torn_down_walls = []
    ds = DisjointSets(n ** d)
    random.shuffle(walls)
    for i, wall in enumerate(walls):
        if ds.join(wall[0], wall[1]):
            torn_down_walls.append(wall)
        if len(ds) == 1:
            break
    walls = [wall for wall in walls if not wall in torn_down_walls]
    return walls, torn_down_walls
\end{lstlisting}

Here is an example of how to use it. This example also draws the walls and the border of the maze:

%%% META:FILE:nlib.py
\begin{lstlisting}
>>> walls, torn_down_walls = make_maze(n=20, d=2)
\end{lstlisting}

The following figure shows a representation of a generated maze:

\begin{figure}[ht]
\centering\includegraphics[width=2in]{images/maze1.png}
\caption{Example of a maze as generated using the {\ft DisjointSets} algorithm.}
\end{figure}

\subsection{Minimum spanning tree: Kruskal}

\index{minimum spanning tree}\index{Kruskal}

Given a connected graph with weighted links (links with a weight or length), a {\it minimum spanning tree} is a subset of that graph that connects all vertices of the original graph, and the sum of the link weights is minimal. This subgraph is also a tree because the condition of minimal weight implies that there is only one path connecting each couple of vertices.

\begin{figure}[ht]
\centering\includegraphics[width=2in]{images/mst.png}
\caption{Example of a minimum spanning tree subgraph of a larger graph. The numbers on the links indicate their weight or length.}
\end{figure}

One algorithm to build the minimal spanning tree of a graph is the Kruskal~\cite{kruskal} algorithm. It works by placing all vertices in a {\ft DisjointSets} structure and looping over links in order of their weight. If the link connects two vertices belonging to different sets, the link is selected to be part of the minimum spanning tree, and the two sets are joined, else the link is ignored. The Kruskal algorithm assumes an undirected graph, for example, all links are bidirectional, and the weight of a link is the same in both directions:

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
def Kruskal(graph):
    vertices, links = graph
    A = []
    S = DisjointSets(len(vertices))
    links.sort(cmp=lambda a, b: cmp(a[2], b[2]))
    for source, dest, length in links:
        if S.join(source, dest):
            A.append((source, dest, length))
    return A
\end{lstlisting}

The Kruskal algorithm goes as follows:
\begin{eqnarray}
T_{worst} &\in &\Theta (n_E\log n_V) \\
T_{memory} &\in &\Theta (n_E)
\end{eqnarray}

We provide an example of application in the next subsection.

\goodbreak\subsection{Minimum spanning tree: Prim}

The Prim~\cite{prim} algorithm solves the same problem as the Kruskal algorithm, but the Prim algorithm works on a directed graph. It works by placing all vertices in a minimum priority queue where the queue metric for each vertex is the length, or weighted value, of a link connecting the vertex to the closest known neighbor vertex. At each iteration, the algorithm pops a vertex from the priority queue, loops over its neighbors (adjacent links), and, if it finds that one of its neighbors is already in the queue and it is possible to connect it to the current vertex using a shorter link than the one connecting the neighbor to its current closest vertex, the neighbor information is then updated. The algorithm loops until there are no vertices in the priority queue.

The Prim algorithm also differs from the Kruskal algorithm because the former needs a starting vertex, whereas the latter does not. The result when interpreted as a subgraph does not depend on the starting vertex:

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
from heapq import heappush, heappop, heapify

class PrimVertex(object):
    INFINITY = 1e100
    def __init__(self, id, links):
        self.id = id
        self.closest = None
        self.closest_dist = PrimVertex.INFINITY
        self.neighbors = [link[1:] for link in links if link[0] == id]
    def __lt__(self, other):
        return self.closest_dist < other.closest_dist

def Prim(graph, start):
    vertices, links = graph
    P = [PrimVertex(i, links) for i in vertices]
    Q = [P[i] for i in vertices if not i == start]
    vertex = P[start]
    while Q:
        for neighbor_id, length in vertex.neighbors:
            neighbor = P[neighbor_id]
            if neighbor in Q and length<neighbor.closest_dist:
                 neighbor.closest = vertex
                 neighbor.closest_dist = length
        heapify(Q)
        vertex = heappop(Q)
    return [(v.id, v.closest.id, v.closest_dist) for v in P if not v.id == start]
\end{lstlisting}

\begin{lstlisting}
>>> vertices = range(10)
>>> links = [(i, j, abs(math.sin(i+j+1))) for i in vertices for j in vertices]
>>> graph = [vertices, links]
>>> link = Prim(graph, 0)
>>> for link in links: print(link)
(1, 4, 0.279...)
(2, 0, 0.141...)
(3, 2, 0.279...)
(4, 1, 0.279...)
(5, 0, 0.279...)
(6, 2, 0.412...)
(7, 8, 0.287...)
(8, 7, 0.287...)
(9, 6, 0.287...)
\end{lstlisting}

The Prim algorithm, when using a priority queue for $Q$, goes as follows:
\begin{eqnarray}
T_{worst} &\in &\Theta (n_E+n_V\log n_V) \\
T_{memory} &\in &\Theta (n_E)
\end{eqnarray}

One important application of the minimum spanning tree is in evolutionary biology. Consider, for example, the DNA for the genes that produce hemoglobin, a molecule responsible for the transport of oxygen in blood. This protein is present in every animal, and the gene is also present in the DNA of every known animal. Yet its DNA structure is a little different. One can select a pool of animals and, for each two of them, compute the similarity of the DNA of their hemoglobin genes using the {\ft lcs} algorithm discussed later. One can then link each two animals by a metric that represents how similar the two animals are. We can then run the Prim or the Kruskal algorithm to find the minimum spanning tree. The tree represents the most likely evolutionary tree connecting those animal species. Actually, three genes are responsible for hemoglobin ({\it HBA1}, {\it HBA2}, and {\it HBB}). By performing the analysis on different genes and comparing the results, it is possible to establish a consistency check of the results.~\cite{evolutionary}

Similar studies are performed routinely in evolutionary biology. They can also be applied to viruses to understand how viruses evolved over time.~\cite{korber}

\subsection{Single-source shortest paths: Dijkstra}

\index{single-source shortest paths}\index{Dijkstra}

The Dijkstra~\cite{dijkstra} algorithm solves a similar problem to the Kruskal and Prim algorithms. Given a graph, it computes, for each vertex, the shortest path connecting the vertex to a starting (or source, or root) vertex. The collection of links on all the paths defines the {\it single-source shortest paths}.

It works, like Prim, by placing all vertices in a min priority queue where the queue metric for each vertex is the length of the path connecting the vertex to the source. At each iteration, the algorithm pops a vertex from the priority queue, loops over its neighbors (adjacent links), and, if it finds that one of its neighbors is already in the queue and it is possible to connect it to the current vertex using a link that makes the path to the source shorter, the neighbor information is updated. The algorithm loops until there are no more vertices in the priority queue.

The implementation of this algorithm is almost identical to the Prim algorithm, except for two lines:

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
from heapq import heappush, heappop, heapify

def Dijkstra(graph, start):
    vertices, links = graph
    P = [PrimVertex(i, links) for i in vertices]
    Q = [P[i] for i in vertices if not i == start]
    vertex = P[start]
    vertex.closest_dist = 0
    while Q:
        for neighbor_id, length in vertex.neighbors:
            neighbor = P[neighbor_id]
            dist = length+vertex.closest_dist
            if neighbor in Q and dist<neighbor.closest_dist:
                 neighbor.closest = vertex
                 neighbor.closest_dist = dist
        heapify(Q)
        vertex = heappop(Q)
    return [(v.id, v.closest.id, v.closest_dist) for v in P if not v.id == start]
\end{lstlisting}

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
>>> vertices = range(10)
>>> links = [(i, j, abs(math.sin(i+j+1))) for i in vertices for j in vertices]
>>> graph = [vertices, links]
>>> links = Dijkstra(graph, 0)
>>> for link in links: print(link)
(1, 2, 0.897...)
(2, 0, 0.141...)
(3, 2, 0.420...)
(4, 2, 0.798...)
(5, 0, 0.279...)
(6, 2, 0.553...)
(7, 2, 0.685...)
(8, 0, 0.412...)
(9, 0, 0.544...)
\end{lstlisting}

The Dijkstra algorithm goes as follows:
\begin{eqnarray}
T_{worst} &\in &\Theta (n_E+n_V\log n_V) \\
T_{memory} &\in &\Theta (n_E)
\end{eqnarray}

An application of the Dijkstra is in solving a maze such as the one built when discussing disjoint sets. To use the Dijkstra algorithm, we need to generate a maze, take the links representing torn-down walls, and use them to build an undirected graph. This is done by symmetrizing the links (if $i$ and $j$ are connected, $j$ and $i$ are also connected) and adding to each link a length (1, because all links connect next-neighbor cells):


%%% META:FILE:nlib.py
\begin{lstlisting}
>>> n, d = 4, 2
>>> walls, links = make_maze(n, d)
>>> symmetrized_links = [(i, j, 1) for (i, j) in links]+[(j, i, 1) for (i, j) in links]
>>> graph = [range(n * n), symmetrized_links]
>>> links = Dijkstra(graph, 0)
>>> paths = dict((i, (j, d)) for (i, j, d) in links)
\end{lstlisting}

Given a maze cell {\ft i}, {\ft path[i]} gives us a tuple $(j, d)$ where $d$ is the number of steps for the shortest path to reach the origin (0) and $j$ is the ID of the next cell along this path.
The following figure shows a generated maze and a reconstructed path connecting an arbitrary cell to the origin:

\begin{figure}[ht]
\centering\includegraphics[width=2in]{images/maze2.png}
\caption{The result shows an application of the Dijkstra algorithm for the single source shortest path applied to solve a maze.}
\end{figure}

\goodbreak\section{Greedy algorithms}

\subsection{Huffman encoding}

\index{greedy algorithms}
\index{Huffman encoding}\index{Shannon-Fano}

The {\it Shannon--Fano encoding}~\cite{shannon}\cite{fano} (also known as {\bf minimal prefix code}) is a lossless data compression algorithm.
In this encoding, each character in a string is mapped into a sequence of bits
so characters that appear with less frequency are encoded with a longer
sequence of bits, whereas characters that appear with more frequency are
encoded with a shorter sequence.

The {\it Huffman encoding}~\cite{huffman} is an implementation of the Shannon--Fano encoding, but the sequence of bits into which each character is mapped is chosen such that the length of the compressed string is minimal.
This choice is constructed in the following way.
We associate a tree with each character
in the string to compress. Each tree is a trivial tree containing only one
node: the root node. We then associate with the root node the frequency of the
character representing the tree. We then extract from the list of trees the
two trees with rarest or lowest frequency: t1 and t2. We form a new tree, t3, we attach
t1 and t2 to t3, and we associate a frequency with t3 equal to the sum of the
frequencies of t1 and t2. We repeat this operation until the list of trees
contains only one tree. At this point, we associate a sequence of bits with
each node of the tree. Each bit corresponds to one level on the tree. The
more frequent characters end up being closer to the root and are encoded
with a few bits, while rare characters are far from the root and encoded with
more bits.

PKZIP, ARJ, ARC, JPEG, MPEG3 (mp3), MPEG4, and other
compressed file formats all use the Huffman coding algorithm for compressing
strings. Note that Huffman is a compression algorithm with
no information loss. In the JPEG and MPEG compression algorithms, Huffman algorithms are
combined with some form or cut of the Fourier spectrum (e.g., MP3 is
an audio compression format in which frequencies below 2 KHz are dumped and not
compressed because they are not audible). Therefore the JPEG and MPEG
formats are referred to as compression with information loss.

Here is a possible implementation of Huffman encoding using the Python {\ft heapq} library. Notice that in order for it to work properly, we need to wrap the set of symbols they represents, and their relative frequency, into a class {\ft HuffmanNode} that implements the $<$ ({\ft \_\_lt\_\_}) operator.

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
from heapq import heappush, heappop

class HuffmanNode:
    def __init__(self, frequency, content):
        self.frequency = frequency
        self.content = content
    def __lt__(self, other):
        return self.frequency < other.frequency
    def unpack(self):
        return self.frequency, self.content
  
def encode_huffman(input):

    def inorder_tree_walk(t, key, keys):
        (f, ab) = t
        if isinstance(ab, tuple):
            inorder_tree_walk(ab[0], key+"0", keys)
            inorder_tree_walk(ab[1], key+"1", keys)
        else:
            keys[ab] = key

    symbols = {}
    for symbol in input:
        symbols[symbol] = symbols.get(symbol, 0)+1
    heap = []
    for (k, f) in symbols.items():
        heappush(heap, HuffmanNode(f, k))
    while len(heap)>1:
        (f1, k1) = heappop(heap).unpack()
        (f2, k2) = heappop(heap).unpack()
        heappush(heap, HuffmanNode(f1 + f2, ((f1, k1), (f2, k2))))
    symbol_map = {}
    root = heap[0].unpack()    
    inorder_tree_walk(root, '', symbol_map)
    encoded = ''.join(symbol_map[symbol] for symbol in input)
    return symbol_map, encoded

def decode_huffman(keys, encoded):
    reversed_map = dict((v, k) for (k, v) in keys.items())
    i, output = 0, []
    for j in range(1, len(encoded)+1):
        if encoded[i:j] in reversed_map:
           output.append(reversed_map[encoded[i:j]])
           i=j
    return ''.join(output)
\end{lstlisting}

We can use it as follows:

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
>>> input = "this is a nice day"
>>> keys, encoded = encode_huffman(input)
>>> print(encoded)
00100101110011101100111011111000111100001111010000011110100
>>> decoded = decode_huffman(keys, encoded)
>>> decoded == input
True
>>> print(1.0 * len(input)/(len(encoded)/8))
2.44...
\end{lstlisting}

We managed to compress the original data by a factor 2.57.

\index{entropy}

We can ask how good is this compression factor.
The maximum theoretical best compression factor is given by the Shannon {\it entropy}, defined as

\begin{equation}
E = -\sum_u w_i \log_2 w_i
\end{equation}
where $w_i$ is the relative frequency of each symbol.
In our case, this is easy to compute as

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
>>> from math import log
>>> input = "this is a nice day"
>>> w = [1.0 * input.count(c)/len(input) for c in set(input)]
>>> E = -sum(wi * log(wi, 2) for wi in w)
>>> print(E)
3.23...
\end{lstlisting}

How could we have done better? Notice for example that the Huffman encoding does not take into account the order in which symbols appear. The original string contains the triple ``is'' twice, and we could have taken advantage of that pattern, but we did not.

Our choice of using characters as symbols is arbitrary. We could have used a couple of characters as symbols or triplets or any other subsequences of bytes of the original input. We could also have used symbols of different lengths for different parts of the input (we could have used a single symbol for ``is''). A different choice would have given a different compression ratio, perhaps better, perhaps worse.

\subsection{Longest common subsequence}

\index{longest common subsequence}\index{DNA}

Given two sequences of characters $S_1$ and $S_2$, this is the problem of determining the length of the longest common subsequence (LCS) that is a subsequence of both $S_1$ and $S_2$.

There are several applications for the LCS~\cite{bergroth} algorithm:

\begin{itemize}
\item  {\bf Molecular biology}: DNA sequences (genes) can be represented as sequences of four letters ACGT, corresponding to the four sub-molecules forming DNA. When biologists find a new sequence, they want to find similar sequences or ones that are close. One way of computing how similar two sequences are is to find the length of their LCS.

\item  {\bf File comparison}: The Unix program {\ft diff} is used to compare
two different versions of the same file, to determine what changes have been
made to the file. It works by finding a LCS of the
lines of the two files and displays the set of lines that have changed. In
this instance of the problem, we should think of each line of a file as being
a single complicated character.

\item  {\bf Spelling correction}: If some text contains a word, w, that is not
in the dictionary, a ``close'' word (e.g., one with a small edit distance to w)
may be suggested as a correction. Transposition errors are common in written
text. A transposition can be treated as a deletion plus an insertion, but a
simple variation on the algorithm can treat a transposition as a single
point mutation.

\item  {\bf Speech recognition}: Algorithms similar to the LCS are used in
some speech recognition systems---find a close match between a new utterance
and one in a library of classified utterances.
\end{itemize}

Let"s start with some simple observations about the LCS problem. If we have
two strings, say, ``ATGGCACTACGAT'' and ``ATCGAGC, '' we can represent a
subsequence as a way of writing the two so that certain letters line up:
\begin{lstlisting}
     ATGGCACTACGAT
     || | |   |
     ATCG AG  C
\end{lstlisting}

From this we can observe the following simple fact: if the two strings start
with the same letter, it"s always safe to choose that starting letter as the
first character of the subsequence. This is because, if you have some other
subsequence, represented as a collection of lines as drawn here, you can
``push'' the leftmost line to the start of the two strings without causing
any other crossings and get a representation of an equally long subsequence
that does start this way.

Conversely, suppose that, like in the preceding example, the two first
characters differ. Then it is not possible for both of them to be part of a
common subsequence.  There are three possible choices: remove the first letter from
either one of the strings or remove the letter from both strings.

Finally, observe that once we"ve decided what to do with the first
characters of the strings, the remaining subproblem is again a LCS problem on two shorter strings. Therefore we can solve
it recursively. However, because we don"t know which choice of the three to take, 
we will take them all and see which choice returns the best result.

Rather than finding the subsequence itself, it turns out to be more
efficient to find the length of the longest subsequence. Then, in
the case where the first characters differ, we can determine which
subproblem gives the correct solution by solving both and taking the max of
the resulting subsequence lengths. Once we turn this into a dynamic
programming algorithm, we get the following:

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
def lcs(a, b):
    previous = [0] * len(a)
    for i, r in enumerate(a):
        current = []
        for j, c in enumerate(b):
            if r == c:
                e = previous[j-1]+1 if i * j>0 else 1
            else:
                e = max(previous[j] if i>0 else 0, 
                        current[-1] if j>0 else 0)
            current.append(e)
        previous=current
    return current[-1]
\end{lstlisting}

Here is an example:

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
>>> dna1 = "ATGCTTTAGAGGATGCGTAGATAGCTAAATAGCTCGCTAGA"
>>> dna2 = "GATAGGTACCACAATAATAAGGATAGCTCGCAAATCCTCGA"
>>> lcs(dna1, dna2)
26
\end{lstlisting}

The algorithms can be shown to be $O(nm)$ (where $m=$ len(a) and $n=$ len(b)).

Another application of this algorithm is in the Unix {\ft diff} utility. Here is a simple example to find the number of common lines between two files:

\begin{lstlisting}
>>> a = open("file1.txt").readlines()
>>> b = open("file2.txt").readlines()
>>> lcs(a, b)
\end{lstlisting}

\subsection{Needleman--Wunsch}

\index{Needleman--Wunsch}\index{global alignment}

With some minor changes to the LCS algorithm, we obtain the Needleman--Wunsch algorithm~\cite{needleman}, which solves the problem of {\it global sequence alignment}. The changes are that, instead of using only two alternating rows ({\ft c} and {\ft d} for storing the temporary results, we store all temporary results in an array {\ft z}; when two matching symbols are found and they are not consecutive, we apply a penalty equal to $p^m$, where $m$ is the distance between the two matches and is also the size of the gap in the matching subsequence:


%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
def needleman_wunsch(a, b, p=0.97):
    z=[]
    for i, r in enumerate(a):
        z.append([])
        for j, c in enumerate(b):
            if r == c:
                e = z[i-1][j-1]+1 if i * j>0 else 1
            else:
                e = p * max(z[i-1][j] if i>0 else 0, 
                          z[i][j-1] if j>0 else 0)
            z[-1].append(e)
    return z
\end{lstlisting}

This algorithm can be used to identify common subsequences of DNA between chromosomes (or in general common similar subsequences between any two strings of binary data). Here is an example in which we look for common genes in two randomly generated chromosomes:

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
>>> bases = "ATGC"
>>> from random import choice
>>> genes = [''.join(choice(bases) for k in range(10)) for i in range(20)]
>>> chromosome1 = ''.join(choice(genes) for i in range(10))
>>> chromosome2 = ''.join(choice(genes) for i in range(10))
>>> z = needleman_wunsch(chromosome1, chromosome2)
>>> Canvas(title="Needleman-Wunsch").imshow(z).save("images/needleman.png")
\end{lstlisting}

The output of the algorithm is the following image:

\begin{figure}[ht]
\centering\includegraphics[width=4in]{images/needleman.png}
\caption{A Needleman and Wunsch plot sequence alignment. The arrow-like patterns indicate the point in the two sequences (represented by the $X$- and $Y$-coordinates) where the two sequences are more likely to align.}
\end{figure}

The arrow-like patterns in the figure correspond to locations where {\ft chromosome1} (Y coordinate) and where {\ft chromosome2} (X coordinate) have DNA in common. Those are the places where the sequences are more likely to be aligned for a more detailed comparison.

\subsection{Continuous Knapsack}
\index{continuous knapsack}

Assume you want to fill your knapsack such that you will maximize the value of its contents~\cite{knapsack}.  However, you are limited by the volume your knapsack can hold. In the continuous knapsack, the amount of each product can vary continuously. In the discrete one, each product has a finite size, and you either carry it or no.

The continuous knapsack problem can be formulated as the problem of
maximizing
\begin{equation}
f(x)=a_0x_0+a_1x_1+...+a_nx_n
\end{equation}
given the constraint
\begin{equation}
b_0x_0+b_1x_1+...+b_nx_n\leq c
\end{equation}
where coefficients $a_i$, $b_i$, and $c$ are provided and $x_i\in [0, 1]$ are
to be determined.

Using financial terms, we can say that

\begin{itemize}
\item  The set $\{x_0, x_1, ..., x_n\}$ forms a portfolio

\item  $b_i$ is the cost of investment $i$

\item  $c$ is the total investment capital available

\item  $a_i$ is the expected return of investment for investment $i$

\item  $f(x)$ is the expected value of our portfolio $\{x_0, x_1, ..., x_n\}$
\end{itemize}

Here is the solving algorithm:

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
def continuum_knapsack(a, b, c):
    table = [(a[i]/b[i], i) for i in range(len(a))]
    table.sort()
    table.reverse()
    f=0.0
    for (y, i) in table:
        quantity = min(c/b[i], 1)
        x.append((i, quantity))
        c = c-b[i] * quantity
        f = f+a[i] * quantity
    return (f, x)
\end{lstlisting}

This algorithm is dominated by the sort; therefore
\begin{equation}
T_{worst}(x)\in O(n\log n)
\end{equation}

\subsection{Discrete Knapsack}
\index{discrete knapsack}

The discrete Knapsack problem is very similar to the continuous knapsack
problem but $x_i\in \{0, 1\}$ (can only be 0 or 1).

Consider the jars of liquids replaced with baskets of objects, say, a basket each of gold bars, silver coins, copper beads, and Rolex watches.  How many of each item do you take?  The discrete knapsack problem does not consider ``baskets of items'' but rather all the items together.  In this example, dump out all the baskets and you have individual objects to take.  Which objects do you take, and which do you leave behind?

In this case, a greedy approach does not apply and the problem is, in general, 
NP complete. This concept is defined formally later but it means that there is no known algorithm that can solve this problem and that its order of growth is a polynomial. The best known algorithm has an exponential running time.

This kind of problem is unsolvable for large input.

If we assume that $c$ and $b_i$ are all multiples of a finite factor $\varepsilon$, then it is possible to solve the problem in $O(c/\varepsilon )$.
Even when there is not a finite factor $\varepsilon$, 
we can always round $c$ and $b_i$ to some finite precision $\varepsilon$, 
and we can conclude that, for any finite precision $\varepsilon$, we can
solve the problem in linear time. The algorithm that solves this problem
follows a dynamic programming approach.

We can reformulate the problem in terms of a simple capital budgeting
problem. We have to invest \$5M. We assume $\varepsilon =$\$1M. We are in
contact with three investment firms. Each offers a number of investment
opportunities characterized by an investment cost $c[i, j]$ and an expected
return of investment $r[i, j]$. The index $i$ labels the investment firm and
the index $j$ labels the different investment opportunities offered by the
firm. We have to build a portfolio that maximizes the return of investment.
We cannot select more than one investment for each firm, and we cannot select
fractions of investments.

Without loss of generality, we will assume that
\begin{equation}
c[i, j]\leq c[i, j+1]\text{ and }r[i, j]\leq r[i, j+1]
\end{equation}
which means that investment opportunities for each firm are sorted according
to their cost.

\medskip Consider the following explicit case:
\begin{equation}
\begin{tabular}{|l|l|l|l|l|l|l|}
\hline
& Firm & $i=0$ & Firm & $i=1$ & Firm & $i=2$ \\ \hline
proposal & $c[0, j]$ & $r[0, j]$ & $c[1, j]$ & $r[1, j]$ & $c[2, j]$ & $r[2, j]$
\\ \hline
$j=0$ & 0 & 0 & 0 & 0 & 0 & 0 \\ \hline
$j=1$ & 1 & 5 & 2 & 8 & 1 & 4 \\ \hline
$j=2$ & 2 & 6 & 3 & 9 & - & - \\ \hline
$j=3$ & - & - & 4 & 12 & - & - \\ \hline
\end{tabular}
\tag{Table 1}
\end{equation}
(table values are always multiples of $\varepsilon =$\$1M).

Notice that we can label each possible portfolio by a triplet $%
\{j_0, j_1, j_2\}$.

A straightforward way to solve this is to try all possibilities and choose
the best. In this case, there are only $3\times 4\times 2=24$ possible
portfolios. Many of these are infeasible (e.g., portfolio $\{2, 3, 0\}$
costs \$6M and we cannot afford it). Other portfolios are feasible but very
poor (like portfolio $\{0, 0, 1\}$, which is feasible but returns only \$4M).

Here are some disadvantages of total enumeration:

\begin{itemize}
\item  For larger problems, the enumeration of all possible solutions may not
be computationally feasible.

\item  Infeasible combinations may not be detectable a priori, leading to
inefficiency.

\item  Information about previously investigated combinations is not used to
eliminate inferior or infeasible combinations (unless we use memoization, 
but in this case the algorithm would grow polynomially in memory space).
\end{itemize}

We can, instead, use a dynamic programming approach.

We break the problem into three stages, and at each stage, we fill a table of
optimal investments for each discrete amount of money. At each stage $i$, we
only consider investments from firm $i$ and the table during the previous
stage.

So stage $0$ represents the money allocated to firm $0$, stage $1$ the money
to firm $1$, and stage $2$ the money to firm $2$.

STAGE\ ZERO: we maximize the return of investment considering only offers
from firm 0. We fill a table $f[0, k]$ with the maximum return of investment
if we invest $k$ million dollars in firm $0$:
\begin{equation}
f[0, k]=\max_{j|c[0, j]<k}r[0, j]  \label{stage0}
\end{equation}
\begin{equation}
\begin{tabular}{|l|l|}
\hline
$k$ & $f[0, k]$ \\ \hline
0 & 0 \\ \hline
1 & 5 \\ \hline
2$^{ * }$ & 6$^{ * }$ \\ \hline
3 & 6 \\ \hline
4 & 6 \\ \hline
5 & 6 \\ \hline
\end{tabular}
\label{table0}
\end{equation}

STAGE TWO: we maximize the return of investment considering offers from firm $%
1$ and the prior table. We fill a table $f[1, k]$ with the maximum return of
investment if we invest $k$ million dollars in firm $0$ and firm $1$:
\begin{equation}
f[1, k]=\max_{j|c[1, j]<k}r[1, j]+f[0, k-c[0, j]]  \label{stage1}
\end{equation}
\begin{equation}
\begin{tabular}{|l|l|l|l|}
\hline
$k$ & $c[2, j]$ & $f[0, k-c[0, j]]$ & $f[1, k]$ \\ \hline
0 & 0 & 0 & 0 \\ \hline
1 & 0 & 1 & 5 \\ \hline
2 & 2 & 0 & 8 \\ \hline
3 & 2 & 1 & 9 \\ \hline
4 & 3 & 1 & 13 \\ \hline
5$^{ * }$ & 4$^{ * }$ & 1$^{ * }$ & 18$^{ * }$ \\ \hline
\end{tabular}
\label{table1}
\end{equation}

STAGE THREE: we maximize the return of investment considering offers from
firm $2$ and the preceding table. We fill a table $f[2, k]$ with the maximum
return of investment if we invest $k$ million dollars in firm $0$, firm $1$, 
and firm $2$:
\begin{equation}
f[2, k]=\max_{j|c[2, j]<k}r[2, j]+f[1, k-c[1, j]]  \label{stage2}
\end{equation}
\begin{equation}
\begin{tabular}{|l|l|l|l|}
\hline
$k$ & $c[2, j]$ & $f[1, k-c[1, j]]$ & $f[2, k]$ \\ \hline
0 & 0 & 0 & 0 \\ \hline
1 & 0 & 1 & 5 \\ \hline
2 & 2 & 0 & 8 \\ \hline
3 & 2 & 1 & 9 \\ \hline
4 & 1 & 3 & 13 \\ \hline
5$^{ * }$ & 2$^{ * }$ & 3$^{ * }$ & 18$^{ * }$ \\ \hline
\end{tabular}
\label{table2}
\end{equation}
The maximum return of investment with \$5M is therefore \$18M. It can be
achieved by investing \$2M in firm 2 and \$3M in firms 0 and 1. The optimal
choice is marked with a star in each table. Note that to determine
how much money has to be allocated to maximize the return of
investment requires storing past tables to be able to look up the
solution to subproblems.

We can generalize eq.(\ref{stage1}) and eq.(\ref{stage2}) for any number of
investment firms (decision stages):

\begin{equation}
f[i, k]=\max_{j|c[i, j]<k}r[i, j]+f[i-1, k-c[i-1, j]]
\end{equation}

\goodbreak\section{Artificial intelligence and machine learning}

\index{artificial intelligence}\index{machine learning}

\goodbreak\subsection{Clustering algorithms}

\index{clustering}\index{hierarchical clustering}\index{k-means}

There are many algorithms available to cluster data~\cite{clustering}. They are all based on empirical principles because the cluster themselves are defined by the algorithm used to identify them. Normally we distinguish three categories:
\begin{itemize}
\item {\it Hierarchical clustering}: These algorithms start by considering each point a cluster of its own. At each iteration, the two clusters closest to each other are joined together, forming a larger cluster. Hierarchical clustering algorithms differ from each other about the rule used to determine the distance between clusters. The algorithm returns a tree representing the clusters that are joined, called a {\it dendrogram}.
\item {\it Centroid-based clustering}: These algorithms require that each point be represented by a vector and each cluster also be represented by a vector (centroid of the cluster). With each iteration, a better estimation for the centroids is given. An example of centroid-based clustering is {\it k-means} clustering. These algorithms require an a priori knowledge of the number of clusters and return the position of the centroids as well the set of points belonging to each cluster.
\item {\it Distribution-based clustering}: These algorithms are based on statistics (more than the other two categories). They assume the points are generated from a  distribution (which mush be known a priori) and determine the parameters of the distribution. It provides clustering because the distribution may be a sum of more than one localized distribution (each being a cluster).
\end{itemize}

Both {\it k}-means and distribution-based clustering assume an a priori knowledge about the data that often defies the purpose of using clustering: learn something we do now know about the data using an empirical algorithm. They also require that the points be represented by vectors in a Euclidean space, which is not always the case. Consider the case of clustering DNA sequences or financial time series. Technically the latter can be presented as vectors, but their dimensionality can be very large, thus making the algorithms impractical.

Hierarchical clustering only requires the notion of a distance between points, for some of the points.

\begin{figure}[ht]
\centering\includegraphics[width=4in]{images/dendrogram.png}
\caption{Example of a dendrogram.}
\end{figure}

The following algorithm is a hierarchical clustering algorithm with the following characteristics:

\begin{itemize}
\item Individual points do not need to be vectors (although they can be).
\item Points may have a weight used to determine their relative importance in identifying the characteristics of the cluster (think of clustering financial assets based on the time series of their returns; the weight could the average traded volume).
\item The distance between points is computed by a metric function provided by the user. The metric can return {\ft None} if there is no known connection between two points.
\item The algorithm can be used to build the entire {\it dendrogram} \index{dendrogram}, or it can stop for a given value of $k$, a target number of clusters.
\item For points that are vectors and a given $k$, the result is similar to the result of the $k$-means clustering.
\end{itemize}

The algorithm works like any other hierarchical clustering algorithm. At the beginning, all-to-all distances are computed and stored in a list {\ft d}. Each point is its own cluster. At each iteration, the two clusters closer together are merged to form one bigger cluster. The distance between each other cluster and the merged cluster is computed by performing a weighted average of the distances between the other cluster and the two merged clusters. The weight factors are provided as input. This is equivalent to what the $k$-means algorithm does by computing the position of a centroid based on the vectors of the member points.

The algorithm {\ft self.q} implements disjointed sets representing the set of clusters. The algorithm {\ft self.q} is a dictionary. If {\ft self.q[i]} is a list, then {\ft i} is its own cluster, and the list contains the IDs of the member points. If  {\ft self.q[i]} is an integer, then cluster {\ft i} is no longer its own cluster as it was merged to the cluster represented by the integer.

At each point in time, each cluster is represented by one element, which can be found recursively by {\ft self.parent(i)}. This function returns the ID of the cluster containing element {\ft i} and returns a list of IDs of all points in the same cluster:

\index{class!Cluster}

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
class Cluster(object):
    def __init__(self, points, metric, weights=None):
        self.points, self.metric = points, metric
        self.k = len(points)
        self.w = weights or [1.0] * self.k
        self.q = dict((i, [i]) for i, e in enumerate(points))
        self.d = []
        for i in range(self.k):
            for j in range(i+1, self.k):
                m = metric(points[i], points[j])
                if not m is None:
                    self.d.append((m, i, j))
        self.d.sort()
        self.dd = []
    def parent(self, i):
        while isinstance(i, int): (parent, i) = (i, self.q[i])
        return parent, i
    def step(self):
        if self.k>1:
             # find new clusters to join
            (self.r, i, j), self.d = self.d[0], self.d[1:]
             # join them
            i, x = self.parent(i)  # find members of cluster i
            j, y = self.parent(j)  # find members if cluster j
            x += y                # join members
            self.q[j] = i         # make j cluster point to i
            self.k -= 1           # decrease cluster count
             # update all distances to new joined cluster
            new_d = []  # links not related to joined clusters
            old_d = {}  # old links related to joined clusters
            for (r, h, k) in self.d:
                if h in (i, j):
                    a, b = old_d.get(k, (0.0, 0.0))
                    old_d[k] = a+self.w[k] * r, b+self.w[k]
                elif k in (i, j):
                    a, b = old_d.get(h, (0.0, 0.0))
                    old_d[h] = a+self.w[h] * r, b+self.w[h]
                else:
                    new_d.append((r, h, k))
            new_d += [(a/b, i, k) for k, (a, b) in old_d.items()]
            new_d.sort()
            self.d = new_d
             # update weight of new cluster
            self.w[i] = self.w[i]+self.w[j]
             # get new list of cluster members
            self.v = [s for s in self.q.values() if isinstance(s, list)]
            self.dd.append((self.r, len(self.v)))
        return self.r, self.v

    def find(self, k):
         # if necessary start again
        if self.k<k: self.__init__(self.points, self.metric)
         # step until we get k clusters
        while self.k>k: self.step()
         # return list of cluster members
        return self.r, self.v
\end{lstlisting}

Given a set of points, we can determine the most likely number of clusters representing the data, and we can make a plot of the number of clusters versus distance and look for a plateau in the plot. In correspondence with the plateau, we can read from the $y$-coordinate the number of clusters. This is done by the function {\ft cluster} in the preceding algorithm, which returns the average distance between clusters and a list of clusters.

For example:

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
>>> def metric(a, b):
...     return math.sqrt(sum((x-b[i]) ** 2 for i, x in enumerate(a)))
>>> points = [[random.gauss(i % 5, 0.3) for j in range(10)] for i in range(200)]
>>> c = Cluster(points, metric)
>>> r, clusters = c.find(1)  # cluster all points until one cluster only
>>> Canvas(title="clustering example", xlab="distance", ylab="number of clusters"
...       ).plot(c.dd[150:]).save("clustering1.png")
>>> Canvas(title="clustering example (2d projection)", xlab="p[0]", ylab="p[1]"
...       ).ellipses([p[:2] for p in points]).save("clustering2.png")
\end{lstlisting}

With our sample data, we obtain the following plot (``clustering1.png''):

\begin{figure}[ht]
\centering\includegraphics[width=4in]{images/clustering1.png}
\caption{Number of clusters found as a function of the distance cutoff.}
\end{figure}

and the location where the curve bends corresponds to five clusters. Although our points live in 10 dimensions, we can try to project them into two dimensions and see the five clusters (``clustering2.png''):

\begin{figure}[ht]
\centering\includegraphics[width=4in]{images/clustering2.png}
\caption{Visual representation of the clusters where the points coordinates are projected in 2D.}
\end{figure}

\goodbreak\subsection{Neural network}

\index{neural network}

An artificial {\it neural network} is an electrical circuit (usually simulated in software) that mimics the functionality of the neurons in the animal (and human) brain~\cite{neural}. It is usually employed in pattern recognition. The network consists of a set of simulated neurons, connected by links (synapses). Some links connect the neurons with each other, some connect the neurons with the input and some with the output. Neurons are usually organized in the layers with one {\it input layer} of neurons connected only with the input and the next layer.  Another one, the {\it output layer}, comprises neurons connected only with the output and previous layers, or many {\it hidden layers} of neurons connected only with other neurons.
Each neuron is characterized by input links and output links. Each output of a neuron is a function of its inputs. The exact shape of that function depends on the network and on parameters that can be adjusted. Usually this function is chosen to be a monotonic increasing function on the sum of the inputs, where both the inputs and the outputs take values in the [0, 1] range. The inputs can be thought as electrical signals reaching the neuron. The output is the electrical signal emitted by the neuron. Each neuron is defined by a set of parameters {\ft a} which determined the relative weight of the input signals. A common choice for this characteristic function is:

\begin{equation}
\textrm{output}_{ij} = \tanh(\sum_k a_{ijk} \textrm{input}_{ik})
\end{equation}

where $i$ labels the neuron, $j$ labels the output, $k$ labels the input, and $a_{ijk}$ are characteristic parameters describing the neurons.

The network is trained by providing an input and adjusting the characteristics $a_{ijk}$ of each neuron $k$ to produce the expected output. The network is trained iteratively until its parameters converge (if they converge), and then it is ready to make predictions. We say the network has learned from the training data set.

\begin{figure}[ht]
\centering\includegraphics[width=4in]{images/neural.png}
\caption{Example of a minimalist neural network.}
\end{figure}

\index{class!NeuralNetwork}

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
class NeuralNetwork:
    """
    Back-Propagation Neural Networks
    Placed in the public domain.
    Original author: Neil Schemenauer <nas@arctrix.com>
    Modified by: Massimo Di Pierro
    Read more: http://www.ibm.com/developerworks/library/l-neural/
    """

    @staticmethod
    def rand(a, b):
        """ calculate a random number where:  a <= rand < b """
        return (b-a) * random.random() + a

    @staticmethod
    def sigmoid(x):
        """ our sigmoid function, tanh is a little nicer than the standard 1/(1+e^-x) """
        return math.tanh(x)

    @staticmethod
    def dsigmoid(y):
        """  # derivative of our sigmoid function, in terms of the output """
        return 1.0 - y ** 2

    def __init__(self, ni, nh, no):
         # number of input, hidden, and output nodes
        self.ni = ni + 1  # +1 for bias node
        self.nh = nh
        self.no = no

         # activations for nodes
        self.ai = [1.0] * self.ni
        self.ah = [1.0] * self.nh
        self.ao = [1.0] * self.no

         # create weights
        self.wi = Matrix(self.ni, self.nh, fill=lambda r, c: self.rand(-0.2, 0.2))
        self.wo = Matrix(self.nh, self.no, fill=lambda r, c: self.rand(-2.0, 2.0))

         # last change in weights for momentum
        self.ci = Matrix(self.ni, self.nh)
        self.co = Matrix(self.nh, self.no)

    def update(self, inputs):
        if len(inputs) != self.ni-1:
            raise ValueError("wrong number of inputs")

         # input activations
        for i in range(self.ni-1):
            self.ai[i] = inputs[i]

         # hidden activations
        for j in range(self.nh):
            s = sum(self.ai[i] * self.wi[i, j] for i in range(self.ni))
            self.ah[j] = self.sigmoid(s)

         # output activations
        for k in range(self.no):
            s = sum(self.ah[j] * self.wo[j, k] for j in range(self.nh))
            self.ao[k] = self.sigmoid(s)
        return self.ao[:]

    def back_propagate(self, targets, N, M):
        if len(targets) != self.no:
            raise ValueError("wrong number of target values")

         # calculate error terms for output
        output_deltas = [0.0] * self.no
        for k in range(self.no):
            error = targets[k]-self.ao[k]
            output_deltas[k] = self.dsigmoid(self.ao[k]) * error

         # calculate error terms for hidden
        hidden_deltas = [0.0] * self.nh
        for j in range(self.nh):
            error = sum(output_deltas[k] * self.wo[j, k] for k in range(self.no))
            hidden_deltas[j] = self.dsigmoid(self.ah[j]) * error

         # update output weights
        for j in range(self.nh):
            for k in range(self.no):
                change = output_deltas[k] * self.ah[j]
                self.wo[j, k] = self.wo[j, k] + N * change + M * self.co[j, k]
                self.co[j, k] = change

         # update input weights
        for i in range(self.ni):
            for j in range(self.nh):
                change = hidden_deltas[j] * self.ai[i]
                self.wi[i, j] = self.wi[i, j] + N * change + M * self.ci[i, j]
                self.ci[i, j] = change

         # calculate error
        error = sum(0.5 * (targets[k]-self.ao[k]) ** 2 for k in range(len(targets)))
        return error

    def test(self, patterns):
        for p in patterns:
            print(p[0], "->", self.update(p[0]))

    def weights(self):
        print("Input weights:")
        for i in range(self.ni):
            print(self.wi[i])
        print()
        print("Output weights:")
        for j in range(self.nh):
            print(self.wo[j])

    def train(self, patterns, iterations=1000, N=0.5, M=0.1, check=False):
         # N: learning rate
         # M: momentum factor
        for i in range(iterations):
            error = 0.0
            for p in patterns:
                inputs = p[0]
                targets = p[1]
                self.update(inputs)
                error = error + self.back_propagate(targets, N, M)
            if check and i % 100 == 0:
                print("error %-14f" % error)
\end{lstlisting}

In the following example, we teach the network the XOR function, and we create a network with two inputs, two intermediate neurons, and one output. We train it and check what it learned:

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
>>> pat = [[[0, 0], [0]], [[0, 1], [1]], [[1, 0], [1]], [[1, 1], [0]]]
>>> n = NeuralNetwork(2, 2, 1)
>>> n.train(pat)
>>> n.test(pat)
[0, 0] -> [0.00...]
[0, 1] -> [0.98...]
[1, 0] -> [0.98...]
[1, 1] -> [-0.00...]
\end{lstlisting}

Now, we use our neural network to learn patterns in stock prices and predict the next day return. We then check what it has learned, comparing the sign of the prediction with the sign of the actual return for the same days used to train the network:
%%% META:FILE:test.py
\begin{lstlisting}[caption={in file: {\ft test.py}}]
>>> storage = PersistentDictionary("sp100.sqlite")
>>> v = [day["arithmetic_return"] * 300 for day in storage["AAPL/2011"][1:]]
>>> pat = [[v[i:i+5], [v[i+5]]] for i in range(len(v)-5)]
>>> n = NeuralNetwork(5, 5, 1)
>>> n.train(pat)
>>> predictions = [n.update(item[0]) for item in pat]
>>> success_rate = sum(1.0 for i, e in enumerate(predictions)
...                    if e[0] * v[i+5]>0)/len(pat)
\end{lstlisting}
The learning process depends on the random number generator; therefore, sometimes, for this small training data set, the network succeeds in predicting the sign of the next day arithmetic return of the stock with more than 50\% probability, and sometimes it does not. We leave it to the reader to study the significance of this result but using a different subset of the data for the training of the network and for testing its success rate.

\goodbreak\subsection{Genetic algorithms}

\index{genetic algorithms}

Here we consider a simple example of genetic algorithms~\cite{barricelli}.

We have a population of chromosomes in which each chromosome is just a data structure, in our example, a string of random ``ATGC'' characters.

We also have a metric to measure the fitness of each chromosome.

At each iteration, only the top-ranking chromosomes in the population survive. The top 10 mate with each other, and their offspring constitute the population for the next iteration. When two members of the population mate, the newborn member of the population has a new DNA sequence, half of which comes from the father and half from the mother, with two randomly mutated DNA basis.

The algorithm stops when we reach a maximum number of generations or we find a chromosome of the population with maximum fitness.

In the following example, the fitness is measured by the similarity between a chromosome and a random target chromosome. The population evolves to approximate better and better that one random target chromosome:

\index{class!Chromosome}

%%% META:FILE:genetic.py
\begin{lstlisting}
from random import randint, choice

class Chromosome:
    alphabet = "ATGC"
    size = 32
    mutations = 2
    def __init__(self, father=None, mother=None):
        if not father or not mother:
            self.dna = [choice(self.alphabet) for i in range(self.size)]
        else:
            self.dna = father.dna[:self.size/2]+mother.dna[self.size/2:]
            for mutation in range(self.mutations):
                self.dna[randint(0, self.size-1)] = choice(self.alphabet)
    def fitness(self, target):
        return sum(1 for i, c in enumerate(self.dna) if c == target.dna[i])

def top(population, target, n=10):
    table = [(chromo.fitness(target), chromo) for chromo in population]
    table.sort(reverse = True)
    return [row[1] for row in table][:n]

def oneof(population):
    return population[randint(0, len(population)-1)]

def main():
    GENERATIONS = 10000
    OFFSPRING = 20
    SEEDS = 20
    TARGET = Chromosome()

    population = [Chromosome() for i in range(SEEDS)]
    for i in range(GENERATIONS):
        print("\n\nGENERATION:", i)
        print(0, TARGET.dna)
        fittest = top(population, TARGET)
        for chromosome in fittest: print(i, chromosome.dna)
        if max(chromo.fitness(TARGET) for chromo in fittest) == Chromosome.size:
            print("SOLUTION FOUND")
            break
        population = [Chromosome(father=oneof(fittest), mother=oneof(fittest)) \
                      for i in range(OFFSPRING)]

if __name__ == "__main__": main()
\end{lstlisting}

Notice that this algorithm can easily be modified to accommodate other fitness metrics and DNA that consists of a data structure other than a sequence of ``ATGC'' symbols. The only trickery is finding a proper mating algorithm that preserves some of the fitness features of the parents in the DNA of their offspring. If this does not happen, each next generation loses the fitness properties gained by its parents, thus causing the algorithm not to converge. In our case, it works because if the parents are ``close'' to the target, then half of the DNA of each parent is also close to the corresponding half of the target DNA. Therefore the DNA of the offspring is as fit as the average of their parents. On top of this, the two random mutations allow the algorithm to further explore the space of all possible DNA sequences.

\goodbreak\section{Long and infinite loops}
\index{P}\index{NP}\index{NPC}\index{EXP}
\goodbreak\subsection{P, NP, and NPC}

We say a problem is in P if it can be solved in polynomial time: $%
T_{worst}\in O(n^\alpha )$ for some $\alpha $.

We say a problem is in NP if an input string can be verified to be a
solution in polynomial time: $T_{worst}\in O(n^\alpha )$ for some $\alpha $.

We say a problem is in co-NP if an input string can be verified not to be a
solution in polynomial time: $T_{worst}\in O(n^\alpha )$ for some $\alpha $.

We say a problem is in NPH (NP Hard) if it is harder than any other problem
in NP.

We say a problem is in NPC (NP Complete) if it is in NP and in NPH.
Consequences:
\begin{equation}
\text{if }\exists x\text{ }|\text{ }x\in NPC\text{ and }x\in P\Rightarrow
\forall y\in NP, y\in P
\end{equation}

There are a number of open problems about the relations among these sets.
Is the set co-NP equivalent to NP? Or perhaps is the intersection between co-NP and NP equal to P?
Are NP and NPC the same set? These questions are very important in computer science because if, for example, NP turns out to be the same set as NPC, it means that it must be possible to find algorithms that solve in polynomial time problems that currently do not have a polynomial time solution. Conversely, if one could prove that NP is not equivalent to NPC, we would know that a polynomial time solution to NPC problems does not exist~\cite{pnp}.

\subsection{Cantor"s argument}

\index{Cantor"s argument}

Cantor proved that the real numbers in any interval (e.g., in $[0, 1)$)
are more than the integer numbers, therefore real numbers are uncountable~\cite{hofstadter}.
The proof proceeds as follows:

\begin{enumerate}
\item  Consider the real numbers in the interval $[0, 1)$ not including 1$.$

\item  Assume that these real numbers are countable. Therefore it is
possible to associate each of them to an integer
\begin{equation}
\begin{tabular}{lll}
1 & $\longleftrightarrow $ & $0.xxxxxxxxxxx...$ \\
2 & $\longleftrightarrow $ & $0.xxxxxxxxxxx...$ \\
3 & $\longleftrightarrow $ & $0.xxxxxxxxxxx...$ \\
4 & $\longleftrightarrow $ & $0.xxxxxxxxxxx...$ \\
5 & $\longleftrightarrow $ & $0.xxxxxxxxxxx...$ \\
... & ... & ...
\end{tabular}
\label{cantor}
\end{equation}
(here $x$ represent a decimal digit of a real numbers)

\item  Now construct a number $\alpha =0.yyyyyyyy....$ where the first
decimal digit differs from the first decimal digit of the first real number
of table \ref{cantor}, the second decimal digit differs from the second
decimal digit of the second real number of table \ref{cantor}, and so on and
so on for all the infinite decimal digits:
\begin{equation}
\begin{tabular}{lll}
1 & $\longleftrightarrow $ & $0.\overline{x}xxxxxxxxxx...$ \\
2 & $\longleftrightarrow $ & $0.x\overline{x}xxxxxxxxx...$ \\
3 & $\longleftrightarrow $ & $0.xx\overline{x}xxxxxxxx...$ \\
4 & $\longleftrightarrow $ & $0.xxx\overline{x}xxxxxxx...$ \\
5 & $\longleftrightarrow $ & $0.xxxx\overline{x}xxxxxx...$ \\
... & ... & ...
\end{tabular}
\label{cantor2}
\end{equation}

\item  The new number $\alpha $ is a real number, and by construction, it is
not in the table. In fact, it differs with each item by at least one decimal
digit. Therefore the existence of $\alpha $ disproves the assumption that
all real numbers in the interval $[0, 1)$ are listed in the table.
\end{enumerate}

There is a very practical consequence of this argument. In fact, in chapter 2, we have seen the distinction between type {\ft float} and class {\ft Decimal}. We have seen about pitfalls of {\ft float} and how {\ft Decimal} can represent floating point numbers with arbitrary precision (assuming we have the memory to do so). Cantor"s argument tells us there are numbers that cannot even be represented as {\ft Decimal} because they would require an infinite amount of storage; $\pi$ and $e$ are examples of these numbers.

\subsection{G\"odel"s theorem}

\index{G\"odel"s theorem}

G\"odel used a similar diagonal argument to prove that there are as many
problems (or theorems) as real numbers and as many algorithms (or proofs) as
natural numbers~\cite{hofstadter}. Because there is more of the former than the latter, it
follows that there are problems for which there is no corresponding solving
algorithm. Another interpretation of G\"odel"s theorem is that, in any formal
language, for example, mathematics, there are theorems that cannot be proved.

Another consequence of G\"odel"s theorem is the following:
it is impossible to write a computer program to test if a given algorithm
stops or enters into an infinite loop.

Consider the following code:

\begin{lstlisting}
def next(i):
    while len(set(str(i * i))) > 2:
        i=i+2
    print(i)

next(81621)
\end{lstlisting}

This code check searches for a number equal or greater than 81621 which square is comprised of only two digits. 
Nobody knows whether such number exists, therefore nobody knows if this code stops.

Although one day this problem may be solved, there are many other problems that
are still unsolved; actually, there are an infinite number of them.

\chapter{Numerical Algorithms}

\goodbreak\section{Well-posed and stable problems}

\index{well-posed problems}
\index{stable problems}

Numerical algorithms deal mostly with well-posed and stable problems.

A problem is well posed if
\begin{itemize}
\item The solution exists and is unique
\item The solution has a continuous dependence on input data (a small change in the input causes a small change in the output)
\end{itemize}

\index{critical points}\index{chaos}

Most physical problems are well posed, except at {\it critical points}, where any infinitesimal variation in one of the input parameters of the system can cause a large change in the output and therefore in the behavior of the system. This is called {\it chaos}.

Consider the case of dropping a ball on a triangular-shaped mountain. Let the input of the problem be the horizontal position where the drop occurs and the output the horizontal position of the ball after a fixed amount of time. Almost anywhere the ball is dropped, it will roll down the mountain following deterministic and classical laws of physics, thus the position is calculable and a continuous function of the input position. This is true everywhere, except when the ball is dropped on top of the peak of the mountain. In this case, a minor infinitesimal variation to the right or to the left can make the ball roll to the right or to the left, respectively.  Therefore this is not a well posed problem.

A problem is said to be {\it stable} if the solution is not just continuous but also weakly sensitive to input data. This means that the change of the output (in percent) is smaller than the change in the input (in percent).

Numerical algorithms work best with stable problems.

We can quantify this as follows. Let $x$ be an input and $y$ be the output of a function:
\begin{equation}
y = f(x)
\end{equation}
We define the condition number of $f$ in $x$ as

\index{condition number}

\begin{equation}
\func{cond}(f, x) \equiv \frac{|dy/y|}{|dx/x|} = |x f'(x)/f(x)|
\end{equation}
(the latter equality only holds if $f$ is differentiable in $x$).

A problem with a low condition number is said to be well-conditioned, while a problem with a high condition number is said to be ill-conditioned. XXX

We say that a problem characterized by a function $f$ is well conditioned in a domain $D$ if the condition number is less than 1 for every input in the domain. We also say that a problem is stable if it is well conditioned.

In this book, we are mostly concerned with stable (well-conditioned) problems. If a problem is well-conditioned in for all input in a domain, it is also stable.


\goodbreak\section{Approximations and error analysis}

\index{error analysis}

Consider a physical quantity, for example, the length of a nail. Given one nail, we can measure its length by choosing a measuring instrument. Whatever instrument we choose, we will be able to measure the length of the nail within the resolution of the instrument. For example, with a tape measure with a resolution of 1 mm, we will only be able to determine the length of the nail within 1 mm of resolution. Repeated measurements performed at different times, by different people, using different instruments may bring different results. We can choose a more precise instrument, but it would not change the fact that different measures will bring different values compatible with the resolution of the instrument. Eventually one will have to face the fact that there may not be such a thing as the length of a nail. For example, the length varies with the temperature and the details of how the measurement is performed. In fact, a nail (as everything else) is made out of atoms, which are made of protons, neutrons, and electrons, which determine an electromagnetic cloud that fluctuates in space and time and depends on the surrounding objects and interacts with the instrument of measure. The length of the nail is the result of a measure.

For each measure there is a result, but the results of multiple measurements are not identical. The results of many measurements performed with the same resolution can be summarized in a distribution of results. This distribution will have a mean $\bar x$ and a standard deviation $\delta x$, which we call uncertainty. From now on, unless otherwise specified, we assume that the distribution of results is Gaussian so that $\bar x$ can be interpreted as the mean and $\delta x$ as the standard deviation.

Now let us consider a system that, given an input $x$, produces the output $y$; $x$ and $y$ are physical quantities that we can measure, although only with a finite resolution. We can model the system with a function $f$ such that $y = f(x)$ and, in general, $f$ is not known.

We have to make various approximations:
\begin{itemize}
\item We can replace the ``true'' value for the input with our best estimate, $\bar x$, and its associated uncertainty, $\delta x$.

\item We can replace the ``true'' value for the output with our best estimate, $\bar y$, and its associated uncertainty, $\delta y$.

\item Even if we know there is a ``true'' function $f$ describing the system, our implementation for the function is always an approximation, $\bar f$. In fact,  we may not have a single approximation but a series of approximations of increasing precision, $f_n$, which become more and more accurate (usually) as $n$ increases. If we are lucky, up to precision errors, as $n$ increases, our approximations will become closer and closer to $f$, but this will take an infinite amount of time. We have to stop at some finite $n$.
\end{itemize}

\index{data error}\index{computational error}\index{statistical error}\index{systematic error}\index{total error}\index{propagated data error}

With the preceding definition, we can define the following types of errors:

\begin{itemize}
\item {\bf Data error}: the difference between $x$ and $\bar x$.

\item {\bf Computational error}: the difference between $\bar f(\bar x)$ and $y$.
Computational error includes two parts systematic error and statistical error.

\item {\bf Statistical error}: due to the fact that, often, the computation of $\bar f(x) = \lim_{n\rightarrow\infty} f_n(x)$ is too computationally expensive and we must approximate $\bar f(x)$ with $f_n(x)$. This error can be estimated and controlled.

\item {\bf Systematic error}: due to the fact that $\bar f(x) = \lim_{n\rightarrow\infty} f_n(x) \neq f(x)$. This is for two reasons: modeling errors (we do not know $f(x)$) and rounding errors (we do not implement $f(x)$ with arbitrary precision arithmetics).

\item {\bf Total error}: defined as the computational error + the propagated data error and in a formula:
\begin{equation}
\delta y = |f(\bar x)-f_n(\bar x)| + |f'_n(\bar x)|\delta x
\end{equation}
The first term is the computational error (we use $f_n$ instead of the true $f$), and the second term is the propagated data error ($\delta x$, the uncertainty in $x$, propagates through $f_n$).
\end{itemize}


\goodbreak\subsection{Error propagation}

\index{error propagation}

When a variable $x$ has a finite Gaussian uncertainty $\delta x$, how does the uncertainty propagate through a function $f$? Assuming the uncertainty is small, we can always expand using a Taylor series:

\begin{equation}
y+\delta y = f(x+\delta x) = f(x) + f'(x)\delta x + O(\delta x^2)
\end{equation}
And because we interpret $\delta y$ as the width of the distribution $y$, it should be positive:
\begin{equation}
  \delta y = |f'(x)|\delta x
\end{equation}

We have used this formula before for the propagated data error.
For functions of two variables $z = f(x, y)$ and assuming the uncertainties in $x$ and $y$ are independent, 

\begin{equation}
  \delta z = \sqrt{\left|\frac{\partial f(x, y)}{\partial x}\right|^2\delta x^2 +
\left|\frac{\partial f(x, y)}{\partial y}\right|^2\delta y^2 }
\end{equation}

which for simple arithmetic operations reduces to

\begin{tabular}{ll}
  $z = x + y$ &
  $\delta z = \sqrt{\delta x^2 + \delta y^2 }$ \\
  $z = x - y$ &
  $\delta z = \sqrt{\delta x^2 + \delta y^2 }$ \\
  $z = x * y$ &
  $\delta z = |x * y|\sqrt{(\delta x/x)^2 + (\delta y/y)^2 }$ \\
  $z = x / y$ &
  $\delta z = |x/y|\sqrt{(\delta x/x)^2 + (\delta y/y)^2 }$ \\
\end{tabular}

Notice that when $z=x-y$ approaches zero, the uncertainty in $z$ is larger than the uncertainty in $x$ and $y$ and can overwhelm the result.
Also notice that if $z=x/y$ and $y$ is small compared to $x$, then the uncertainty in $z$ can be large.
Bottom line: try to avoid differences between numbers that are in proximity of each other and try to avoid dividing by small numbers.

\goodbreak\subsection{{\ft buckingham}}

Buckingham is a Python library that implements error propagation and unit conversion. It defines a single class called {\ft Number}, and a number object has value, an uncertainty, and a dimensionality (e.g., length, volume, mass).

Here is an example:

\begin{lstlisting}
>>> from buckingham import * 
>>> globals().update(allunits())
>>> L = (4 + pm(0.5)) * meter
>>> v = 5 * meter/second
>>> t = L/v
>>> t)                                                                                               
(8.00 +/- 1.00)/10
>>> t.units()
second
>>> t.convert("hour")
(2.222 +/- 0.278)/10^4
\end{lstlisting}

Notice how adding an uncertainty to a numeric value with {\ft +\\pm(...)} or adding units to a numeric value (integer or floating point) transforms the {\ft float} number into a {\ft Number} object. A {\ft Number} object behaves like a floating point but propagates its uncertainty and its units.  Internally, all units are converted to the International System, unless an explicit conversion is specified.

\goodbreak\section{Standard strategies}

Here are some strategies that are normally employed in numerical algorithms:

\begin{itemize}
\item Approximate a continuous system with a discrete system
\item Replace integrals with sums
\item Replace derivatives with finite differences
\item Replace nonlinear with linear + corrections
\item Transform a problem into a different one
\item Approach the true result by iterations
\end{itemize}

Here are some examples of each of the strategies.

\goodbreak\subsection{Approximate continuous with discrete}

Consider a ball in a one-dimensional box of size $L$, and let $x$ be the position of the ball in the box. Instead of treating $x$ as a continuous variable, we can assume a finite resolution of $h = L/n$ (where $h$ is the minimum distance we can distinguish without instruments and $n$ is the maximum number of distinct discrete points we can discriminate), and set $x \equiv h i$, where $i$ is an integer in between $0$ and $n$; $x=0$ when $i=0$ and $x=L$ when $i=n$.


\goodbreak\subsection{Replace derivatives with finite differences}

\index{derivative}\index{finite differences}

Computing $\textrm{d}f(x)/\textrm{d}x$ analytically is only possible when the function $f$ is expressed in simple analytical terms. Computing it analytically is not possible when $f(x)$ is itself implemented as a numerical algorithm. Here is an example:

\begin{lstlisting}
def f(x):
    (s, t) = (1.0, 1.0)
    for i in range(1, 10): (s, t) = (s+t, t * x/i)
    return s
\end{lstlisting}

What is the derivative of $f(x)$?

The most common ways to define a derivative are the right derivative

\begin{equation}
  \frac{\textrm{d}f^{+}(x)}{\textrm{d}x} = \lim_{h\rightarrow 0}
  \frac{f(x+h)-f(x)}{h}
\end{equation}
the left derivative
\begin{equation}
  \frac{\textrm{d}f^{-}(x)}{\textrm{d}x} = \lim_{h\rightarrow 0}\
  \frac{f(x)-f(x-h)}{h}
\end{equation}
and the average of the two
\begin{equation}
  \frac{\textrm{d}f(x)}{\textrm{d}x} = \frac12\left(
  \frac{\textrm{d}f^{+}(x)}{\textrm{d}x} +
  \frac{\textrm{d}f^{-}(x)}{\textrm{d}x} \right) =
  \lim_{h\rightarrow 0}\frac{f(x+h)-f(x-h)}{2h}
\end{equation}

If the function is differentiable in $x$, then, by definition of ``differentiable, '' the left and right definitions are equal, and the three prior definitions are equivalent. We can pick one or the other, and the difference will be a systematic error.

If the limit exists, then it means that

\begin{equation}
\frac{\textrm{d}f(x)}{\textrm{d}x} = \frac{f(x+h)-f(x-h)}{2h} + O(h)
\end{equation}

where $O(h)$ indicates a correction that, at most, is proportional to $h$.

The three definitions are equivalent for functions that are differentiable in $x$, and the latter is preferable because it is more symmetric.

Notice that even more definitions are possible as long as they agree in the limit $h\rightarrow 0$. Definitions that converge faster as $h$ goes to zero are referred to as ``improvement.''


\index{functional}

We can easily implement the concept of a numerical derivative in code by creating a {\it functional} $D$ that takes a function $f$ and returns the function $\frac{\textrm{d}f(x)}{\textrm{d}x}$ (a functional is a function that returns another function):

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
def D(f, h=1e-6):  # first derivative of f
    return lambda x, f=f, h=h: (f(x+h)-f(x-h))/2/h
\end{lstlisting}

We can do the same with the second derivative:

\begin{equation}
  \frac{\textrm{d}^2f(x)}{\textrm{d}x^2} = \frac{f(x+h)-2f(x)-f(x-h)}{h^2} + O(h)
\end{equation}

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
def DD(f, h=1e-6):  # second derivative of f
    return lambda x, f=f, h=h: (f(x+h)-2.0 * f(x)+f(x-h))/(h * h)
\end{lstlisting}

Here is an example:

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
>>> def f(x): return x * x-5.0 * x
>>> f(0)
0.0
>>> f1 = D(f)  # first derivative
>>> f1(0)
-5.0
>>> f2 = DD(f)  # second derivative
>>> f2(0)
2.00000...
>>> f2 = D(f1)  # second derivative
>>> f2(0)
1.99999...
\end{lstlisting}

Notice how composing the first derivative twice or computing the second derivative directly yields a similar result.

We could easily derive formulas for higher-order derivatives and implement them, but they are rarely needed.

\goodbreak\subsection{Replace nonlinear with linear}

\index{linear approximation}

Suppose we are interested in the values of $f(x)=\sin(x)$ for values of $x$ between $0$ and $0.1$:

\begin{lstlisting}
>>> from math import sin
>>> points = [0.01 * i for i in range(0, 11)]
>>> for x in points:
...     print(x, sin(x), "%.2f" % (abs(x-sin(x))/sin(x) * 100))
0.01 0.009999833... 0.00
0.02 0.019998666... 0.01
0.03 0.029995500... 0.02
0.04 0.039989334... 0.03
0.05 0.049979169... 0.04
0.06 0.059964006... 0.06
0.07 0.069942847... 0.08
0.08 0.079914693... 0.11
0.09 0.089878549... 0.14
0.1 0.0998334166... 0.17
\end{lstlisting}
Here the first column is the value of $x$, the second column is the corresponding $\sin(x)$, and the third column is the relative difference (in percent) between $x$ and $\sin(x)$. The difference is always less than $20\%$; therefore, if we are happy with this precision, then we can replace $\sin(x)$ with $x$.

This works because any function $f(x)$ can be expanded using a Taylor series. The first order of the Taylor expansion is linear. For values of $x$ sufficiently close to the expansion point, the function can therefore be approximated with its Taylor expansion.

Expanding on the previous example, consider the following code:

\begin{lstlisting}
>>> from math import sin
>>> points = [0.01 * i for i in range(0, 11)]
>>> for x in points:
...     s = x - x * x * x/6
...     print(x, math.sin(x), s, ``%.6f'' % (abs(s-sin(x))/(sin(x)) * 100))
0.01 0.009999833... 0.009999... 0.000000
0.02 0.019998666... 0.019998... 0.000000
0.03 0.029995500... 0.029995... 0.000001
0.04 0.039989334... 0.039989... 0.000002
0.05 0.049979169... 0.049979... 0.000005
0.06 0.059964006... 0.059964... 0.000011
0.07 0.069942847... 0.069942... 0.000020
0.08 0.079914693... 0.079914... 0.000034
0.09 0.089878549... 0.089878... 0.000055
0.1 0.0998334166... 0.099833... 0.000083
\end{lstlisting}

Notice that the third column $s = x - x^3/6$ is very close to $\sin(x)$. In fact, the difference is less than one part in 10, 000 (fourth column). Therefore, for $x \in [-1, +1]$, it is possible to replace the $sin(x)$ function with the $x-x^3/6$ polynomial. Here we just went one step further in the Taylor expansion, replacing the first order with the third order. The error committed in this approximation is very small.


\goodbreak\subsection{Transform a problem into a different one}

Continuing with the previous example, the polynomial approximation for the sin function works when $x$ is smaller than $1$ but fails when $x$ is greater than or equal to $1$. In this case, we can use the following relations to reduce the computation of $\sin(x)$ for large $x$ to $\sin(x)$ for $0<x<1$. In particular, we can use

\begin{equation}
\sin(x) = -\sin(-x) \textrm{when} x < 0
\end{equation}

to reduce the domain to $x \in [0, \infty]$. We can then use

\begin{equation}
\sin(x) = \sin(x - 2k\pi) \qquad k\in {\Bbb N}
\end{equation}

to reduce the domain to $x \in [0, 2\pi)$

\begin{equation}
\sin(x) = -\sin(2\pi - x)
\end{equation}

to reduce the domain to $x \in [0, \pi)$

\begin{equation}
\sin(x) = \sin(\pi - x)
\end{equation}

to reduce the domain to $x \in [0, \pi/2)$, and

\begin{equation}
\sin(x) = \sqrt{1 - \sin(\pi/2 - x)^2}
\end{equation}

to reduce the domain to $x \in [0, \pi/4)$, where the latter is a subset of $[0, 1)$.

\goodbreak\subsection{Approximate the true result via iteration}

\index{approximations}

The approximations $\sin(x) \simeq x$ and $\sin(x) \simeq x - x^3/6$ came from linearizing the function $\sin(x)$ and adding a correction to the previous approximation, respectively. In general, we can iterate the process of finding corrections and approximating the true result.

Here is an example of a general iterative algorithm:
\begin{lstlisting}
result=guess
loop:
    compute correction
    result=result+correction
    if result sufficiently close to true result:
        return result
\end{lstlisting}

For the $\sin$ function:

\begin{lstlisting}
def mysin(x):
    (s, t) = (0.0, x)
    for i in range(3, 10, 2): (s, t) = (s+t, -t * x * x/i/(i-1))
    return s
\end{lstlisting}

Where do these formulas come from? How do we decide how many iterations we need? We address these problems in the next section.


\goodbreak\subsection{Taylor series}

\index{Taylor series}\index{Taylor Theorem}

A function $f(x):{\Bbb R}\rightarrow{\Bbb R}$ is said to be a {\it real analytical} in $\bar x$ if it is continuous in $x=\bar x$ and all its derivatives exist and are continuous in $x=\bar x$.

When this is the case, the function can be locally approximated with a local power series:

\begin{equation}
f(x) = f(\bar x) + f^{(0)}(\bar x)(x-\bar x) + ... + \frac{f^{(k)}(\bar x)}{n!}(x-\bar x)^k + R_k
\end{equation}

The remainder $R_k$ can be proven to be (Taylor"s theorem):
\begin{equation}
R_k = \frac{f^{(k+1)}(\xi)}{(k+1)!}(x-\bar x)^{k+1}
\end{equation}
where $\xi$ is a point in between $x$ and $\bar x$. Therefore, if $f^{(k+1)}$ exists and is limited within a neighborhood $D = \{x~\textrm{for}~|x-\bar x|<\epsilon\}$, then
\begin{equation}
|R_k| < \left| max_{x\in D} f^{(k+1)} \right| |(x-\bar x)^{k+1}|
\end{equation}

If we stop the Taylor expansion at a finite value of $k$, the preceding formula gives us the statistical error part of the computational error.

Some Taylor series are very easy to compute:

Exponential for $\bar x = 0$:

\begin{eqnarray}
f(x) &=& e^x \\
f^{(1)}(x) &=& e^x \\
... && ... \\
f^{(k)}(x) &=& e^x \\
e^x &=&  1 + x + \frac12 x^2 + ... + \frac1{k!}x^k + ...
\end{eqnarray}

Sin for $\bar x = 0$:

\begin{eqnarray}
f(x) &=& sin(x) \\
f^{(1)}(x) &=& cos(x) \\
f^{(2)}(x) &=& -sin(x) \\
f^{(3)}(x) &=& -cos(x) \\
... && ... \\
sin(x) &=&  x - \frac1{3!}x^3 + ... + \frac{(-1)^n}{(2k+1)!}x^{(2k+1)} + ...
\end{eqnarray}

We can show the effects of the various terms:

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
>>> X = [0.03 * i for i in range(200)]
>>> c = Canvas(title="sin(x) approximations")
>>> c.plot([(x, math.sin(x)) for x in X], legend="sin(x)")
<...>
>>> c.plot([(x, x) for x in X[:100]], legend="Taylor 1st")
<...>
>>> c.plot([(x, x-x ** 3/6) for x in X[:100]], legend="Taylor 5th")
<...>
>>> c.plot([(x, x-x ** 3/6+x ** 5/120) for x in X[:100]], legend="Taylor 5th")
<...>
>>> c.save("images/sin.png")
\end{lstlisting}

\begin{figure}[ht]
\centering\includegraphics[width=4in]{images/sin.png}
\caption{The figure shows the $\sin$ function and its approximation using the Taylor expansion around $x=0$ at different orders.}
\end{figure}

Notice that we can very well expand in Taylor around any other point, for example, $\bar x = \pi/2$, and we get

\begin{equation}
sin(x) =  1 - \frac1{2}(x-\frac{\pi}{2})^2 + ... + \frac{(-1)^n}{(2k)!}(x-\frac{\pi}{2})^{(2k)} + ...
\end{equation}

and a plot would show:

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
>>> a = math.pi/2
>>> X = [0.03 * i for i in range(200)]
>>> c = Canvas(title="sin(x) approximations")
>>> c.plot([(x, math.sin(x)) for x in X], legend="sin(x)")
<...>
>>> c.plot([(x, 1-(x-a) ** 2/2) for x in X[:150]], legend="Taylor 2nd")
<...>
>>> c.plot([(x, 1-(x-a) ** 2/2+(x-a) ** 4/24) for x in X[:150]], legend="Taylor 4th")
<...>
>>> c.plot([(x, 1-(x-a) ** 2/2+(x-a) ** 4/24-(x-a) ** 6/720) for x in X[:150]], legend="Taylor 6th")
<...>
>>> c.save("images/sin2.png")
\end{lstlisting}

\begin{figure}[ht]
\centering\includegraphics[width=4in]{images/sin2.png}
\caption{The figure shows the $\sin$ function and its approximation using the Taylor expansion around $x=\pi/2$ at different orders.}
\end{figure}

Similarly we can expand the $\cos$ function around $\bar x = 0$. Not accidentally, we would get the same coefficients as the Taylor expansion of the $\sin$ function around $\bar x = \pi/2$. In fact, $\sin(x) = \cos(x-\pi/2)$:

\begin{eqnarray}
f(x) &=& cos(x) \\
f^{(1)}(x) &=& -sin(x) \\
f^{(2)}(x) &=& -cos(x) \\
f^{(3)}(x) &=& sin(x) \\
... && ... \\
cos(x) &=&  1 - \frac1{2}x^2 + ... + \frac{(-1)^n}{(2k)!}x^{(2k)} + ...
\end{eqnarray}

With a simple replacement, it is easy to prove that
\begin{equation}
e^{ix} = \cos(x) + i \sin(x)
\end{equation}
which will be useful when we talk about Fourier and Laplace transforms.

Now let"s consider the $k$th term in Taylor expansion of $e^x$. It can be rearranged as a function of the previous $(k-1)-th$ term:

\begin{equation}
T_k(x) = \frac1{k!}x^n = \frac{x}{k} \frac1{(k-1)!}x^{k-1} = \frac{x}{k} T_{k-1}(x)
\end{equation}

For $x<0$, the terms in the sign have alternating sign and are decreasing in magnitude; therefore, for $x<0$, $R_k<T_{k+1}(1)$. This allows for an easy implementation of the Taylor expansion and its stopping condition:

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
def myexp(x, precision=1e-6, max_steps=40):
    if x == 0:
       return 1.0
    elif x>0:
       return 1.0/myexp(-x, precision, max_steps)
    else:
       t = s = 1.0  # first term
       for k in range(1, max_steps):
           t = t * x/k    # next term
           s = s + t    # add next term
           if abs(t)<precision: return s
       raise ArithmeticError("no convergence")
\end{lstlisting}

This code presents all the features of many of the algorithms we see later in the chapter:
\begin{itemize}
\item It deals with the special case $e^0=1$.
\item It reduces difficult problems to easier problems (exponential of a positive number to the exponential of a negative number via $e^x = 1/e^{-x}$).
\item It approximates the ``true'' solution by iterations.
\item The max number of iterations is limited.
\item There is a stopping condition.
\item It detects failure to converge.
\end{itemize}

Here is a test of its convergence:

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
>>> for i in range(10):
...     x= 0.1 * i
...     assert abs(myexp(x) - math.exp(x)) < 1e-4
\end{lstlisting}

We can do the same for the $\sin$ function:
\begin{equation}
T_k(x) = -\frac{x^2}{(2k)(2k+1)}T_{k-1}(x)
\end{equation}
In this case, the residue is always limited by
\begin{equation}
|R_k| < |x^{2k+1}|
\end{equation}

because the derivatives of $\sin$ are always $\sin$ and $\cos$ and their image is always between [$-$1, 1].

Also notice that the stopping condition is only true when $0\leq x<1$. Therefore, for other values of $x$, we must use trigonometric relations to reduce the problem to a domain where the Taylor series converges.

Hence we write:

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
def mysin(x, precision=1e-6, max_steps=40):
    pi = math.pi
    if x == 0:
       return 0
    elif x<0:
       return -mysin(-x)
    elif x>2.0 * pi:
       return mysin(x % (2.0 * pi))
    elif x>pi:
       return -mysin(2.0 * pi - x)
    elif x>pi/2:
       return mysin(pi-x)
    elif x>pi/4:
       return sqrt(1.0-mysin(pi/2-x) ** 2)
    else:
       t = s = x                                     # first term
       for k in range(1, max_steps):
           t = t * (-1.0) * x * x/(2 * k)/(2 * k+1)  # next term
           s = s + t                                 # add next term
           r = x ** (2 * k+1)                        # estimate residue
           if r<precision: return s                  # stopping condition
       raise ArithmeticError("no convergence")
\end{lstlisting}

Here we test it:
%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
>>> for i in range(10):
...     x= 0.1 * i
...     assert abs(mysin(x) - math.sin(x)) < 1e-4
\end{lstlisting}

Finally, we can do the same for the $\cos$ function:

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
def mycos(x, precision=1e-6, max_steps=40):
    pi = math.pi
    if x == 0:
       return 1.0
    elif x<0:
       return mycos(-x)
    elif x>2.0 * pi:
       return mycos(x % (2.0 * pi))
    elif x>pi:
       return mycos(2.0 * pi - x)
    elif x>pi/2:
       return -mycos(pi-x)
    elif x>pi/4:
       return sqrt(1.0-mycos(pi/2-x) ** 2)
    else:
       t = s = 1                      # first term
       for k in range(1, max_steps):
           t = t * (-1.0) * x * x/(2 * k)/(2 * k-1)    # next term
           s = s + t                  # add next term
           r = x ** (2 * k)               # estimate residue
           if r<precision: return s   # stopping condition
       raise ArithmeticError("no convergence")
\end{lstlisting}

Here is a test of convergence:

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
>>> for i in range(10):
...     x = 0.1 * i
...     assert abs(mycos(x) - math.cos(x)) < 1e-4
\end{lstlisting}

\goodbreak\subsection{Stopping Conditions}

\index{stopping conditions}\index{absolute error}\index{relative error}

To implement a stopping condition, we have two options. We can look at the absolute error, defined as

\begin{equation}
\textrm{[absolute error]}=\textrm{[approximate value]}-\textrm{[true value]}
\end{equation}

or we can look at the relative error

\begin{equation}
\textrm{[relative error]}=\textrm{[absolute error]}/\textrm{[true value]}
\end{equation}

or better, we can consider both. Here is an example of pseudo-code:

\begin{lstlisting}
result = guess
loop:
    compute correction
    result = result+correction
    compute remainder
    if |remainder| < target_absolute_precision return result
    if |remainder| < target_relative_precision * |result| return result
\end{lstlisting}

In the code, we use the computed {\ft result} as an estimate of the [true value] and, occasionally, the computed {\ft correction} is an estimate of the [absolute error]. The target absolute precision is an input value that we use as an upper limit for the absolute error. The target relative precision is an input value we use as an upper limit for the relative error. When absolute error falls below the target absolute precision or the relative error falls below the target relative precision, we stop looping and assume the result is sufficiently precise:

\begin{lstlisting}
def generic_looping_function(guess, ap, rp, ns):
    result = guess
    for k in range(ns):
        correction = ...
        result = result+correction
        remainder = ...
        if norm(remainder) < max(ap, norm(result) * rp): return result
    raise ArithmeticError("no convergence")
\end{lstlisting}

In the preceding code, 
\begin{itemize}
\item {\ft ap} is the target absolute precision.
\item {\ft rp} is the target relative precision.
\item {\ft ns} is the maximum number of steps.
\end{itemize}
From now on, we will adopt this naming convention.


Consider, for example, a financial algorithm that outputs a dollar amount. If it converges to a number very close to $1$ or $0$, the concept of relative precision loses significance for a result equal to zero, and the algorithm never detects convergence. In this case, setting an absolute precision of \$1 or 1c is the right thing to do. Conversely, if the algorithm converges to a very large dollar amount, setting a precision of \$1 or 1c may be a too strong requirement, and the algorithm will take too long to converge. In this case, setting a relative precision of 1\% or 0.1\% is the correct thing to do.

 Because in general we do not know in advance the output of the algorithm, we should use both stopping conditions. We should also detect which of the two conditions causes the algorithm to stop looping and return, so that we can estimate the uncertainty in the result.

\goodbreak\section{Linear algebra}

\index{linear algebra}

In this section, we consider the following algorithms:
\begin{itemize}
\item Arithmetic operation among matrices
\item Gauss--Jordan elimination for computing the inverse of a matrix $A$
\item Cholesky decomposition for factorizing a symmetric positive definite matrix $A$ into $L L^t$, where $L$ is a lower triangular matrix
\item The Jacobi algorithms for finding eigenvalues
\item Fitting algorithms based on linear least squares
\end{itemize}
We will provide examples of applications.

\goodbreak\subsection{Linear systems}

In mathematics, a system described by a function $f$ is linear if it is additive:
\begin{equation}
f(x+y) = f(x) + f(y)
\end{equation}
and if it is homogeneous, 
\begin{equation}
f(\alpha x) = \alpha f(x)
\end{equation}

In simpler words, we can say that the output is proportional to the input.

As discussed in the introduction to this chapter, one of the simplest techniques for approximating any unknown system consists of approximating it with a linear system (and this approximation will be correct for some system and not for others).

When we try to model a new system, approximating the system with a linear system is often the first step in describing it in a quantitative way, even if it may turn out that this is not a good approximation.

This is the same as approximating the function $f$ describing the system with the first-order Taylor expansions $f(x+h) - f(x) = f'(x) h$.

For a multidimensional system with input $\mathbf{x}$ (now a vector) and output $\mathbf{y}$ (also a vector, not necessarily of the same size as $\mathbf{x}$), we can still approximate $\mathbf{y}=f(\mathbf{x})$ with
$f(\mathbf{y}+\mathbf{h}) - \mathbf{y} \simeq A \mathbf{h}$, yet we need to clarify what this latter equation means.

Given
\begin{equation}
\mathbf{x} \equiv \left(\begin{tabular}{c}$x_0$\\$x_1$\\...\\$x_{n-1}$\end{tabular}\right)\qquad
\mathbf{y} \equiv \left(\begin{tabular}{c}$y_0$\\$y_1$\\...\\$y_{m-1}$\end{tabular}\right)
\end{equation}
\begin{equation}
A \equiv \left(\begin{tabular}{cccc}
$a_{00}$ & $a_{01}$ & ... & $a_{0, n-1}$ \\
$a_{10}$ & $a_{11}$ & ... & $a_{1, n-1}$ \\
... & ... & ... & ... \\
$a_{m-1, 0}$ & $a_{m-1, 1}$ & ... & $a_{m-1, n-1}$
\end{tabular}\right)
\end{equation}

the following equation means
\begin{equation}
\mathbf{y} = f(\mathbf{x}) \simeq A \mathbf{x}
\end{equation}
which means
\begin{eqnarray}
y_0 &= f_0(\mathbf(x) &\simeq a_{00} x_0 + a_{01} x_1 + ... + a_{0, n-1}x_{n-1} \\
y_1 &= f_1(\mathbf(x) &\simeq a_{10} x_0 + a_{11} x_1 + ... + a_{1, n-1}x_{n-1} \\
y_2 &= f_2(\mathbf(x) &\simeq a_{20} x_0 + a_{21} x_1 + ... + a_{2, n-1}x_{n-1} \\
... &=& ... \\
y_{m-1} &= f_{m-1}(\mathbf(x) &\simeq a_{m-1, 0} x_0 + a_{m-1, 1} x_1 + ...
a_{m-1, n-1}x_{n-1}
\end{eqnarray}
which says that every output variable $y_j$ is approximated with a function proportional to each of the input variables $x_i$.

A system is linear if the $\simeq$ relations turn out to be exact and can be replaced by $=$ symbols.

As a corollary of the basic properties of a linear system discussed earlier, linear systems have one nice additional property. If we combine two linear systems $y=Ax$ and $z=By$, the combined system is also a linear system $z = (BA)x$.

\index{elementary algebra}\index{abstract algebra}

{\it Elementary algebra} is defined as a set of numbers (e.g., real numbers) endowed with the ordinary four elementary operations ($+$, $-$, $\times$, $/$).

{\it Abstract algebra} is a generalization of the concept of elementary algebra to other sets of objects (not necessarily numbers) by definition operations among them such as addition and multiplication.

{\it Linear algebra} is the extension of elementary algebra to matrices (and vectors, which can be seen as special types of matrices) by defining the four elementary operations among them.

We will implement them in code using Python.
In Python, we can implement a matrix as a list of lists, as follows:
\begin{lstlisting}
>>> A = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]
\end{lstlisting}
But such an object (a list of lists) does not have the mathematical properties we want, so we have to define them.

First, we define a class representing a matrix:

\index{class!Matrix}

%%%% FIXME, MAYBE USE numpy

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
class Matrix(object):
    def __init__(self, rows, cols=1, fill=0.0):
        """
        Constructor a zero matrix
        Examples:
        A = Matrix([[1, 2], [3, 4]])
        A = Matrix([1, 2, 3, 4])
        A = Matrix(10, 20)
        A = Matrix(10, 20, fill=0.0)
        A = Matrix(10, 20, fill=lambda r, c: 1.0 if r == c else 0.0)
        """
        if isinstance(rows, list):
            if isinstance(rows[0], list):
                self.rows = [[e for e in row] for row in rows]
            else:
                self.rows = [[e] for e in rows]
        elif isinstance(rows, int) and isinstance(cols, int):
            xrows, xcols = range(rows), range(cols)
            if callable(fill):
                self.rows = [[fill(r, c) for c in xcols] for r in xrows]
            else:
                self.rows = [[fill for c in xcols] for r in xrows]
        else:
            raise RuntimeError("Unable to build matrix from %s" % repr(rows))
        self.nrows = len(self.rows)
        self.ncols = len(self.rows[0])
\end{lstlisting}

Notice that the constructor takes the number of rows and columns (cols) of the matrix but also a {\ft fill} value, which can be used to initialize the matrix elements and defaults to zero. It can be callable in case we need to initialize the matrix with row, col dependent values.

The actual matrix elements are stored as a list or array into the {\ft data} member variable. If {\ft optimize=True}, the data are stored in an {\ft array} of double precision floating point numbers (``d''). This optimization will prevent you from building matrices of complex numbers or matrices of arbitrary precision decimal numbers.

Now we define a getter method, a setter method, and a string representation for the matrix elements:
\index{\_\_getitem\_\_}\index{\_\_setitem\_\_}

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
    def __getitem__(A, coords):
        " x = A[0, 1]"
        i, j = coords
        return A.rows[i][j]

    def __setitem__(A, coords, value):
        " A[0, 1] = 3.0 "
        i, j = coords
        A.rows[i][j] = value

    def tolist(A):
        " assert(Matrix([[1, 2], [3, 4]]).tolist() == [[1, 2], [3, 4]]) "
        return A.rows

    def __str__(A):
        return str(A.rows)

    def flatten(A):
        " assert(Matrix([[1, 2], [3, 4]]).flatten() == [1, 2, 3, 4]) "
        return [A[r, c] for r in range(A.nrows) for c in range(A.ncols)]

    def reshape(A, n, m):
        " assert(Matrix([[1, 2], [3, 4]]).reshape(1, 4).tolist() == [[1, 2, 3, 4]]) "
        if n * m != A.nrows * A.ncols:
             raise RuntimeError("Impossible reshape")
        flat = A.flatten()
        return Matrix(n, m, fill=lambda r, c, m=m, flat=flat: flat[r * m+c])

    def swap_rows(A, i, j):
        " assert(Matrix([[1, 2], [3, 4]]).swap_rows(1, 0).tolist() == [[3, 4], [1, 2]]) "
        A.rows[i], A.rows[j] = A.rows[j], A.rows[i]
\end{lstlisting}

\index{matrix!identity}\index{matrix!diagonal}

We also define some convenience functions for constructing the identity matrix (given its size) and a diagonal matrix (given the diagonal elements). We make these methods static because they do not act on an existing matrix.

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
    @staticmethod
    def identity(rows=1, e=1.0):
        return Matrix(rows, rows, lambda r, c, e=e: e if r == c else 0.0)

    @staticmethod
    def diagonal(d):
        return Matrix(len(d), len(d), lambda r, c, d=d:d[r] if r == c else 0.0)
\end{lstlisting}

Now we are ready to define arithmetic operations among matrices. We start with addition and subtraction:

\index{matrix!addition}\index{matrix!subtraction}

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
    def __add__(A, B):
        """
        Adds A and B element by element, A and B must have the same size
        Example
        >>> A = Matrix([[4, 3.0], [2, 1.0]])
        >>> B = Matrix([[1, 2.0], [3, 4.0]])
        >>> C = A + B
        >>> print(C)
        [[5, 5.0], [5, 5.0]]
        """
        n, m = A.nrows, A.ncols
        if not isinstance(B, Matrix):
            if n == m:
                B = Matrix.identity(n, B)
            elif n == 1 or m == 1:
                B = Matrix([[B for c in range(m)] for r in range(n)])
        if B.nrows!=n or B.ncols!=m:
            raise ArithmeticError("incompatible dimensions")
        C = Matrix(n, m)
        for r in range(n):
            for c in range(m):
                C[r, c] = A[r, c]+B[r, c]
        return C

    def __sub__(A, B):
        """
        Adds A and B element by element, A and B must have the same size
        Example
        >>> A = Matrix([[4.0, 3.0], [2.0, 1.0]])
        >>> B = Matrix([[1.0, 2.0], [3.0, 4.0]])
        >>> C = A - B
        >>> print(C)
        [[3.0, 1.0], [-1.0, -3.0]]
        """
        n, m = A.nrows, A.ncols
        if not isinstance(B, Matrix):
            if n == m:
                B = Matrix.identity(n, B)
            elif n == 1 or m == 1:
                B = Matrix(n, m, fill=B)
        if B.nrows!=n or B.ncols!=m:
            raise ArithmeticError("Incompatible dimensions")
        C = Matrix(n, m)
        for r in range(n):
            for c in range(m):
                C[r, c] = A[r, c]-B[r, c]
        return C
    def __radd__(A, B): #B+A
        return A+B
    def __rsub__(A, B): #B-A
        return (-A)+B
    def __neg__(A):
        return Matrix(A.nrows, A.ncols, fill=lambda r, c:-A[r, c])
\end{lstlisting}
With the preceding definitions, we can add matrices to matrices, subtract matrices from matrices, but also add and subtract scalars to and from matrices and vectors
(scalars are interpreted as diagonal matrices when added to square matrices and as constant vectors when added to vectors).

Here are some examples:

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
>>> A = Matrix([[1.0, 2.0], [3.0, 4.0]])
>>> print(A + A)       # calls A.__add__(A)
[[2.0, 4.0], [6.0, 8.0]]
>>> print(A + 2)       # calls A.__add__(2)
[[3.0, 2.0], [3.0, 6.0]]
>>> print(A - 1)       # calls A.__add__(1)
[[0.0, 2.0], [3.0, 3.0]]
>>> print(-A)          # calls A.__neg__()
[[-1.0, -2.0], [-3.0, -4.0]]
>>> print(5 - A)       # calls A.__rsub__(5)
[[4.0, -2.0], [-3.0, 1.0]]
>>> b = Matrix([[1.0], [2.0], [3.0]])
>>> print(b + 2)       # calls b.__add__(2)
[[3.0], [4.0], [5.0]]
\end{lstlisting}

The class {\ft Matrix} works with complex numbers as well:
%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
>>> A = Matrix([[1, 2], [3, 4]])
>>> print(A + 1j)
[[(1+1j), 2.0], [3.0, (4+1j)]]
\end{lstlisting}


\index{matrix!multiplication}\index{scalar product}
Now we implement multiplication. We are interested in three types of multiplication: multiplication of a scalar by a matrix ({\ft \_\_rmul\_\_}), multiplication of a matrix by a matrix ({\ft \_\_mul\_\_}), and scalar product between two vectors (also handled by {\ft \_\_mul\_\_}):

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
    def __rmul__(A, x):
        "multiplies a number of matrix A by a scalar number x"
        M = copy.deepcopy(A)
        for r in range(M.nrows):
            for c in range(M.ncols):
                 M[r, c] *= x
        return M

    def __mul__(A, B):
        "multiplies a number of matrix A by another matrix B"
        if isinstance(B, (list, tuple)):
            return (A * Matrix(len(B), 1, fill=lambda r, c:B[r])).nrows
        elif not isinstance(B, Matrix):
            return B * A
        elif A.ncols == 1 and B.ncols == 1 and A.nrows == B.nrows:
             # try a scalar product ;-)
            return sum(A[r, 0] * B[r, 0] for r in range(A.nrows))
        elif A.ncols!=B.nrows:
            raise ArithmeticError("Incompatible dimension")
        M = Matrix(A.nrows, B.ncols)
        for r in range(A.nrows):
            for c in range(B.ncols):
                for k in range(A.ncols):
                    M[r, c] += A[r, k] * B[k, c]
        return M
\end{lstlisting}

This allows us the following operations:
%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
>>> A = Matrix([[1.0, 2.0], [3.0, 4.0]])
>>> print(2 * A)        # scalar * matrix
[[2.0, 4.0], [6.0, 8.0]]
>>> print(A * A)        # matrix * matrix
[[7.0, 10.0], [15.0, 22.0]]
>>> b = Matrix([[1], [2], [3]])
>>> print(b * b)        # scalar product
14
\end{lstlisting}


\goodbreak\subsection{Examples of linear transformations}

\index{linear transformation}

In this section, we try to provide an intuitive understanding of two-dimensional linear transformations.

In the following code, we consider an image (a set of points) containing a circle and two orthogonal axes. We then apply the following linear transformations to it:
\begin{itemize}
\item $A_1$, which scales the $X$-axis
\item $A_2$, which scales the $Y$-axis
\item $S$, which scales both axes
\item $B_1$, which scales the $X$-axis and then rotates ($R$) the image 0.5 rad
\item $B_2$, which is neither a scaling nor a rotation; as it can be seen from the image, it does not preserve angles
\end{itemize}

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
>>> points = [(math.cos(0.0628 * t), math.sin(0.0628 * t)) for t in range(200)]
>>> points += [(0.02 * t, 0) for t in range(50)]
>>> points += [(0, 0.02 * t) for t in range(50)]
>>> Canvas(title="Linear Transformation", xlab="x", ylab="y", 
...        xrange=(-1, 1), yrange=(-1, 1)).ellipses(points).save("la1.png")
>>> def f(A, points, filename):
...      data = [(A[0, 0] * x+A[0, 1] * y, A[1, 0] * x+A[1, 1] * y) for (x, y) in points]
...      Canvas(title="Linear Transformation", xlab="x", ylab="y"
...            ).ellipses(points).ellipses(data).save(filename)
>>> A1 = Matrix([[0.2, 0], [0, 1]])
>>> f(A1, points, "la2.png")
>>> A2 = Matrix([[1, 0], [0, 0.2]])
>>> f(A2, points, "la3.png")
>>> S = Matrix([[0.3, 0], [0, 0.3]])
>>> f(S, points, "la4.png")
>>> s, c = math.sin(0.5), math.cos(0.5)
>>> R = Matrix([[c, -s], [s, c]])
>>> B1 = R * A1
>>> f(B1, points, "la5.png")
>>> B2 = Matrix([[0.2, 0.4], [0.5, 0.3]])
>>> f(B2, points, "la6.png")
\end{lstlisting}

\newpage

\begin{figure}[ht]
\centering
\begin{tabular}{cc}
\includegraphics[width=1.5in]{images/la1.png} &
\includegraphics[width=1.5in]{images/la2.png} \\
\includegraphics[width=1.5in]{images/la3.png} &
\includegraphics[width=1.5in]{images/la4.png} \\
\includegraphics[width=1.5in]{images/la5.png} &
\includegraphics[width=1.5in]{images/la6.png}
\end{tabular}
\caption{Example of the effect of different linear transformations on the same set of points. From left to right, top to bottom, they show stretching along both the $X$- and $Y$-axes, scaling across both axes, a rotation, and a generic transformation that does not preserve angles.}
\end{figure}

\goodbreak\subsection{Matrix inversion and the Gauss--Jordan algorithm}

\index{matrix!inversion}\index{Gauss-Jordan}

Implementing the inverse of the multiplication (division) is a more challenging task.

We define $A^{-1}$, the inverse of the square matrix $A$, as that matrix such that for every vector $b$, $A\mathbf(x)=\mathbf{b}$ implies $\mathbf(x)=A^{-1}\mathbf{b}$. The Gauss--Jordan algorithm computes $A^{-1}$ given $A$.

To implement it, we must first understand how it works. Consider the following equation:

\begin{equation}
A \mathbf{x} = \mathbf{b}
\end{equation}
We can rewrite it as:
\begin{equation}
A \mathbf{x} = B \mathbf{b}
\end{equation}
where $B=1$, the identity matrix. This equation remains true if we multiply both terms by a nonsingular matrix $S_0$:
\begin{equation}
S_0 A \mathbf{x} = S_0 B \mathbf{b}
\end{equation}
The trick of the Gauss--Jordan elimination consists in finding a series of matrices $S_0$, $S_1$, ..., $S_{n-1}$ so that
\begin{equation}
S_{n-1} ... S_1 S_0 A \mathbf{x} = S_{n-1} ... S_1 S_0 B \mathbf{b} = \mathbf{x}
\end{equation}
Because the preceding expression must be true for every $b$ and because $x$ is the solution of $A x=b$, by definition, 
$S_{n-1} \ldots S_1 S_0 B \equiv A^{-1}$.

The Gauss-Jordan algorithm works exactly this way: given $A$, it computes $A^{-1}$:

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
    def __rtruediv__(A, x):
        """Computes x/A using Gauss-Jordan elimination where x is a scalar"""
        n = A.ncols
        if A.nrows != n:
           raise ArithmeticError("matrix not squared")
        indexes = range(n)
        A = copy.deepcopy(A)
        B = Matrix.identity(n, x)
        for c in indexes:
            for r in range(c+1, n):
                if abs(A[r, c])>abs(A[c, c]):
                    A.swap_rows(r, c)
                    B.swap_rows(r, c)
            p = 0.0 + A[c, c]  # trick to make sure it is not integer
            for k in indexes:
                A[c, k] = A[c, k]/p
                B[c, k] = B[c, k]/p
            for r in range(n):
                if r == c:
                    continue
                p = 0.0 + A[r, c]  # trick to make sure it is not integer
                for k in indexes:
                    A[r, k] -= A[c, k] * p
                    B[r, k] -= B[c, k] * p
        return B

    def __truediv__(A, B):
        if isinstance(B, Matrix):
            return A * (1.0/B)  # matrix/matrix
        else:
            return (1.0/B) * A  # matrix/scalar

\end{lstlisting}

Here is an example, and we will see many more applications later:

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
>>> A = Matrix([[1, 2], [4, 9]])
>>> print(1/A)
[[9.0, -2.0], [-4.0, 1.0]]
>>> print(A/A)
[[1.0, 0.0], [0.0, 1.0]]
>>> print(A/2)
[[0.5, 1.0], [2.0, 4.5]]
\end{lstlisting}

\goodbreak\subsection{Transposing a matrix}

\index{matrix!transpose}

Another operation that we will need is transposition:

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
    @property
    def T(A):
        """Transposed of A"""
        return Matrix(A.ncols, A.nrows, fill=lambda r, c: A[c, r])
\end{lstlisting}

Notice the new matrix is defined with the number of rows and columns switched from matrix A. Notice that in Python, a {\ft property} is a method that is called like an attribute, therefore without the {\ft ()} notation.
This can be used as follows:

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
>>> A = Matrix([[1, 2], [3, 4]])
>>> print(A.T)
[[1, 3], [2, 4]]
\end{lstlisting}

For later use, we define two functions to check whether a matrix is symmetrical or zero within a given precision.

Another typical transformation for matrices of complex numbers is the Hermitian operation, which is a transposition combined with complex conjugation of the elements:

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
    @property
    def H(A):
        """Hermitian of A"""
        return Matrix(A.ncols, A.nrows, fill=lambda r, c: A[c, r].conj())
\end{lstlisting}

\index{matrix!symmetric}

In later algorithms we will need to check whether a matrix is symmetrical (or almost symmetrical given precision) or zero (or almost zero):

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
def is_almost_symmetric(A, ap=1e-6, rp=1e-4):
    if A.nrows != A.ncols: return False
    for r in range(A.nrows):
        for c in range(r):
            delta = abs(A[r, c]-A[c, r])
            if delta>ap and delta>max(abs(A[r, c]), abs(A[c, r])) * rp:
                return False
    return True

def is_almost_zero(A, ap=1e-6, rp=1e-4):
    for r in range(A.nrows):
        for c in range(A.ncols):
            delta = abs(A[r, c]-A[c, r])
            if delta>ap and delta>max(abs(A[r, c]), abs(A[c, r])) * rp:
                return False
    return True
\end{lstlisting}

\goodbreak\subsection{Solving systems of linear equations}

\index{linear equations}\index{systems}

Linear algebra is fundamental for solving systems of linear equations such as the following:

\begin{eqnarray}
&x_0+2x_1+2x_2=&3 \\
&4x_0+4x_1+2x_2=&6 \\
&4x_0+6x_1+4x_2=&10
\end{eqnarray}
This can be rewritten using the equivalent linear algebra notation:
\begin{equation}
A \textrm{x} = \textrm{b}
\end{equation}
where
\begin{equation}
A = \left(\begin{tabular}{ccc}
1 & 2 & 2 \\
4 & 4 & 2 \\
4 & 6 & 4 \\
\end{tabular}\right) \qquad and \qquad
b =
\left(\begin{tabular}{c}
3 \\
6 \\
10 \\
\end{tabular}\right)
\end{equation}

The solution of the equation can now be written as
\begin{equation}
\textrm{x} = A^{-1}\textrm{b}
\end{equation}

We can easily solve the system with our Python library:

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
>>> A = Matrix([[1, 2, 2], [4, 4, 2], [4, 6, 4]])
>>> b = Matrix([[3], [6], [10]])
>>> x = (1/A) * b
>>> print(x)
[[-1.0], [3.0], [-1.0]]
\end{lstlisting}

Notice that $b$ is a column vector and therefore

\begin{lstlisting}
>>> b = Matrix([[3], [6], [10]])
\end{lstlisting}

but not

\begin{lstlisting}
>>> b = Matrix([[3, 6, 10]])  # wrong
\end{lstlisting}

We can also obtain a column vector by performing a transposition of a row vector:

\begin{lstlisting}
>>> b = Matrix([[3, 6, 10]]).T
\end{lstlisting}

\goodbreak\subsection{Norm and condition number again}

\index{matrix!norm}\index{condition number}\index{matrix!condition number}

By norm of a vector, we often refer to the 2-norm defined using the Pythagoras theorem:
\begin{equation}
||x||_2 = \sqrt{\sum_i x_i^2}
\end{equation}

For a vector, we can define the $p$-norm as a generalization of the $2$-norm:

\begin{equation}
||x||_p \equiv \left(\sum_i abs(x_i)^p \right)^{\frac1p}
\end{equation}

We can extend the notation of a norm to any function that maps a vector into a vector, as follows:

\begin{equation}
||f||_p \equiv \textrm{max}_x ||f(x)||_p / ||x||_p
\end{equation}

An immediate application is to functions implemented as linear transformations:

\begin{equation}
||A||_p \equiv \textrm{max}_x ||Ax||_p / ||x||_p
\end{equation}

This can be difficult to compute in the general case, but it reduces to a simple formula for the 1-norm:

\begin{equation}
||A||_1 \equiv \textrm{max}_j \sum_i abs(A_{ij})
\end{equation}

The 2-norm is difficult to compute for a matrix, but the 1-norm provides an approximation. It is computed by adding up the magnitude of the elements per each column and finding the maximum sum.

This allows us to define a generic function to compute the norm of lists, matrices/vectors, and scalars:

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
def norm(A, p=1):
    if isinstance(A, (list, tuple)):
        return sum(abs(x) ** p for x in A) ** (1.0/p)
    elif isinstance(A, Matrix):
        if A.nrows == 1 or A.ncols == 1:
             return sum(norm(A[r, c]) ** p \
                for r in range(A.nrows) \
                for c in range(A.ncols)) ** (1.0/p)
        elif p == 1:
             return max([sum(norm(A[r, c]) \
                for r in range(A.nrows)) \
                for c in range(A.ncols)])
        else:
             raise NotImplementedError
    else:
        return abs(A)
\end{lstlisting}

Now we can implement a function that computes the condition number for ordinary functions as well as for linear transformations represented by a matrix:

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
def condition_number(f, x=None, h=1e-6):
    if callable(f) and not x is None:
        return D(f, h)(x) * x/f(x)
    elif isinstance(f, Matrix):  # if is the Matrix
        return norm(f) * norm(1/f)
    else:
        raise NotImplementedError
\end{lstlisting}

Here are some examples:

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
>>> def f(x): return x * x-5.0 * x
>>> print(round(condition_number(f, 1), 2))
0.75
>>> A = Matrix([[1, 2], [3, 4]])
>>> print(round(condition_number(A), 2))
21.0
\end{lstlisting}

\index{matrix!exponential}

Having the norm for matrices also allows us to extend the definition of convergence of a Taylor series to a series of matrices:

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
def exp(x, ap=1e-6, rp=1e-4, ns=40):
    if isinstance(x, Matrix):
       t = s = Matrix.identity(x.ncols)
       for k in range(1, ns):
           t = t * x/k    # next term
           s = s + t    # add next term
           if norm(t)<max(ap, norm(s) * rp): return s
       raise ArithmeticError("no convergence")
    elif type(x) == type(1j):
       return cmath.exp(x)
    else:
       return math.exp(x)
\end{lstlisting}

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
>>> A = Matrix([[1, 2], [3, 4]])
>>> print(exp(A))
[[51.96..., 74.73...], [112.10..., 164.07...]]
\end{lstlisting}

\goodbreak\subsection{Cholesky factorization}

\index{Cholesky}\index{matrix!positive definite}\index{positive definite}

A matrix is said to be positive definite if $x^t Ax>0$ for every $x\neq0$.

If a matrix is symmetric and positive definite, then there exists a lower triangular matrix $L$ such that $A=L L^t$. A lower triangular matrix is a matrix that has zeros above the diagonal elements.

The Cholesky algorithm takes a matrix $A$ as input and returns the matrix $L$:

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
def Cholesky(A):
    if not is_almost_symmetric(A):
        raise ArithmeticError("not symmetric")
    L = copy.deepcopy(A)
    for k in range(L.ncols):
        if L[k, k]<=0:
            raise ArithmeticError("not positive definite")
        p = L[k, k] = math.sqrt(L[k, k])
        for i in range(k+1, L.nrows):
            L[i, k] /= p
        for j in range(k+1, L.nrows):
            p=float(L[j, k])
            for i in range(k+1, L.nrows):
                L[i, j] -= p * L[i, k]
    for  i in range(L.nrows):
        for j in range(i+1, L.ncols):
            L[i, j]=0
    return L
\end{lstlisting}

Here we provide an example and a check that indeed $A=L L^t$:

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
>>> A = Matrix([[4, 2, 1], [2, 9, 3], [1, 3, 16]])
>>> L = Cholesky(A)
>>> is_almost_zero(A - L * L.T)
True
\end{lstlisting}

The Cholesky algorithm fails if and only if the input matrix is not symmetric or not positive definite, therefore it can be used to check whether a symmetric matrix is positive definite.

Consider for example a generic covariance matrix $A$. It is supposed to be positive definite, but sometimes it is not, because it is computed incorrectly by taking different subsets of the data to compute $A_{ij}$, $A_{jk}$, and $A_{ik}$. The Cholesky algorithm provides an algorithm to check whether a matrix is positive definite:

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
def is_positive_definite(A):
    if not is_almost_symmetric(A):
        return False
    try:
        Cholesky(A)
        return True
    except Exception:
        return False
\end{lstlisting}

Another application of the Cholesky is in generating vectors $\mathbf{x}$ with probability distribution

\begin{equation}
p(\mathbf{x}) \propto \exp\left(-\frac12 \mathbf{x}^t A^{-1} \mathbf{x}\right)
\end{equation}
where $A$ is a symmetric and positive definite matrix. In fact, if $A=LL^t$, then
\begin{equation}
p(\mathbf{x}) \propto \exp\left(-\frac12 (L^{-1}\mathbf{x})^t (L^{-1}\mathbf{x})\right)
\end{equation}
and with a change of variable $\mathbf{u}=\mathbf{L^{-1}x}$, we obtain
\begin{equation}
p(\mathbf{x}) \propto \exp\left(-\frac12 \mathbf{u}^t \mathbf{u}\right)
\end{equation}
and
\begin{equation}
p(\mathbf{x}) \propto e^{-\frac12 u_0^2}e^{-\frac12 u_1^2}e^{-\frac12 u_2^2}...
\end{equation}
Therefore the $u_i$ components are Gaussian random variables.

In summary, given a covariance matrix $A$, we can generate random vectors $x$ or random numbers with the same covariance simply by doing

%% META:FILE:nlib.py
\begin{lstlisting}
def RandomList(A):
    L = Cholesky(A)
    while True:
        u = Matrix([[random.gauss(0, 1)] for c in range(L.nrows)])
        yield (L * u).flatten()
\end{lstlisting}

Here is an example of how to use it:

\begin{lstlisting}
>>> A = Matrix([[1.0, 0.1], [0.2, 3.0]])
>>> for k, v in enumerate(RandomList(A)):
...     print(v)
\end{lstlisting}

The {\ft RandomList} is a generator. You can iterate over it. The {\ft yield} keyword is used like {\ft return}, except the function will return a generator.

\goodbreak\subsection{Modern portfolio theory}

\index{Modern Portfolio Theory}\index{tangency portfolio}\index{Markowitz}\index{Sharpe ratio}

Modern portfolio theory~\cite{mpt} is an investment approach that tries to maximize return given a fixed risk. Many different metrics have been proposed. One of them is the {\it Sharpe ratio}.

For a stock or a portfolio with an average return $r$ and risk $\sigma$, the Sharpe ratio is defined as
\begin{equation}
\textrm{Sharpe}(r, \sigma) \equiv (r-\bar r)/\sigma
\end{equation}
Here $\bar r$ is the current risk-free investment rate. Usually the risk is measured as the standard deviation of its daily (or monthly or yearly) return.

Consider the stock price $p_{it}$ of stock $i$ at time $t$ and its arithmetic daily return
$r_{it}=(p_{i, t+1}-p_{it})/p_{it}$ given a risk-free interest equal to $\bar r$.

For each stock, we can compute the average return and average risk (variance of daily returns) and display it in a risk-return plot as we did in chapter 2.

We can try to build arbitrary portfolios by investing in multiple stocks at the same time. Modern portfolio theory states that there is a maximum Sharpe ratio and there is one portfolio that corresponds to it. It is called the tangency portfolio.

A portfolio is identified by fractions of \$1 invested in each stock in the portfolio. Our goal is to determine the tangent portfolio.

If we assume that daily returns for the stocks are Gaussian, then the solving algorithm is simple.

All we need is to compute the average return for each stock, defined as
\begin{equation}
r_i = 1/T \sum_t r_{it}
\end{equation}
and the covariance matrix
\begin{equation}
A_{ij} = \frac1T \sum_t (r_{it}-r_i)(r_{jt}-r_j)
\end{equation}

Modern portfolio theory tells us that the tangent portfolio is given by
\begin{equation}
\mathbf{x}=A^{-1} ( \mathbf{r}-\bar{r}\mathbf{1})
\end{equation}

The inputs of the formula are the covariance matrix ($A$), a vector or arithmetic returns for the assets in the portfolio ($r$), the risk free rate ($\bar{r}$). The output is a vector ($x$) whose elements are the percentages to be invested in each asset to obtain a tangency portfolio. Notice that some elements of $x$ can be negative and this corresponds to short position (sell, not buy, the asset).

Here is the algorithm:

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
def Markowitz(mu, A, r_free):
    """Assess Markowitz risk/return.
    Example:
    >>> cov = Matrix([[0.04, 0.006, 0.02], 
    ...               [0.006, 0.09, 0.06], 
    ...               [0.02, 0.06, 0.16]])
    >>> mu = Matrix([[0.10], [0.12], [0.15]])
    >>> r_free = 0.05
    >>> x, ret, risk = Markowitz(mu, cov, r_free)
    >>> print(x)
    [0.556634..., 0.275080..., 0.1682847...]
    >>> print(ret, risk)
    0.113915... 0.186747...
    """
    x = Matrix([[0.0] for r in range(A.nrows)])
    x = (1/A) * (mu - r_free)
    x = x/sum(x[r, 0] for r in range(x.nrows))
    portfolio = [x[r, 0] for r in range(x.nrows)]
    portfolio_return = mu * x
    portfolio_risk = sqrt(x * (A * x))
    return portfolio, portfolio_return, portfolio_risk
\end{lstlisting}

Here is an example.
We consider three assets (0, 1, 2) with the following covariance matrix:
\begin{lstlisting}
>>> cov = Matrix([[0.04, 0.006, 0.02], 
...               [0.006, 0.09, 0.06], 
...               [0.02, 0.06, 0.16]])
\end{lstlisting}
and the following expected returns (arithmetic returns, not log returns, because the former are additive, whereas the latter are not):
\begin{lstlisting}
>>> mu = Matrix([[0.10], [0.12], [0.15]])
\end{lstlisting}
Given the risk-free interest rate
\begin{lstlisting}
>>> r_free = 0.05
\end{lstlisting}
we compute the tangent portfolio (highest Sharpe ratio), its return, and its risk with one function call:
\begin{lstlisting}
>>> x, ret, risk = Markowitz(mu, cov, r_free)
>>> print(x)
[0.5566343042071198, 0.27508090614886727, 0.16828478964401297]
>>> ret, risk
0.113915857605 0.186747095412
>>> (ret-r_free).risk
0.34225891152
>>> for r in range(3): print((mu[r, 0]-r_free)/sqrt(cov[r, r]))
0.25
0.233333333333
0.25
\end{lstlisting}

Investing 55\% in asset 0, 27\% in asset 1, and 16\% in asset 2, the resulting portfolio has an expected return of 11.39\% and a risk of 18.67\%, which corresponds to a Sharpe ratio of 0.34, much higher than 0.25, 0.23, and 0.23 for the individual assets.

Notice that the tangency portfolio is not the only one with the highest Sharpe ratio (return for unit of risk). In fact, any linear combination of the tangency portfolio with a risk-free asset (putting money in the bank) has the same Sharpe ratio. For any target risk, one can find a linear combination of the risk-free asset and the tangent portfolio that has a better Sharpe ratio than any other possible portfolio comprising the same assets.

If we call $\alpha$ the fraction of the money to invest in the tangency portfolio and $1-\alpha$ the fraction to keep in the bank at the risk free rate, the resulting combined portfolio has return:

\begin{equation}
\alpha \mathbf{x}\cdot\mathbf{r} + (1-\alpha) \bar r
\end{equation}

and risk

\begin{equation}
\alpha \sqrt{\mathbf{x}^t A \mathbf{x}}
\end{equation}

We can determine $\alpha$ by deciding how much risk we are willing to take, and these formulas tell us the optimal portfolio for that amount of risk.


\goodbreak\subsection{Linear least squares, $\chi^2$}

\index{linear least squares}\index{$\chi^2$}\index{fitting}\index{Regression}

Consider a set of data points $(x_J, y_j) = (t_j, o_j \pm do_j)$. We want to fit them with a linear combination of linear independent functions $f_i$ so that

\begin{eqnarray}
c_0 f_0(t_0) + c_1 f_1(t_0) + c_2 f_2(t_0) +  ... & = & e_0 \simeq o_0 \pm do_0\\
c_0 f_0(t_1) + c_1 f_1(t_1) + c_2 f_2(t_1) +  ... & = & e_1 \simeq o_1 \pm do_1\\
c_0 f_0(t_2) + c_1 f_1(t_2) + c_2 f_2(t_2) +  ... & = & e_2 \simeq o_2 \pm do_2\\
... &=& ...
\end{eqnarray}

We want to find the $\{c_i\}$ that minimizes the sum of the squared distances between the actual ``observed'' data $o_j$ and the predicted ``expected'' data $e_j$, in units of $do_j$. This metric is called $\chi^2$ in general~\cite{chi2}. An algorithm that minimizes the $\chi^2$  and is linear in the $c_i$ coefficients (our case here) is called {\it linear least squares} or {\it linear regression}.

\begin{equation}
\chi^2 = \sum_j \left|\frac{e_j - o_j}{do_j}\right|^2
\end{equation}

If we define the matrix $A$ and $B$ as

\begin{equation}
A=\left(
\begin{tabular}{cccc}
$\frac{f_0(t_0)}{do_0}$ & $\frac{f_1(t_0)}{do_0}$ & $\frac{f_2(t_0)}{do_0}$ &...\\
$\frac{f_0(t_1)}{do_1}$ & $\frac{f_1(t_1)}{do_1}$ & $\frac{f_2(t_1)}{do_1}$ &...\\
$\frac{f_0(t_2)}{do_2}$ & $\frac{f_1(t_2)}{do_2}$ & $\frac{f_2(t_2)}{do_2}$ &...\\
...& ...& ... & ...
\end{tabular}
\right) \qquad b =
\left(
\begin{tabular}{c}
$\frac{o_0}{do_0}$ \\
$\frac{o_1}{do_1}$ \\
$\frac{o_2}{do_2}$ \\
...
\end{tabular}
\right)
\end{equation}

then the problem is reduced to

\begin{eqnarray}
\min_{\mathbf{c}}\chi^2 &=& \min_{\mathbf{c}} |A\mathbf{c}-\mathbf{b}|^2 \\
  &=& \min_{\mathbf{c}} (A\mathbf{c}-\mathbf{b})^t (A\mathbf{c}-\mathbf{b}) \\
  &=& \min_{\mathbf{c}} (\mathbf{c}^t A^t A \mathbf x - 2\mathbf{b}^t A \mathbf{c} + \mathbf{b}^t \mathbf{b})
\end{eqnarray}
This is the same as solving the following equation:

\begin{eqnarray}
\nabla_{c} (\mathbf{c}^t A^t A \mathbf x - 2\mathbf{c}^t A^t \mathbf{b} + \mathbf{b}^t\mathbf{b}) &=& 0 \\
A^t A \mathbf{c} - A^t \mathbf{b} &=& 0
\end{eqnarray}

Its solution is

\begin{equation}
\mathbf{c} = (A^t A)^{-1} (A^t \mathbf{b})
\end{equation}

The following algorithm implements a fitting function based on the preceding procedure. It takes as input a list of functions $f_i$ and a list of points $p_j=(t_j, o_j, do_j)$ and returns three objects---a list with the $c$ coefficients, the value of $\chi^2$ for the best fit, and the fitting function:

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
def fit_least_squares(points, f):
    """
    Computes c_j for best linear fit of y[i] \pm dy[i] = fitting_f(x[i])
    where fitting_f(x[i]) is \sum_j c_j f[j](x[i])

    parameters:
    - a list of fitting functions
    - a list with points (x, y, dy)

    returns:
    - column vector with fitting coefficients
    - the chi2 for the fit
    - the fitting function as a lambda x: ....
    """
    def eval_fitting_function(f, c, x):
        if len(f) == 1: return c * f[0](x)
        else: return sum(func(x) * c[i, 0] for i, func in enumerate(f))
    A = Matrix(len(points), len(f))
    b = Matrix(len(points))
    for i in range(A.nrows):
        weight = 1.0/points[i][2] if len(points[i])>2 else 1.0
        b[i, 0] = weight * float(points[i][1])
        for j in range(A.ncols):
            A[i, j] = weight * f[j](float(points[i][0]))
    c = (1.0/(A.T * A)) * (A.T * b)
    chi = A * c-b
    chi2 = norm(chi, 2) ** 2
    fitting_f = lambda x, c=c, f=f, q=eval_fitting_function: q(f, c, x)
    cs = [c] if isinstance(c, float) else c.flatten()
    return cs, chi2, fitting_f

# examples of fitting functions
def POLYNOMIAL(n):
    return [(lambda x, p=p: x ** p) for p in range(n+1)]
CONSTANT = POLYNOMIAL(0)
LINEAR   = POLYNOMIAL(1)
QUADRATIC = POLYNOMIAL(2)
CUBIC    = POLYNOMIAL(3)
QUARTIC  = POLYNOMIAL(4)
\end{lstlisting}

As an example, we can use it to perform a polynomial fit: given a set of points, we want to find the coefficients of a polynomial that best approximate those points.

In other words, we want to find the $c_i$ such that, given $t_j$ and $o_j$, 
\begin{eqnarray}
c_0  + c_1 t_0^{1} + c_2 t_0^{2} +  ... & = & e_0 \simeq o_0 \pm do_0 \\
c_0  + c_1 t_1^{1} + c_2 t_1^{2} +  ... & = & e_1 \simeq o_1 \pm do_1\\
c_0  + c_1 t_2^{1} + c_2 t_2^{2} +  ... & = & e_2 \simeq o_2 \pm do_2\\
... &  &... \\
\end{eqnarray}

Here is how we can generate some random points and solve the problem for a polynomial of degree 2 (or quadratic fit):

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
>>> points = [(k, 5+0.8 * k+0.3 * k * k+math.sin(k), 2) for k in range(100)]
>>> a, chi2, fitting_f = fit_least_squares(points, QUADRATIC)
>>> for p in points[-10:]:
...     print(p[0], round(p[1], 2), round(fitting_f(p[0]), 2))
90 2507.89 2506.98
91 2562.21 2562.08
92 2617.02 2617.78
93 2673.15 2674.08
94 2730.75 2730.98
95 2789.18 2788.48
96 2847.58 2846.58
97 2905.68 2905.28
98 2964.03 2964.58
99 3023.5 3024.48
>>> Canvas(title="polynomial fit", xlab="t", ylab="e(t), o(t)"
...      ).errorbar(points[:10], legend="o(t)"
...      ).plot([(p[0], fitting_f(p[0])) for p in points[:10]], legend="e(t)"
...      ).save("images/polynomialfit.png")
\end{lstlisting}

Fig.~\ref{fit} is a plot of the first 10 points compared with the best fit:

\begin{figure}[ht]
\centering\includegraphics[width=4in]{images/polynomialfit.png}
\caption{Random data with their error bars and the polynomial best fit.\label{fit}}
\end{figure}

We can also define a $\chi^2_{dof} = \chi^2/(N-1)$ where $N$ is the number of $c$ parameters determined by the fit. A value of $\chi^2_{dof} \simeq 1$ indicates a good fit. In general, the smaller $\chi^2_{dof}$, the better the fit. A large value of $\chi^2_{dof}$ is a symptom of poor modeling (the assumptions of the fit are wrong), whereas a value $\chi^2_{dof}$ much smaller than 1 is a symptom of an overestimate of the errors $do_j$ (or perhaps manufactured data).

\goodbreak\subsection{Trading and technical analysis}

\index{trading strategy}\index{technical analysis}

In finance, {\it technical analysis} is an empirical discipline that consists of forecasting the direction of prices through the study of patterns in historical data (in particular, price and volume). As an example, we implement a simple strategy that consists of the following steps:

\begin{itemize}
\item We fit the adjusted closing price for the previous seven days and use our fitting function to predict the adjusted close for the next day.
\item If we have cash and predict the price will go up, we buy the stock.
\item If we hold the stock and predict the price will go down, we sell the stock.
\end{itemize}

\index{class!Trader}

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
class Trader:
    def model(self, window):
        "the forecasting model"
         # we fit last few days quadratically
        points = list(enumerate(window))
        a, chi2, fitting_f = fit_least_squares(points, QUADRATIC)
         # and we extrapolate tomorrow"s price
        tomorrow_prediction = fitting_f(len(points))
        return tomorrow_prediction

    def strategy(self, history, ndays=7):
        "the trading strategy"
        if len(history)<ndays:
            return
        else:
            today_close = history[-1]
            tomorrow_prediction = self.model(history[-ndays:])
            return "buy" if tomorrow_prediction>today_close else "sell"

    def simulate(self, data, cash=1000.0, shares=0.0, daily_rate=0.03/360):
        "find fitting parameters that optimize the trading strategy"
        for t in range(len(data)):
            suggestion = self.strategy(data[:t])
            today_close = data[t-1]
             # and we buy or sell based on our strategy
            if cash>0 and suggestion == "buy":
                 # we keep track of finances
                shares_bought = int(cash/today_close)
                shares += shares_bought
                cash -= shares_bought * today_close
            elif shares>0 and suggestion == "sell":
                cash += shares * today_close
                shares = 0.0
             # we assume money in the bank also gains an interest
            cash *=math.exp(daily_rate)
         # we return the net worth
        return cash + shares * data[-1]
\end{lstlisting}

Now we back test the strategy using fake financial data. We can generate fake financial data with this function:

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
def fake_stock_prices(start_price=100, average_return=0.05, volatility=0.30, days=100):
    daily_volatility = volatility/math.sqrt(250)
    daily_return = average_return/250
    s = [random.gauss(0, daily_volatility) for d in range(days-1)]
    mu = daily_return - sum(s)/(days-1)
    v = [start_price]
    for item in s:
        v.append(v[-1] * math.exp(mu + item))
    return v
\end{lstlisting}

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
>>> initial_cash = 1000
>>> data = fake_stock_prices(average_return=0.05) 
>>> final_cash = Trader().simulate(data, cash=initial_cash)
>>> naive_profit = initial_cash * (math.exp(0.05) - 1)
>>> strategy_profit = final_cash - initial_cash
\end{lstlisting}

If {\ft strategy\_profit} > {\ft naive\_profit} than our strategy outperforms the naive buy and hold strategy.

Of course, we can always engineer a strategy based on historical data that will outperform holding the stock, but {\it past performance is never a guarantee of future performance}.

According to the definition from investopedia.com, ``technical analysts believe that the historical performance of stocks and markets is an indication of future performance.''

The efficacy of both technical and fundamental analysis is disputed by the efficient-market hypothesis, which states that stock market prices are essentially unpredictable~\cite{andrew}.

It is easy to extend the previous class to implement other strategies and back test them.

\goodbreak\subsection{Eigenvalues and the Jacobi algorithm}

\index{eigenvalues}\index{eigenvectors}\index{Jacobi}

Given a matrix $A$, an eigenvector is defined as a vector $\mathbf{x}$ such that
$A\mathbf{x}$ is proportional to $\mathbf{x}$.
The proportionality factor is called an eigenvalue, $e$. One matrix may have many eigenvectors $\mathbf{x}_i$ and associated eigenvalues $e_i$:

\begin{equation}
A\mathbf{x}_i = e_i\mathbf{x}_i
\end{equation}

For example:
\begin{equation}
A = \left(\begin{tabular}{ccc}
1 & -2  \\
1 & 4  \\
\end{tabular}\right) \qquad and \qquad
x_i =
\left(\begin{tabular}{c}
-1 \\
1 \\
\end{tabular}\right)
\end{equation}

\begin{equation}
\left(\begin{tabular}{ccc}
1 & -2  \\
1 & 4  \\
\end{tabular}\right) * 
\left(\begin{tabular}{c}
-1 \\
1 \\
\end{tabular}\right) \qquad =  \qquad
3 * \left(\begin{tabular}{c}
-1 \\
1 \\
\end{tabular}\right)
\end{equation}

In this case, $x_i$ is an eigenvector and the corresponding eigenvalue is $e=3$.

Some eigenvalues may be zero ($e_i=0$), which means the matrix $A$ is singular. A matrix is singular if it maps a nonzero vector into zero.

Given a square matrix $A$, if the space generated by the linear independent eigenvalues has the same dimensionality as the number of rows (or columns) of $A$, then its eigenvalues are real and the matrix can we written as

\begin{equation}
A = U D U^t
\end{equation}
where
$D$ is a diagonal matrix with eigenvalues on the diagonal $D_{ii} = e_i$ and
$U$ is a matrix whose column $i$ is the $\mathbf{x}_i$ eigenvalue.

The following algorithm is called the Jacobi algorithm. It takes as input a symmetric matrix $A$ and returns the matrix $U$ and a list of corresponding eigenvalues $e$, sorted from smallest to largest:


%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
def sqrt(x):
    try:
        return math.sqrt(x)
    except ValueError:
        return cmath.sqrt(x)

def Jacobi_eigenvalues(A, checkpoint=False):
    """Returns U end e so that A=U * diagonal(e) * transposed(U)
       where i-column of U contains the eigenvector corresponding to
       the eigenvalue e[i] of A.

       from http://en.wikipedia.org/wiki/Jacobi_eigenvalue_algorithm
    """
    def maxind(M, k):
        j=k+1
        for i in range(k+2, M.ncols):
            if abs(M[k, i])>abs(M[k, j]):
               j=i
        return j
    n = A.nrows
    if n!=A.ncols:
        raise ArithmeticError("matrix not squared")
    indexes = range(n)
    S = Matrix(n, n, fill=lambda r, c: float(A[r, c]))
    E = Matrix.identity(n)
    state = n
    ind = [maxind(S, k) for k in indexes]
    e = [S[k, k] for k in indexes]
    changed = [True for k in indexes]
    iteration = 0
    while state:
        if checkpoint: checkpoint("rotating vectors (%i) ..." % iteration)
        m=0
        for k in range(1, n-1):
            if abs(S[k, ind[k]])>abs(S[m, ind[m]]): m=k
            pass
        k, h = m, ind[m]
        p = S[k, h]
        y = (e[h]-e[k])/2
        t = abs(y)+sqrt(p * p+y * y)
        s = sqrt(p * p+t * t)
        c = t/s
        s = p/s
        t = p * p/t
        if y<0: s, t = -s, -t
        S[k, h] = 0
        y = e[k]
        e[k] = y-t
        if changed[k] and y == e[k]:
            changed[k], state = False, state-1
        elif (not changed[k]) and y!=e[k]:
            changed[k], state = True, state+1
        y = e[h]
        e[h] = y+t
        if changed[h] and y == e[h]:
            changed[h], state = False, state-1
        elif (not changed[h]) and y!=e[h]:
            changed[h], state = True, state+1
        for i in range(k):
            S[i, k], S[i, h] = c * S[i, k]-s * S[i, h], s * S[i, k]+c * S[i, h]
        for i in range(k+1, h):
            S[k, i], S[i, h] = c * S[k, i]-s * S[i, h], s * S[k, i]+c * S[i, h]
        for i in range(h+1, n):
            S[k, i], S[h, i] = c * S[k, i]-s * S[h, i], s * S[k, i]+c * S[h, i]
        for i in indexes:
            E[k, i], E[h, i] = c * E[k, i]-s * E[h, i], s * E[k, i]+c * E[h, i]
        ind[k], ind[h]=maxind(S, k), maxind(S, h)
        iteration+=1
     # sort vectors
    for i in range(1, n):
        j=i
        while j>0 and e[j-1]>e[j]:
            e[j], e[j-1] = e[j-1], e[j]
            E.swap_rows(j, j-1)
            j-=1
     # normalize vectors
    U = Matrix(n, n)
    for i in indexes:
        norm = sqrt(sum(E[i, j] ** 2 for j in indexes))
        for j in indexes: U[j, i] = E[i, j]/norm
    return U, e

\end{lstlisting}

Here is an example that shows, for a particular case, the relation between the input, $A$, of the output of the $U, e$ of the Jacobi algorithm:

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
>>> import random
>>> A = Matrix(4, 4)
>>> for r in range(A.nrows):
...     for c in range(r, A.ncols):
...         A[r, c] = A[c, r] = random.gauss(10, 10)
>>> U, e = Jacobi_eigenvalues(A)
>>> is_almost_zero(U * Matrix.diagonal(e) * U.T-A)
True
\end{lstlisting}

Eigenvalues can be used to filter noise out of data and find hidden dependencies in data. Following are some examples.

\goodbreak\subsection{Principal component analysis}

\index{principal component analysis}\index{correlation}

One important application of the Jacobi algorithm is for principal component analysis (PCA). This is a mathematical procedure that converts a set of observations of possibly correlated vectors into a set of uncorrelated vectors called {\it principal components}.

Here we consider, as an example, the time series of the adjusted arithmetic returns for the S\&P100 stocks that we downloaded and stored in chapter 2.

Each time series is a vector. We know they are not independent because there are correlations. Our goal is to model each time series and a vector plus noise where the vector is the same for all series. We also want find that vector that has maximal superposition with the individual time series, the principal component.

First, we compute the correlation matrix for all the stocks. This is a nontrivial task because we have to make sure that we only consider those days when all stocks were traded. %%%% FIXME EXPLAIN MORE

%%%% FIXME EXAMPLE?

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
def compute_correlation_matrix(v):
    """Input is a list of lists where some elements can be missing (None)"""
    m = len(v)
    n = len(v[0])
    mus = [sum(v[i][k] for k in range(n))/n for i in range(m)]
    var = [sum(v[i][k] ** 2 for k in range(n))/n - mus[i] ** 2 for i in range(m)]
    corr = Matrix(m, m, fill=lambda i, j: \
             (sum(v[i][k] * v[j][k] for k in range(1, n))/n - mus[i] * mus[j])/ \
             math.sqrt(var[i] * var[j]))
    return corr
\end{lstlisting}

We use the preceding function to compute the correlation and pass it as input to the Jacobi algorithm and plot the output eigenvalues:

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
>>> stocks = [fake_stock_prices() for i in range(5)]
>>> corr = compute_correlation_matrix(stocks)
>>> U, e = Jacobi_eigenvalues(corr)
>>> Canvas(title="Fake Stock Correlations", xlab="i", ylab="e[i]"
...       ).plot([(i, ei) for i, ei, in enumerate(e)]
...       ).save("images/correlations.png")
\end{lstlisting}

\begin{figure}[ht]
\centering\includegraphics[width=4in]{images/correlations.png}
\caption{Eigenvalues of the correlation matrix for 5 fake stocks stocks, sorted by their magnitude.}
\end{figure}

\index{alpha}\index{beta}

The image shows that one eigenvalue, the last one, is much larger than the others. It tells us that the data series have something in common. In fact, the arithmetic returns for stock $j$ at time $t$ can be written as

\begin{equation}
r_{it} = \beta_i p_t + \alpha_{it}
\end{equation}
where $p$ is the principal component given by

\begin{eqnarray}
p_t &=& \sum_i U_{n-1, j} r_{jt} \\
\beta_i &=& \sum_t r_{it} p_t \\
\alpha_{it} &=& r_{it} - \beta_i p_t
\end{eqnarray}

Here $\mathbf{p}$ is the vector of adjusted arithmetic returns that better correlates with the returns of the individual assets and therefore best represents the market. The $\beta_i$ coefficient tells us how much $\mathbf{r}_i$ overlaps with $\mathbf{p}$; $\alpha$, at first approximation, measures leftover noise.

\goodbreak\section{Sparse matrix inversion}

\index{sparse matrix}

Sometimes we have to invert matrices that are very large, and the Gauss-Jordan algorithms fails. Yet, if the matrix is sparse, in the sense that most of its elements are zeros, than two algorithms come to our rescue: the {\it minimum residual} and the {\it biconjugate gradient} (for which we consider a variant called the {\it stabilized bi-conjugate gradient}).

We will also assume that the matrix to be inverted is given in some implicit algorithmic as $\mathbf{y}=f(\mathbf{x})$ because this is always the case for sparse matrices. There is no point to storing all its elements because most of them are zero.

%%%% FIXME CODE

\goodbreak\subsection{Minimum residual}

\index{minimum residual}

Given a linear operator $f$, the Krylov space spanned by a vector $x$ is defined as

\begin{equation}
K(f, y, i) = \{y, f(y), f(f(y)), f(f(f(y))), (f^i)(y)\}
\end{equation}
The {\it minimum residual}~\cite{minres} algorithm works by solving $x=f^{-1}(y)$ iteratively. At each iteration, it computes a new orthogonal basis vector $q_i$ for the Krylov space $K(f, y, i)$ and computes the coefficients $\alpha_i$ that project $x_i$ into component $i$ of the Krylov space:
\begin{equation}
x_i = y + \alpha_1 q_1 + \alpha_2 q_2 + ... + \alpha_i q_i \in K(f, y, i+1)
\end{equation}
which minimizes the norm of the residue defined as:
\begin{equation}
r = f(x_i) - y
\end{equation}
Therefore $\lim_{i\rightarrow\infty} f(x_i) = y$.
If a solution to the original problem exists, ignoring precision issues, the minimum residual converges to it, and the residue decreases at each iteration.

Notice that in the following code, $x$ and $y$ are exchanged because we adopt the convention that $y$ is the output and $x$ is the input:

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
import copy

def invert_minimum_residual(f, x, ap=1e-4, rp=1e-4, ns=200):
    y = copy.copy(x)
    r = x-1.0 * f(x)
    for k in range(ns):
        q = f(r)
        alpha = (q * r)/(q * q)
        y = y + alpha * r
        r = r - alpha * q
        residue = sqrt((r * r)/r.nrows)
        if residue<max(ap, norm(y) * rp): return y
    raise ArithmeticError("no convergence")
\end{lstlisting}

\goodbreak\subsection{Stabilized biconjugate gradient}

\index{bi-conjugate gradient}

The stabilized biconjugate gradient~\cite{bicgstab} method is also based on constructing a Krylov subspace and minimizing the same residue as in the minimum residual algorithm, yet it is faster than the minimum residual and has a smoother convergence than other conjugate gradient methods:

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
def invert_bicgstab(f, x, ap=1e-4, rp=1e-4, ns=200):
    y = copy.copy(x)
    r = x - 1.0 * f(x)
    q = r
    p = 0.0
    s = 0.0
    rho_old = alpha = omega = 1.0
    for k in range(ns):
        rho = q * r
        beta = (rho/rho_old) * (alpha/omega)
        rho_old = rho
        p = beta * p + r - (beta * omega) * s
        s = f(p)
        alpha = rho/(q * s)
        r = r - alpha * s
        t = f(r)
        omega = (t * r)/(t * t)
        y = y + omega * r + alpha * p
        residue=sqrt((r * r)/r.nrows)
        if residue<max(ap, norm(y) * rp): return y
        r = r - omega * t
    raise ArithmeticError("no convergence")
\end{lstlisting}

Notice that the minimum residual and the stabilized biconjugate gradient, if they converge, converge to the same value.

As an example, consider the following. We take a picture using a camera, but we take the picture out of focus. The image is represented by a set of $m^2$ pixels. The defocusing operation can be modeled as a first approximation with a linear operator acting on the ``true'' image, $x$, and turning it into an ``out of focus'' image, $y$. We can store the pixels in a one-dimensional vector (both for $x$ and $y$) as opposed to a matrix by mapping the pixel $(r, c)$ into vector component $i$ using the relation $(r, c) = (i/m, i\%m)$.

Hence we can write

\begin{equation}
\mathbf{y} = A \mathbf{x}
\end{equation}

Here the linear operator $A$ represents the effects of the lens, which transforms one set of pixels into another.

We can model the lens as a sequence of $\beta$ smearing operators:

\begin{equation}
A = S^{\beta}
\end{equation}

where a smearing operator is a next neighbor interaction among pixels:

\begin{equation}
S_{ij} = (1-\alpha/4) \delta_{i, j} + \alpha \delta_{i, j\pm 1} + \alpha \delta_{i, j\pm m}
\end{equation}

Here $\alpha$ and $\beta$ are smearing coefficients. When $\alpha=0$ or $\beta=0$, the lens has no effect, and $A = I$. The value of $\alpha$ controls how much the value of light at point $i$ is averaged with the value at its four neighbor points: left ($j-1$), right ($j+1$), top ($j+m$), and bottom ($j-m$). The coefficient $\beta$ determines the width of the smearing radius. The larger the values of $\beta$ and $\alpha$, the more out of focus is the original image.

\index{image manipulation}\index{smearing}

In the following code, we generate an image $x$ and filter it through a lens operator {\ft smear}, obtaining a smeared image $y$. We then use the sparse matrix inverter to reconstruct the original image $x$ given the smeared image $y$. We use the {\ft color2d} plotting function to represent the images:

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
>>> m = 30
>>> x = Matrix(m * m, 1, fill=lambda r, c:(r//m in(10, 20) or r%m in(10, 20)) and 1. or 0.)
>>> def smear(x):
...     alpha, beta = 0.4, 8
...     for k in range(beta):
...        y = Matrix(x.nrows, 1)
...        for r in range(m):
...            for c in range(m):
...                y[r * m+c, 0] = (1.0-alpha/4) * x[r * m+c, 0]
...                if c<m-1: y[r * m+c, 0] += alpha * x[r * m+c+1, 0]
...                if c>0:   y[r * m+c, 0] += alpha * x[r * m+c-1, 0]
...                if r<m-1: y[r * m+c, 0] += alpha * x[r * m+c+m, 0]
...                if c>0:   y[r * m+c, 0] += alpha * x[r * m+c-m, 0]
...        x = y
...     return y
>>> y = smear(x)
>>> z = invert_minimum_residual(smear, y, ns=1000)
>>> y = y.reshape(m, m)
>>> Canvas(title="Defocused image").imshow(y.tolist()).save("images/defocused.png")
>>> Canvas(title="refocus image").imshow(z.tolist()).save("images/refocused.png")
\end{lstlisting}

\begin{figure}[ht]
\centering
\begin{tabular}{cc}
\includegraphics[width=2.2in]{images/defocused.png} &
\includegraphics[width=2.2in]{images/refocused.png}
\end{tabular}
\caption{An out-of-focus image (left) and the original image (image) computed from the out-of-focus one, using sparse matrix inversion.}
\end{figure}

When the Hubble telescope was first put into orbit, its mirror was not installed properly and caused the telescope to take pictures out of focus. Until the defect was physically corrected, scientists were able to fix the images using a similar algorithm.

\goodbreak\section{Solvers for nonlinear equations}

\index{non-linear equations}

In this chapter, we are concerned with the problem of solving in $x$ the equation of one variable:

\begin{equation}
f(x) = 0
\end{equation}

\goodbreak\subsection{Fixed-point method}

\index{fixed point method}

It is always possible to reformulate $f(x)=0$ as $g(x)=x$ using, for example, one of the following definitions:
\begin{itemize}
\item $g(x) = f(x)/c+x$ for some constant $c$
\item $g(x) = f(x)/q(x)+x$ for some $q(x)>0$ at the solution of $f(x)=0$
\end{itemize}

We start at $x_0$, an arbitrary point in the domain, and close to the solution we seek. We compute
\begin{eqnarray}
x_1 &=& g(x_0) \\
x_2 &=& g(x_1) \\
x_3 &=& g(x_2) \\
... &=& ...
\end{eqnarray}
We can compute the distance between $x_i$ and $x$ as
\begin{eqnarray}
|x_i - x| &=& |g(x_{i-1})-g(x)| \\
          &=& |g(x)+g"(\xi)(x_{i-1}-x)-g(x)| \\
          &=& |g"(\xi)||x_{i-1}-x|
\end{eqnarray}
where we use {\it de l"Hopital rule} and $\xi$ is a point in between $x$ and $x_{i-1}$.

If the magnitude of the first derivative of $g$, $|g"|$, is less than 1 in a neighborhood of $x$, and if $x_0$ is in such a neighborhood, then

\begin{equation}
|x_i - x| = |g"(\xi)||x_{i-1}-x| < |x_{i-1}-x|
\end{equation}

The $x_i$ series will get closer and closer to the solution $x$.

Here is the process implemented into an algorithm:

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
def solve_fixed_point(f, x, ap=1e-6, rp=1e-4, ns=100):
    def g(x): return f(x)+x  # f(x)=0 <=> g(x)=x
    Dg = D(g)
    for k in range(ns):
        if abs(Dg(x)) >= 1:
            raise ArithmeticError("error D(g)(x)>=1")
        (x_old, x) = (x, g(x))
        if k>2 and norm(x_old-x)<max(ap, norm(x) * rp):
            return x
    raise ArithmeticError("no convergence")
\end{lstlisting}

And here is an example:

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
>>> def f(x): return (x-2) * (x-5)/10
>>> round(solve_fixed_point(f, 1.0, rp=0), 4)
2.0
\end{lstlisting}

\goodbreak\subsection{Bisection method}

\index{bisection method}

The goal of the bisection~\cite{bisection} method is to solve $f(x)=0$ when the function is continuous and it is known to change sign in between $x=a$ and $x=b$. The bisection method is the continuous equivalent of the binary search algorithm seen in chapter 3. The algorithm iteratively finds the middle point of the domain $x=(b+a)/2$, evaluates the function there, and decides whether the solution is on the left or the right, thus reducing the size of the domain from $(a, b)$ to $(a, x)$ or $(x, b)$, respectively:

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
def solve_bisection(f, a, b, ap=1e-6, rp=1e-4, ns=100):
    fa, fb = f(a), f(b)
    if fa == 0: return a
    if fb == 0: return b
    if fa * fb > 0:
        raise ArithmeticError("f(a) and f(b) must have opposite sign")
    for k in range(ns):
        x = (a+b)/2
        fx = f(x)
        if fx == 0 or norm(b-a)<max(ap, norm(x) * rp): return x
        elif fx * fa < 0: (b, fb) = (x, fx)
        else: (a, fa) = (x, fx)
    raise ArithmeticError("no convergence")
\end{lstlisting}

Here is how to use it:

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
>>> def f(x): return (x-2) * (x-5)
>>> round(solve_bisection(f, 1.0, 3.0), 4)
2.0
\end{lstlisting}

\goodbreak\subsection{Newton method}

\index{Newton solver}

The Newton~\cite{newton} algorithm also solves $f(x)=0$. It is faster (on average) than the bisection method because it makes the additional assumption that the function is also differentiable. This algorithm starts from an arbitrary point $x_0$ and approximates the function at that point with its first-order Taylor expansion
\begin{equation}
f(x) \simeq f(x_0) + f'(x_0)(x-x_0)
\end{equation}
and solves it exactly:
\begin{equation}
f(x) = 0 \rightarrow x = x_0 - \frac{f(x_0)}{f'(x_0)}
\end{equation}
thus finding a new and better estimate for the solution. The algorithm iterates the preceding equation, and when it converges, it approximates the exact solution better and better:

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
def solve_newton(f, x, ap=1e-6, rp=1e-4, ns=20):
    x = float(x)  # make sure it is not int
    for k in range(ns):
        (fx, Dfx) = (f(x), D(f)(x))
        if norm(Dfx) < ap:
            raise ArithmeticError("unstable solution")
        (x_old, x) = (x, x-fx/Dfx)
        if k>2 and norm(x-x_old)<max(ap, norm(x) * rp): return x
    raise ArithmeticError("no convergence")
\end{lstlisting}

The algorithm is guaranteed to converge if $|f'(x)|>1$ in some neighborhood of the solution and if the starting point is in this neighborhood. It may also converge if this condition is not true. It is likely to fail when $|f'(x)|\simeq 0$ is in the neighborhood of the solution or the starting point because the terms {\ft fx/Dfx} would become very large.

Here is an example:

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
>>> def f(x): return (x-2) * (x-5)
>>> round(solve_newton(f, 1.0), 4)
2.0
\end{lstlisting}

\goodbreak\subsection{Secant method}

\index{secant method}

The secant method is very similar to the Newton method, except that $f'(x)$ is replaced by a numerical estimate computed using the current point $x$ and the previous point visited by the algorithm:
\begin{eqnarray}
f'(x_i) &=& \frac{f(x_i)-f(x_{i-1})}{x_i-x_{i-1}} \\
x_{i+i} &=& x_i - \frac{f(x_i)}{f'(x_i)}
\end{eqnarray}
As the algorithm approaches the exact solution, the numerical derivative becomes a better and better approximation for the derivative:

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
def solve_secant(f, x, ap=1e-6, rp=1e-4, ns=20):
    x = float(x)  # make sure it is not int
    (fx, Dfx) = (f(x), D(f)(x))
    for k in range(ns):
        if norm(Dfx) < ap:
            raise ArithmeticError("unstable solution")
        (x_old, fx_old, x) = (x, fx, x-fx/Dfx)
        if k>2 and norm(x-x_old)<max(ap, norm(x) * rp): return x
        fx = f(x)
        Dfx = (fx-fx_old)/(x-x_old)
    raise ArithmeticError("no convergence")
\end{lstlisting}

Here is an example:

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
>>> def f(x): return (x-2) * (x-5)
>>> round(solve_secant(f, 1.0), 4)
2.0
\end{lstlisting}

\goodbreak\section{Optimization in one dimension}

\index{optimization}

While a solver is an algorithm that finds $x$ such that $f(x)=0$, an optimization algorithm is one that finds the maximum or minimum of the function $f(x)$. If the function is differentiable, this is achieved by solving $f'(x)=0$.

For this reason, if the function is differentiable twice, we can simply rename all previous solvers and replace $f(x)$ with $f'(x)$ and $f'(x)$ with $f''(x)$.

\goodbreak\subsection{Bisection method}

\index{bisection method}

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
def optimize_bisection(f, a, b, ap=1e-6, rp=1e-4, ns=100):
    return solve_bisection(D(f), a, b , ap, rp, ns)
\end{lstlisting}

Here is an example:

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
>>> def f(x): return (x-2) * (x-5)
>>> round(optimize_bisection(f, 2.0, 5.0), 4)
3.5
\end{lstlisting}

\goodbreak\subsection{Newton method}

\index{Newton optimization}

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
def optimize_newton(f, x, ap=1e-6, rp=1e-4, ns=20):
    x = float(x)  # make sure it is not int
    (f, Df) = (D(f), DD(f))
    for k in range(ns):
        (fx, Dfx) = (f(x), Df(x))
        if Dfx == 0: return x
        if norm(Dfx) < ap:
            raise ArithmeticError("unstable solution")
        (x_old, x) = (x, x-fx/Dfx)
        if norm(x-x_old)<max(ap, norm(x) * rp): return x
    raise ArithmeticError("no convergence")
\end{lstlisting}

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
>>> def f(x): return (x-2) * (x-5)
>>> round(optimize_newton(f, 3.0), 3)
3.5
\end{lstlisting}

\goodbreak\subsection{Secant method}

\index{secant method}

As in the Newton case, the secant method can also be used to find extrema, by replacing $f$ with $f'$:

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
def optimize_secant(f, x, ap=1e-6, rp=1e-4, ns=100):
    x = float(x)  # make sure it is not int
    (f, Df) = (D(f), DD(f))
    (fx, Dfx) = (f(x), Df(x))
    for k in range(ns):
        if fx == 0: return x
        if norm(Dfx) < ap:
            raise ArithmeticError("unstable solution")
        (x_old, fx_old, x) = (x, fx, x-fx/Dfx)
        if norm(x-x_old)<max(ap, norm(x) * rp): return x
        fx = f(x)
        Dfx = (fx - fx_old)/(x-x_old)
    raise ArithmeticError("no convergence")
\end{lstlisting}

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
>>> def f(x): return (x-2) * (x-5)
>>> round(optimize_secant(f, 3.0), 3)
3.5
\end{lstlisting}

\goodbreak\subsection{Golden section search}

\index{golden section search}

If the function we want to optimize is continuous but not differentiable, then the previous algorithms do not work. In this case, there is one algorithm that comes to our rescue, the golden section~\cite{golden} search. It is similar to the bisection method, with one caveat; in the bisection method, at each point, we need to know if a function changes sign in between two points, therefore two points are all we need. If instead we are looking for a max or min, we need to know if the function is concave or convex in between those two points. This requires one extra point in between the two. So while the bisection method only needs one point in between $[a, b]$, the golden search needs two points, $x_1$ and $x_2$, in between $[a, b]$, and from them it can determine whether the extreme is in $[a, x_2]$ or in $[x_1, b]$. This is also represented pictorially in fig.~\ref{golden-pic}. The two points are chosen in an optimal way so that at the next iteration, one of the two points can be recycled by leaving the ratio between $x_1-a$ and $b-x_2$ fixed and equal to 1:

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
def optimize_golden_search(f, a, b, ap=1e-6, rp=1e-4, ns=100):
    a, b=float(a), float(b)
    tau = (sqrt(5.0)-1.0)/2.0
    x1, x2 = a+(1.0-tau) * (b-a), a+tau * (b-a)
    fa, f1, f2, fb = f(a), f(x1), f(x2), f(b)
    for k in range(ns):
        if f1 > f2:
            a, fa, x1, f1 = x1, f1, x2, f2
            x2 = a+tau * (b-a)
            f2 = f(x2)
        else:
            b, fb, x2, f2 = x2, f2, x1, f1
            x1 = a+(1.0-tau) * (b-a)
            f1 = f(x1)
        if k>2 and norm(b-a)<max(ap, norm(b) * rp): return b
    raise ArithmeticError("no convergence")
\end{lstlisting}

Here is an example:

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
>>> def f(x): return (x-2) * (x-5)
>>> round(optimize_golden_search(f, 2.0, 5.0), 3)
3.5
\end{lstlisting}

\begin{figure}[ht]
\centering\includegraphics[width=2in]{images/golden.png}
\caption{Pictorial representation of the golden search method. If the function is concave ($f''(x)>0$), then knowledge of the function in 4 points ($a$, $x_1$, $x_2$, $b$) permits us to determine whether a minimum is between $[a, x_2]$ or between $[x_1, b]$.\label{golden-pic}}.
\end{figure}

\goodbreak\section{Functions of many variables}

\index{partial derivative}

To be able to work with functions of many variables, we need to introduce the concept of the partial derivative:

\begin{equation}
\frac{\partial f(\mathbf{x})}{\partial x_i} = \lim_{h \rightarrow 0} \frac{f(\mathbf{x}+\mathbf{h}_i) - f(\mathbf{x}-\mathbf{h}_i)}{2h}
\end{equation}
where $\mathbf{h}_i$ is a vector with components all equal to zero but $h_i = h > 0$.

We can implement it as follows:

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
def partial(f, i, h=1e-4):
    def df(x, f=f, i=i, h=h):
        x = list(x)  # make copy of x
        x[i] += h
        f_plus = f(x)
        x[i] -= 2 * h
        f_minus = f(x)
        if isinstance(f_plus, (list, tuple)):
            return [(f_plus[i]-f_minus[i])/(2 * h) for i in range(len(f_plus))]
        else:
            return (f_plus-f_minus)/(2 * h)
    return df
\end{lstlisting}

Similarly to {\ft D(f)}, we have implemented it in such a way that {\ft partial(f, i)} returns a function that can be evaluated at any point $x$. Also notice that the function $f$ may return a scalar, a matrix, a list, or a tuple. The {\ft if} condition allows the function to deal with the difference between two lists or tuples.

Here is an example:

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
>>> def f(x): return 2.0 * x[0]+3.0 * x[1]+5.0 * x[1] * x[2]
>>> df0 = partial(f, 0)
>>> df1 = partial(f, 1)
>>> df2 = partial(f, 2)
>>> x = (1, 1, 1)
>>> round(df0(x), 4), round(df1(x), 4), round(df2(x), 4)
(2.0, 8.0, 5.0)
\end{lstlisting}

\goodbreak\subsection{Jacobian, gradient, and Hessian}

\index{Jacobian}\index{Gradient}\index{Hessian}

A generic function $f(x_0, x_1, x_2, ...)$ of multiple variables $\mathbf{x}=(x_0, x_1, x_2, ..)$ can be expanded in Taylor series to the second order as

\begin{eqnarray}
f(x_0, x_1, x_2, ...) &=& f(\bar x_0, \bar x_1, \bar x_2, ...) + \\
&& \sum_i \frac{\partial f(\mathbf{\bar x})}{\partial x_i}(x_i-\bar x_i) + \\
&& \sum_{ij} \frac12 \frac{\partial^2 f}{\partial x_i\partial x_j}(\mathbf{\bar x})(x_i-\bar x_i)(x_j-\bar x_j) + ...
\end{eqnarray}

We can rewrite the above expression in terms of the vector $\mathbf{x}$ as follows:

\begin{equation}
f(\mathbf{x}) = f(\mathbf{\bar x}) + \nabla_f(\mathbf{\bar x})(\mathbf{x}-\mathbf{\bar x})
+ \frac12 (\mathbf{x}-\mathbf{\bar x})^t H_f(\mathbf{\bar x})(\mathbf{x}-\mathbf{\bar x}) + ...
\end{equation}

where we introduce the gradient vector

\begin{equation}
\nabla_f(x) \equiv \left(
\begin{tabular}{c}
$\partial f(x)/\partial x_0$ \\
$\partial f(x)/\partial x_1$ \\
$\partial f(x)/\partial x_2$ \\
...
\end{tabular}
\right)
\end{equation}

and the Hessian matrix

\begin{equation}
H_f(x) \equiv \left(
\begin{tabular}{cccc}
$\partial^2 f(x)/\partial x_0\partial x_0$ &
$\partial^2 f(x)/\partial x_0\partial x_1$ &
$\partial^2 f(x)/\partial x_0\partial x_2$ &
... \\
$\partial^2 f(x)/\partial x_1\partial x_0$ &
$\partial^2 f(x)/\partial x_1\partial x_1$ &
$\partial^2 f(x)/\partial x_1\partial x_2$ &
... \\
$\partial^2 f(x)/\partial x_2\partial x_0$ &
$\partial^2 f(x)/\partial x_2\partial x_1$ &
$\partial^2 f(x)/\partial x_2\partial x_2$ &
... \\
... & ... & ... & ...
\end{tabular}
\right)
\end{equation}

Given the definition of partial, we can compute the gradient and the Hessian using the two functions

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
def gradient(f, x, h=1e-4):
    return Matrix(len(x), 1, fill=lambda r, c: partial(f, r, h)(x))

def hessian(f, x, h=1e-4):
    return Matrix(len(x), len(x), fill=lambda r, c: partial(partial(f, r, h), c, h)(x))
\end{lstlisting}

Here is an example:

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
>>> def f(x): return 2.0 * x[0]+3.0 * x[1]+5.0 * x[1] * x[2]
>>> print(gradient(f, x=(1, 1, 1)))
[[1.999999...], [7.999999...], [4.999999...]]
>>> print(hessian(f, x=(1, 1, 1)))
[[0.0, 0.0, 0.0], [0.0, 0.0, 5.000000...], [0.0, 5.000000..., 0.0]]
\end{lstlisting}

When dealing with functions returning multiple values like
\begin{equation}
f(\mathbf{x}) = (f_0(\mathbf{x}), f_1(\mathbf{x}), f_2(\mathbf{x}), ...)
\end{equation}

we need to Taylor expand each component:

\begin{equation}
f(\mathbf{x}) =
\left(
\begin{tabular}{c}
$f_0(\mathbf{x})$ \\
$f_1(\mathbf{x})$ \\
$f_2(\mathbf{x})$ \\
...
\end{tabular}
\right) =
\left(
\begin{tabular}{c}
$f_0(\mathbf{\bar x}) + \nabla_{f_0}(\mathbf{x}-\mathbf{\bar x}) + ...$ \\
$f_1(\mathbf{\bar x}) + \nabla_{f_1}(\mathbf{x}-\mathbf{\bar x}) + ...$ \\
$f_2(\mathbf{\bar x}) + \nabla_{f_2}(\mathbf{x}-\mathbf{\bar x}) + ...$ \\
...
\end{tabular}
\right)
\end{equation}

which we can rewrite as

\begin{equation}
f(\mathbf{x}) = f(\mathbf{\bar x}) + J_f(\mathbf{\bar x})(\mathbf{x}-\mathbf{\bar x}) + ... \label{jacobian2}
\end{equation}

where $J_f$ is called Jacobian and is defined as

\begin{equation}
J_f \equiv
\left(
\begin{tabular}{cccc}
$\partial f_0(x)/\partial x_0$ &
$\partial f_0(x)/\partial x_1$ &
$\partial f_0(x)/\partial x_2$ &
... \\
$\partial f_1(x)/\partial x_0$ &
$\partial f_1(x)/\partial x_1$ &
$\partial f_1(x)/\partial x_2$ &
... \\
$\partial f_2(x)/\partial x_0$ &
$\partial f_2(x)/\partial x_1$ &
$\partial f_2(x)/\partial x_2$ &
... \\
... & ... & ... & ...
\end{tabular}
\right)
\end{equation}

which we can implement as follows:

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
def jacobian(f, x, h=1e-4):
    partials = [partial(f, c, h)(x) for c in range(len(x))]
    return Matrix(len(partials[0]), len(x), fill=lambda r, c: partials[c][r])
\end{lstlisting}

Here is an example:

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
>>> def f(x): return (2.0 * x[0]+3.0 * x[1]+5.0 * x[1] * x[2], 2.0 * x[0])
>>> print(jacobian(f, x=(1, 1, 1)))
[[1.9999999..., 7.999999..., 4.9999999...], [1.9999999..., 0.0, 0.0]]
\end{lstlisting}

\goodbreak\subsection{Newton method (solver)}

\index{Newton solver!multidimensional}

We can now solve eq.~\ref{jacobian2} iteratively as we did for the one-dimensional Newton solver with only one change---the first derivative of $f$ is replaced by the Jacobian:

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
def solve_newton_multi(f, x, ap=1e-6, rp=1e-4, ns=20):
    """
    Computes the root of a multidimensional function f near point x.

    Parameters
    f is a function that takes a list and returns a scalar
    x is a list

    Returns x, solution of f(x)=0, as a list
    """
    n = len(x)
    x = Matrix(len(x))
    for k in range(ns):
        fx = Matrix(f(x.flatten()))
        J = jacobian(f, x.flatten())
        if norm(J) < ap:
            raise ArithmeticError("unstable solution")
        (x_old, x) = (x, x-(1.0/J) * fx)
        if k>2 and norm(x-x_old)<max(ap, norm(x) * rp): return x.flatten()
    raise ArithmeticError("no convergence")
\end{lstlisting}

Here is an example:

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
>>> def f(x): return [x[0]+x[1], x[0]+x[1] ** 2-2]
>>> solve_newton_multi(f, x=(0, 0))
[1.0..., -1.0...]
\end{lstlisting}

\goodbreak\subsection{Newton method (optimize)}

\index{Newton optimizer!multi-dimensional}

As for the one-dimensional case, we can approximate $f(\mathbf{x})$ with its Taylor expansion at the first order, 
\begin{equation}
f(\mathbf{x}) = f(\mathbf{\bar x}) + \nabla_f(\mathbf{\bar x})(\mathbf{x}-\mathbf{\bar x}) +
\frac12 (\mathbf{x}-\mathbf{\bar x})^t H_f(\mathbf{\bar x})(\mathbf{x}-\mathbf{\bar x})
\end{equation}
set its derivative to zero, and solve it, thus obtaining
\begin{equation}
\mathbf{x} = \mathbf{\bar x} - H^{-1}_f \nabla_f
\end{equation}
which constitutes the core of the multidimensional Newton optimizer:

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
def optimize_newton_multi(f, x, ap=1e-6, rp=1e-4, ns=20):
    """
    Finds the extreme of multidimensional function f near point x.

    Parameters
    f is a function that takes a list and returns a scalar
    x is a list

    Returns x, which maximizes of minimizes f(x)=0, as a list
    """
    x = Matrix(list(x))
    for k in range(ns):
        (grad, H) = (gradient(f, x.flatten()), hessian(f, x.flatten()))
        if norm(H) < ap:
            raise ArithmeticError("unstable solution")
        (x_old, x) = (x, x-(1.0/H) * grad)
        if k>2 and norm(x-x_old)<max(ap, norm(x) * rp): return x.flatten()
    raise ArithmeticError("no convergence")
\end{lstlisting}

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
>>> def f(x): return (x[0]-2) ** 2+(x[1]-3) ** 2
>>> optimize_newton_multi(f, x=(0, 0))
[2.0, 3.0]
\end{lstlisting}

\goodbreak\subsection{Improved Newton method (optimize)}

We can further improve the Newton multidimensional optimizer by using the following technique. At each step, if the next guess does not reduce the value of $f$, we revert to the previous point, and we perform a one-dimensional Newton optimization along the direction of the gradient. This method greatly increases the stability of the multidimensional Newton optimizer:

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
def optimize_newton_multi_imporved(f, x, ap=1e-6, rp=1e-4, ns=20, h=10.0):
    """
    Finds the extreme of multidimensional function f near point x.

    Parameters
    f is a function that takes a list and returns a scalar
    x is a list

    Returns x, which maximizes of minimizes f(x)=0, as a list
    """
    x = Matrix(list(x))
    fx = f(x.flatten())
    for k in range(ns):
        (grad, H) = (gradient(f, x.flatten()), hessian(f, x.flatten()))
        if norm(H) < ap:
            raise ArithmeticError("unstable solution")
        (fx_old, x_old, x) = (fx, x, x-(1.0/H) * grad)
        fx = f(x.flatten())
        while fx>fx_old:  # revert to steepest descent
            (fx, x) = (fx_old, x_old)
            norm_grad = norm(grad)
            (x_old, x) = (x, x - grad/norm_grad * h)
            (fx_old, fx) = (fx, f(x.flatten()))
            h = h/2
        h = norm(x-x_old) * 2
        if k>2 and h/2<max(ap, norm(x) * rp): return x.flatten()
    raise ArithmeticError("no convergence")
\end{lstlisting}

\goodbreak\section{Nonlinear fitting}

Finally, we have all the ingredients to implement a very generic fitting function that will work linear and nonlinear least squares.

Here we consider a generic experiment or simulated experiment that generates points of the form $(x_i, y_i \pm \delta y_i)$. Our goal is to minimize the $\chi^2$ defined as
\begin{equation}
\chi^2(\mathbf{a}, \mathbf{b}) = \sum _i \left|
\frac{y_i - f(x_i, \mathbf{a}, \mathbf{b})}{\delta y_i}
\right|^2
\end{equation}
where the function $f$ is known but depends on unknown parameters $\mathbf{a}=(a_0, a_1, ...)$ and $\mathbf{b}=(b_0, b_1, ...)$. In terms of these parameters, the function $f$ can be written as follows:
\begin{equation}
f(x, \mathbf{a}, \mathbf{b}) = \sum_j a_j f_j(x, \mathbf{b})
\end{equation}
Here is an example:
\begin{equation}
f(x, \mathbf{a}, \mathbf{b}) = a_0 e^{-b_0 x} + a_1 e^{-b_1 x} + a_2 e^{-b_2 x} + ...
\end{equation}
The goal of our algorithm is to efficiently determine the parameters $\mathbf{a}$ and $\mathbf{b}$ that minimize the $\chi^2$.

We proceed by defining the following two quantities:

\begin{equation}
\mathbf{z} = \left(
\begin{tabular}{c}
$y_0$ / $\delta y_0$ \\
$y_1$ / $\delta y_1$ \\
$y_2$ / $\delta y_2$ \\
...
\end{tabular}
\right)
\end{equation}

and

\begin{equation}
A(\mathbf{b}) = \left(
\begin{tabular}{cccc}
$f_0(x_0, \mathbf{b})/\delta y_0$ &
$f_1(x_0, \mathbf{b})/\delta y_0$ &
$f_2(x_0, \mathbf{b})/\delta y_0$ & ... \\
$f_0(x_1, \mathbf{b})/\delta y_1$ &
$f_1(x_1, \mathbf{b})/\delta y_1$ &
$f_2(x_1, \mathbf{b})/\delta y_1$ & ... \\
$f_0(x_2, \mathbf{b})/\delta y_2$ &
$f_1(x_2, \mathbf{b})/\delta y_2$ &
$f_2(x_2, \mathbf{b})/\delta y_2$ & ... \\
... & ... & ... & ...
\end{tabular}
\right)
\end{equation}

In terms of $A$ and $z$, the $\chi^2$ can be rewritten as

\begin{equation}
\chi^2(\mathbf{a}, \mathbf{b}) = \left| A(\mathbf{b}) \mathbf{a} - \mathbf{z} \right|^2
\end{equation}

We can minimize this function in $a$ using the linear least squares algorithm, exactly:

\begin{equation}
\mathbf{a}(\mathbf{b}) = (A(\mathbf{b}) A(\mathbf{b})^t)^{-1}(A(\mathbf{b})^t z)
\end{equation}

We define a function that returns the minimum $\chi^2$ for a fixed input $\mathbf{b}$:

\begin{equation}
g(\mathbf{b}) =
\min_{\mathbf{a}}
\chi^2(\mathbf{a}, \mathbf{b}) =
\chi^2(\mathbf{a}(\mathbf{b}), \mathbf{b}) = \left|
A(\mathbf{b})\mathbf{a}(\mathbf{b}) - \mathbf{z}
\right|^2
\end{equation}

Therefore we have reduced the original problem to a simple problem by reducing the number of unknown parameters from $N_a+N_b$ to $N_b$.

The following code takes as input the {\ft data} as a list of $(x_i, y_i, \delta y_i)$, a list of functions (or a single function), and a guess for the $\mathbf{b}$ values. If the {\ft fs} argument is not a list but a single function, then there is no $\mathbf{a}$ to compute, and the function proceeds by minimizing the $\chi^2$ using the improved Newton optimizer (the one-dimensional or the improved multidimensional one, as appropriate). If the argument $\mathbf{b}$ is missing, then the fitting parameters are all linear, and the algorithm reverts to regular linear least squares. Otherwise, run the more complex algorithm described earlier:

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
def fit(data, fs, b=None, ap=1e-6, rp=1e-4, ns=200, constraint=None):
    if not isinstance(fs, (list, tuple)):
        def g(b, data=data, f=fs, constraint=constraint):
            chi2 = sum(((y-f(b, x))/dy) ** 2 for (x, y, dy) in data)
            if constraint: chi2+=constraint(b)
            return chi2
        if isinstance(b, (list, tuple)):
            b = optimize_newton_multi_imporved(g, b, ap, rp, ns)
        else:
            b = optimize_newton(g, b, ap, rp, ns)
        return b, g(b, data, constraint=None)
    elif not b:
        a, chi2, ff = fit_least_squares(data, fs)
        return a, chi2
    else:
        na = len(fs)
        def core(b, data=data, fs=fs):
            A = Matrix([[fs[k](b, x)/dy for k in range(na)] \
                                  for (x, y, dy) in data])
            z = Matrix([[y/dy] for (x, y, dy) in data])
            a = (1/(A.T * A)) * (A.T * z)
            chi2 = norm(A * a-z) ** 2
            return a.flatten(), chi2
        def g(b, data=data, fs=fs, constraint=constraint):
            a, chi2 = core(b, data, fs)
            if constraint:
                chi += constraint(b)
            return chi2
        b = optimize_newton_multi_imporved(g, b, ap, rp, ns)
        a, chi2 = core(b, data, fs)
        return a+b, chi2
\end{lstlisting}

Here is an example:

%%% META:FILE:nlib.py
\begin{lstlisting}
>>> data = [(i, i+2.0 * i ** 2+300.0/(i+10), 2.0) for i in range(1, 10)]
>>> fs = [(lambda b, x: x), (lambda b, x: x * x), (lambda b, x: 1.0/(x+b[0]))]
>>> ab, chi2 = fit(data, fs, [5])
>>> print(ab, chi2)
[0.999..., 2.000..., 300.000..., 10.000...] ...
\end{lstlisting}

\index{a priori}\index{Bayesian statistics}

In the preceding implementation, we added a somewhat mysterious argument {\ft constraint}. This is a function of $\mathbf{b}$, and its output gets added to the value of $\chi^2$, which we are minimizing. By choosing the appropriate function, we can set constraints about the expected values $b$. These constraints represent a priori knowledge about the parameters, that is, knowledge that does not come from the data being fitted.

For example, if we know that $b_i$ must be close to some $\bar b_i$ with some uncertainty $\delta b_i$, then we can use
\begin{lstlisting}
def constraint(b, bar_b, delta_b):
    return sum(((b[i]-bar_b[i])/delta_b[i]) ** 2 for i in range(len(b)))
\end{lstlisting}

and pass the preceding function as a constraint.
From a practical effect, this stabilizes our fit. From a theoretical point of view, the $\bar b_i$ are the {\it priors} of Bayesian statistics.

\goodbreak\section{Integration}

\index{integration!numerical}\index{integration!trapezoid}

Consider the integral of $f(x)$ for $x$ in domain $[a, b]$, which we normally represent as

\begin{equation}
I = \int_a^b f(x)dx
\end{equation}
 and which measures the area under the curve $y=f(x)$ delimited on the left by $x=a$ and on the right by $x=b$.

\begin{figure}[ht]
\centering\includegraphics[width=2in]{images/integral1.png}
\caption{Visual representation of the concept of an integral as the area under a curve.}
\end{figure}

As we did in the previous subsection, we can approximate the possible values taken by $x$ as discrete values $x\equiv h i$, where $h=(b-a)/n$. At those values, the function $f$ evaluates to $f_i \equiv f(h i)$. Thus the integral can be approximated as a sum of trapezoids:

\begin{equation}
  I_n \simeq \sum_{i=0}^{i<n} \frac{h}{2}(f_i+f_{i+1})
\end{equation}

\begin{figure}[ht]
\centering\includegraphics[width=2in]{images/integral2.png}
\caption{Visual representation of the trapezoid method for numerical integration.}
\end{figure}

If a function is discontinuous only in a finite number of points in the domain $[a, b]$, then the following limit exists:

\begin{equation}
\lim_{n\rightarrow\infty} I_n \rightarrow I
\end{equation}

We can implement the naive integration as a function of $N$ as follows:

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
def integrate_naive(f, a, b, n=20):
    """
    Integrates function, f, from a to b using the trapezoidal rule
    >>> from math import sin
    >>> integrate(sin, 0, 2)
    1.416118...
    """
    a, b= float(a), float(b)
    h = (b-a)/n
    return h/2 * (f(a)+f(b))+h * sum(f(a+h * i) for i in range(1, n))
\end{lstlisting}

And here we implement the limit by doubling the number of points until convergence is achieved:

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
def integrate(f, a, b, ap=1e-4, rp=1e-4, ns=20):
    """
    Integrates function, f, from a to b using the trapezoidal rule
    converges to precision
    """
    I = integrate_naive(f, a, b, 1)
    for k in range(1, ns):
        I_old, I = I, integrate_naive(f, a, b, 2 ** k)
        if k>2 and norm(I-I_old)<max(ap, norm(I) * rp): return I
    raise ArithmeticError("no convergence")
\end{lstlisting}

We can test the convergence as follows:

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
>>> from math import sin, cos
>>> integrate_naive(sin, 0, 3, n=2)
1.6020...
>>> integrate_naive(sin, 0, 3, n=4)
1.8958...
>>> integrate_naive(sin, 0, 3, n=8)
1.9666...
>>> integrate(sin, 0, 3)
1.9899...
>>> 1.0-cos(3)
1.9899...
\end{lstlisting}

\goodbreak\subsection{Quadrature}

\index{integration!quadrature}

In the previous integration, we divided the domain $[a, b]$ into subdomains, and we computed the area under the curve $f$ in each subdomain by approximating it with a trapezoid; for example, we approximated the function in between $x_i$ and $x_{i+1}$ with a straight line. We can do better by approximating the function with a polynomial of arbitrary degree $n$ and then compute the area in the subdomain by explicitly integrating the polynomial.

This is the basic idea of quadrature. For a subdomain delimited by $(0, 1)$, we can impose
\begin{eqnarray}
\int_0^1 1\textrm{d}x &= h &= \sum_i c_i (i/n)^0 \\
\int_0^1 x\textrm{d}x &= h^2/2 &= \sum_i c_i (i/n)^1 \\
... & ... & ... \\
\int_0^1 x^{n-1}\textrm{d}x &= h^n/n &= \sum_i c_i (i/n)^2
\end{eqnarray}
where $c_i$ are coefficients to be determined:

\index{class!QuadratureIntegrator}

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
class QuadratureIntegrator:
    """
    Calculates the integral of the function f from points a to b
    using n Vandermonde weights and numerical quadrature.
    """
    def __init__(self, order=4):
        h =1.0/(order-1)
        A = Matrix(order, order, fill = lambda r, c: (c * h) ** r)
        s = Matrix(order, 1, fill = lambda r, c: 1.0/(r+1))
        w = (1/A) * s
        self.w = w
    def integrate(self, f, a, b):
        w = self.w
        order = len(w.rows)
        h = float(b-a)/(order-1)
        return (b-a) * sum(w[i, 0] * f(a+i * h) for i in range(order))

def integrate_quadrature_naive(f, a, b, n=20, order=4):
    a, b = float(a), float(b)
    h = float(b-a)/n
    q = QuadratureIntegrator(order=order)
    return sum(q.integrate(f, a+i * h, a+i * h+h) for i in range(n))
\end{lstlisting}

Here is an example of usage:

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
>>> from math import sin
>>> integrate_quadrature_naive(sin, 0, 3, n=2, order=2)
1.602...
>>> integrate_quadrature_naive(sin, 0, 3, n=2, order=3)
1.993...
>>> integrate_quadrature_naive(sin, 0, 3, n=2, order=4)
1.991...
\end{lstlisting}

\newpage
\section{Fourier transforms}

A function with a domain over a finite interval $[a, b]$ can be approximated with a vector. For example, consider a function $f(x)$ with domain $[0, T]$. We can sample the function at points $x_k = a+(b-a)k/N$ and represent the discretized function with a vector
\begin{equation}
\mathbf{u}_f \equiv \{cf(x_0), cf(x_1), cf(x_2), ... cf(x_N)\}
\end{equation}
where $c$ is an arbitrary constant that we choose to be $c=\sqrt{(b-a)/N}$. This choice simplifies our later algebra.
Summarizing, we define
\begin{equation}
u_{fk} \equiv \sqrt{\frac{b-a}{N}}f(x_k)
\end{equation}

Given any two functions, we can define their scalar product as the limit of $N\rightarrow\infty$ of the scalar product between their corresponding vectors:

\begin{equation}
f \cdot g \equiv \lim_{N\rightarrow\infty} \mathbf{u}_f \cdot \mathbf{u}_g =
\lim_{N\rightarrow\infty} \frac{b-a}{N} \sum_k f(x_k) g(x_k)
\end{equation}

Using the definition of integral, it can be proven that, in the limit $N\rightarrow\infty$, this is equivalent to

\begin{equation}
f \cdot g = \int_a^b f(x) g(x) dx
\end{equation}

This is because we have chosen $c$ such that $c^2$ is the width of a rectangle in the Riemann integration.

From now on, we will omit the $f$ subscript in $\mathbf{u}$ and simply use different letters for vectors representing different sampled functions ($\mathbf{u}$, $\mathbf{v}$, $\mathbf{b}$, etc.).

Because we are interested in numerical algorithms, we will keep $N$ finite and work with the sum instead of the integral.

Given a fixed $N$, we can always find $N$ vectors $\mathbf{b}_0, \mathbf{b}_1...\mathbf{b}_{N_1}$ that are linearly independent, normalized, and orthogonal, that is, 

\begin{equation}
\mathbf{b}_i \cdot \mathbf{b}_j = \sum_k b_{ik} b_{ik} = \delta_{ij}
\end{equation}

Here $b_{jk}$ is the $k$ component of vector $\mathbf{b}_j$ and $\delta_{ij}$ is the Kroneker delta defined as 0 when $i\neq j$ and 1 when $i == j$.

Any set of vectors $\{\mathbf{b}_j\}$ meeting the preceding condition is called an orthonormal basis. Any other vector $\mathbf{u}$ can be represented by its projections over the basis vectors:

\begin{equation}
  u_i = \sum_i v_j b_{ji}
\end{equation}

where $v_j$ is the projection of $u$ along $\mathbf{b}_j$, which can be computed as
\begin{equation}
  v_j = \sum_i u_i b_{ji}
\end{equation}

In fact, by direct substitution, we obtain

\begin{eqnarray}
  v_j &=& \sum_k u_k b_{jk} \\
      &=& \sum_k (\sum_i v_i b_{ik}) b_{jk} \\
      &=& \sum_i v_i (\sum_k b_{ik} b_{jk}) \\
      &=& \sum_i v_i \delta_{ij} \\
      &=& v_j
\end{eqnarray}

In other words, once we have a basis of vectors, the vector $\mathbf{u}$ can be represented in terms of the vector $\mathbf{v}$ of $v_j$ coefficients and, conversely, $\mathbf{v}$ can be computed from $\mathbf{u}$; $\mathbf{u}$ and $\mathbf{v}$ contain the same information.

The transformation from $\mathbf{u}$ to $\mathbf{v}$, and vice versa, is a linear transformation. We call $T^+$ the transformation from $\mathbf{u}$ to $\mathbf{v}$  and $T^-$ its inverse:

\begin{equation}
\mathbf{v} = T^+(\mathbf{u}) \qquad
\mathbf{u} = T^-(\mathbf{v})
\end{equation}

From the definition, and without attempting any optimization, we can implement these operators as follows:

\begin{lstlisting}
def transform(u, b):
    return [sum(u[k] * bi[k] for k in range(len(u))) for bi in b]

def antitransform(v, b):
    return [sum(v[i] * bi[k] for i, bi in enumerate(b)) for k in range(len(v))]
\end{lstlisting}

Here is an example of usage:

\begin{lstlisting}
>>> def make_basis(N):
>>>     return [[1 if i == j else 0 for i in range(N)] for j in range(N)]
>>> b = make_basis(4)
>>> b
[[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0], [0, 0, 0, 1]]
>>> u = [1.0, 2.0, 3.0, 4.0]
>>> v = transform(u, b)
>>> antitransform(v, b)
[1.0, 2.0, 3.0, 4.0]
\end{lstlisting}

Of course, this example is trivial because of the choice of basis which makes $v$ the same as $u$. Yet our argument works for any basis $\mathbf{b}_i$. In particular, we can make the following choice:


\begin{equation}
b_{ji} = \frac{1}{\sqrt{2\pi}} e^{2\pi I ij/N}
\end{equation}

where $I$ is the imaginary unit. With this choice, the $T^+$ and $T^-$ functions become

\begin{eqnarray}
v_j &\stackunder{FT^+}{=}& N^{-\frac12} \sum_i u_i e^{2\pi I ij/N} \\
\label{fourierd1}
u_i &\stackunder{FT^-}{=}& N^{-\frac12} \sum_j v_j e^{-2\pi I ij/N}
\label{fourierd2}
\end{eqnarray}

and they take the names of Fourier transform and anti-transform~\cite{fourier}, respectively;
we can implement them as follows:

\begin{lstlisting}
from cmath import exp as cexp

def fourier(u, sign=1):
    N, D = len(u), range(len(u))
    coeff, omega = 1.0/sqrt(N), 2.0 * pi * sign * (1j)/N
    return [sum(coeff * u[i] * cexp(omega * i * j) for i in D) for j in D]

def anti_fourier(v):
    return fourier(v, sign=-1)
\end{lstlisting}

Here $1j$ is the Python notation for $I$ and $cexp$ is the exponential function for complex numbers.

Notice how the transformation works even when $\mathbf{u}$ is a vector of complex numbers.

Something special happens when $u$ is real:
\begin{eqnarray}
Re(v_j) &=& +Re(v_{N-j-1}) \\
Im(v_j) &=& -Im(v_{N-j-1})
\end{eqnarray}

We can speed up the code even more using recursion and by observing that if $N$ is a power of $2$, then

\begin{eqnarray}
v_j &=& N^{-\frac12} \sum_i u_{2i} e^{2\pi I (2i)j/N} + \\
             &&  N^{-\frac12} \sum_i u_{2i+1} e^{2\pi I (2i+1)j/N} \\
             &=& 2^{-\frac12} ( v_j^{even} + e^{2\pi j/N} v_j^{even} )
\end{eqnarray}

where $v_j^{even}$ is the Fourier transform of the even terms and $v_j^{odd}$ is the Fourier transform of the odd terms.

The preceding recursive expression can be implemented using dynamic programming, thus obtaining


\begin{lstlisting}
from cmath import exp as cexp

def fast_fourier(u, sign=1):
    N, sqrtN, D = len(u), sqrt(len(u)), range(len(u))
    v = [ui/sqrtN for ui in u]
    k = N/2
    while k:
        omega = cexp(2.0 * pi * 1j * k/N)
        for i in D:
            j = i ^ k
            if i < k:
                ik, jk = int(i/k), int(j/k)
                v[i], v[j] = v[i]+(omega ** ik) * v[j], v[i]+(omega ** jk) * v[j]
        k/=2
    return v

def fast_anti_fourier(v):
    return fast_fourier(v, sign=-1)
\end{lstlisting}

This implementation of the Fourier transform is equivalent to the previous one in the sense that it produces the same result (up to numerical issues), but it is faster as it runs in $\Theta(N \log_2 N)$ versus $\Theta(N^2)$ of the naive implementation. Here \verb!i ^ j!
is a binary operator, specifically a XOR. For each binary digit of $i$, it returns a flipped bit if the corresponding bit in $j$ is 1. For example:

\begin{lstlisting}
i  : 10010010101110
j  : 00010001000010
i^j: 10000011001110
\end{lstlisting}

\section{Differential equations}

In this section, we deal specifically with differential equations of the following form:

\begin{equation}
a_0 f(x) + a_1 f'(x) + a_2 f''(x) + ... = g(x) \label{diffeq}
\end{equation}

where $f(x)$ is an unknown function to be determined; $f'$, $f''$, and so on, are its derivatives; $a_i$ are known input coefficients; and $g(x)$ is a known input function:

\begin{equation}
f''(x) - 4 f'(x) + f(x) = sin(x)
\end{equation}

In this case, $a_2(x) = 1$, $a_1(x) = -4$, $a_0(x) = 1$, and $g(x) = \sin(x)$.

This can be solved using Fourier transforms by observing that if the Fourier transform of $f(x)$ is $\tilde f(y)$, then the Fourier transform of $f'(x)$ is $iy\tilde f(y)$.

Hence, if we Fourier transform both the left and right side of

\begin{equation}
\sum _k a_k f^{(k)}(x) = g(x)
\end{equation}

we obtain

\begin{equation}
(\sum _k a_k (i y)^k) \tilde f(y) = \tilde g(y)
\end{equation}

therefore $f(x)$ is the anti-Fourier transform of

\begin{equation}
\tilde f(y) = \frac{\tilde g(y)}{(\sum _k a_k (i y)^k)}
\end{equation}

In one equation, the solution of eq.~\ref{diffeq} is

\begin{equation}
f(x) = T^-(T^+(g)/(\sum _k a_k (iy)^k))
\end{equation}

This is fine and useful when the Fourier transformations are easy to compute.

A more practical numerical solution is the following. We define

\begin{equation}
y_i(x) \equiv f^{(i)}(x)
\end{equation}

and we rewrite the differential equation as

\begin{eqnarray}
y"_0 &=& y_1 \\
y"_1 &=& y_2 \\
y"_2 &=& y_3 \\
... && ... \\
y"_{N-1} &=& y_N = (g(x)-\sum_{k<N} a_k y_k(x))/a_N(x)
\end{eqnarray}

or equivalently

\begin{equation}
\mathbf{y}" = F(\mathbf{y})
\end{equation}

where

\begin{equation}
F(\mathbf{y}) = \mathbf{y}+\left(\begin{tabular}{c}
$y_1$ \\
$y_2$ \\
$y_3$ \\
... \\
$(g(x)-\sum_{k<N} a_k(x)y_k(x))/a_N(x)$
\end{tabular}\right)
\end{equation}

\index{Euler method}
The naive solution is due to Euler:

\begin{equation}
\mathbf{y}(x+h) = \mathbf{y}(x) + hF(\mathbf{y}, x)\label{euler}
\end{equation}

The solution is found by iterating the latest equation. Here $h$ is an arbitrary discretization step. Euler"s method works even if the $a_k$ coefficients depend on $x$.

\index{Runge--Katta method}
 Although the Euler integrator works in theory, its systematic error adds up and does not disappear in the limit $h\rightarrow 0$. More accurate integrators are the Runge--Katta and the Adam--Bashforth. In the fourth-order Runge--Katta, the {\it classical Runge--Katta method}, we also solve the differential equation by iteration, except that eq.~\ref{euler} is replaced with

\begin{equation}
\mathbf{y}(x+h) = \mathbf{y}(x) + h/6 (\mathbf{k}_1+2\mathbf{k}_2+2\mathbf{k}_3+\mathbf{k}_4)\label{rungekatta}
\end{equation}
where
\begin{eqnarray}
\mathbf{k}_1 &=& F(\mathbf{y}, x) \\
\mathbf{k}_2 &=& F(\mathbf{y}+h k_1/2, x+h/2) \\
\mathbf{k}_3 &=& F(\mathbf{y}+h k_2/2, x+h/2) \\
\mathbf{k}_4 &=& F(\mathbf{y}+h k_3, x+h)
\end{eqnarray}

\chapter{Probability and Statistics}

\goodbreak\section{Probability}

\index{probability}\index{statistics}

Probability derives from the Latin {\it probare} (to prove or to test). The word
probably means roughly ``likely to occur'' in the case of possible future
occurrences or ``likely to be true'' in the case of inferences from
evidence. See also probability theory.

What mathematicians call probability is the mathematical theory we use to
describe and quantify uncertainty. In a larger context, the word {\it probability}
is used with other concerns in mind. Uncertainty can be due to our
ignorance, deliberate mixing or shuffling, or due to the essential
randomness of Nature. In any case, we measure the uncertainty of events on a
scale from zero (impossible events) to one (certain events or no
uncertainty).

There are three standard ways to define probability:

\begin{itemize}
\item  (frequentist) Given an experiment and a set of possible outcomes $S$, 
the probability of an event $A\subset S$ is computed by repeating the
experiment $N$ times, counting how many times the event $A$ is realized, $N_A
$, then taking the limit
\begin{equation}
\textrm{Prob}(A)\equiv \lim_{N\rightarrow \infty }\frac{N_A}N
\end{equation}
This definition actually requires that one performs an experiment, 
if not an infinite, then a number of times.

\item  (a priori) Given an experiment and a set of possible outcomes $S$
with cardinality $c(S)$, the probability of an event $A\subset S$ is defined
as
\begin{equation}
\textrm{Prob}(A)\equiv \frac{c(A)}{c(S)}
\end{equation}
This definition is ambiguous because it assumes that each ``atomic'' event $%
x\in S$ has the same a priori probability and therefore the definition
itself is circular. Nevertheless we use this definition in many practical
circumstances. What is the probability that when rolling a dice we will get an even
number? The space of possible outcomes is $S=\{1, 2, 3, 4, 5, 6\}$ and $A=\{2, 4, 6\}
$ therefore $\textrm{Prob}(A)=c(A)/c(S)=3/6=1/2$. This analysis works for an ideal die
and ignores the fact that a real dice may be biased. The former definition
takes into account this possibility, whereas the latter does not.

\item  (axiomatic definition) Given an experiment and a set of possible
outcomes $S$, the probability of an event $A\subset S$ is a number $\textrm{Prob}(A)\in
[0, 1]$ that satisfies the following conditions: $\textrm{Prob}(S)=1$; $\textrm{Prob}(A_1\cup
A_2)=\textrm{Prob}(A_1)+\textrm{Prob}(A_2)$ if $A_1\cap A_2=0$.
\end{itemize}

In some sense, probability theory is a physical theory because it applies to
the physical world (this is a nontrivial fact). While the axiomatic
definition provides the mathematical foundation, the a priori
definition provides a method to make predictions based on combinatorics.
Finally the {\em frequentist} definition provides an experimental
technique to confront our predictions with experiment (is our dice a perfect
dice, or is it biased?).

We will differentiate between an ``atomic'' event defined as an event that
can be realized by a single possible outcome of our experiment and a general
event defined as a subset of the space of all possible outcomes. In the case
of a dice, each possible number (from 1 to 6) is an event and is also an
atomic event. The event of getting an even number is an event but not an
atomic event because it can be realized in three possible ways.

The axiomatic definition makes it easy to prove theorems, for example, 

{\it If $S=A\cup A^c$ and $A\cap A^c=0$ then $\textrm{Prob}(A)=1-\textrm{Prob}(A^c)$}

Python has a module called {\ft random} that can generate random numbers, and we can use it to perform some experiments.
Let"s simulate a dice with six possible outcomes.
We can use the frequentist definition:

%%% META:FILE:test.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
>>> import random
>>> S = [1, 2, 3, 4, 5, 6]
>>> def Prob(A, S, N=1000):
...     return float(sum(random.choice(S) in A for i in range(N)))/N
>>> Prob([6], S)
0.166
>>> Prob([1, 2], S)
0.308
\end{lstlisting}
Here {\ft \textrm{Prob}(A)} computes the probability that the event is set {\ft A} using {\ft N=1000} simulated experiments.
The {\ft random.choice} function picks one of the choices at random with equal probability.

We can compute the same quantity using the a priori definition:

%%% META:FILE:test.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
>>> def Prob(A, S): return float(len(A))/len(S)
>>> Prob([6], S)
0.16666666666666666
>>> Prob([1, 2], S)
0.3333333333333333
\end{lstlisting}

As stated before, the latter is more precise because it produces results for an ``ideal'' dice while the frequentist"s approach produces results for a real dice (in our case, a simulated dice).

\goodbreak\subsection{Conditional probability and independence}

We define $\textrm{Prob}(A|B)$ as the probability of event $A$ given event $B$, and we
write
\begin{equation}
\textrm{Prob}(A|B)\equiv \frac{\textrm{Prob}(AB)}{\textrm{Prob}(B)}  \label{pab}
\end{equation}
where $\textrm{Prob}(AB)$ is the probability that $A$ and $B$ both occur and $\textrm{Prob}(B)$ is
the probability that $B$ occurs. Note that if $\textrm{Prob}(A|B)=\textrm{Prob}(A)$, then we say
that $A$ and $B$ are independent. From eq.(\ref{pab})
we conclude $\textrm{Prob}(AB)=\textrm{Prob}(A)\textrm{Prob}(B)$; therefore the probability that two
independent events occur is the product of the probability that each individual event
occurs.

We can experiment with conditional probability using Python. Let"s consider two dices, X and Y.
The space of all possible outcomes is given by $S^2 = S \times S$.
And we are interested in the probability of the second die giving a $6$ given that the first dice is also a $6$:

%%% META:FILE:test.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
>>> def cross(u, v): return [(i, j) for i in u for j in v]
>>> def Prob_conditional(A, B, S): return Prob(cross(A, B), cross(S, S))/Prob(B, S)
>>> Prob_conditional([6], [6], S)
0.16666666666666666
\end{lstlisting}

Because we are only considering cases in which the second die is 6, we will pretend that when the second die is 1 through 5 didn"t occur.
Not surprisingly, we find that {\ft Prob\_conditional([6], [6], S)} produces the same result as
{\ft Prob([6], S)} because the two dices are independent.

In fact, we say that two sets of events $A$ and $B$ are independent if and only if $\textrm{P}(A|B) = \textrm{P}(A)$.


\goodbreak\subsection{Discrete random variables}
\index{discrete random variable}\index{expectation value}

If $S$ is in the space of all possible outcomes of an experiment and we
associate an integer number $X$ to each element of $S$, we say that $X$ is a
{\it discrete random variable}. If $X$ is a discrete variable, we define $%
p(x)$, the {\it probability mass function} or {\it distribution}, as the
probability that $X=x$:
\begin{equation}
p(x) \equiv \textrm{Prob}(X=x)
\end{equation}

We also define the {\it expectation value} of any function of a discrete
random variable $f(X)$ as
\begin{equation}
E[f(X)] \equiv  \sum_i f(x_i)p(x_i)
\end{equation}
where $i$ loops all possible variables $x_i$ of the random variable $X$.

For example, if $X$ is the random variable associated with the outcome of rolling a dice, $p(x)=1/6$ if $x=1, 2, 3, 4, 5$ or $6$ and $p(x)=0$ otherwise:
\begin{equation}
E[X]=\sum_ix_ip(x_i)=\sum_{x_i\in \{1, 2, 3, 4, 5, 6\}}x_i\frac 16=3.5
\end{equation}

and
\begin{equation}
E[(X-3.5)^2]=\sum_i(x_i-3.5)^2p(x_i)=\sum_{x_i\in
\{1, 2, 3, 4, 5, 6\}}(x_i-3.5)^2\frac 16=2.9167
\end{equation}

We call $E[X]$ the {\it mean} of $X$ and usually denote it with $\mu _X$.
We call $E[(X-\mu _X)^2]$ the {\it variance} of $X$ and denote it with $\sigma _X^2$. Note that
\begin{equation}
\sigma _X=E[X^2]-E[X]^2
\end{equation}

For discrete random variables, we can implement these definitions as follows:
\index{mean}\index{variance}\index{standard deviation}

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
def E(f, S): return float(sum(f(x) for x in S))/(len(S) or 1)
def mean(X): return E(lambda x:x, X)
def variance(X): return E(lambda x:x ** 2, X) - E(lambda x:x, X) ** 2
def sd(X): return sqrt(variance(X))
\end{lstlisting}

As an example, let"s consider a simple bet on a dice. We roll the dice once and win \$20 if the dice returns 6; we lose \$5 otherwise:

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
>>> S = [1, 2, 3, 4, 5, 6]
>>> mean(S)
3.5
>>> sd(S)
1.707...
>>> def payoff(x): return 20.0 if x == 6 else -5.0
>>> E(payoff, S)
-0.83333...
\end{lstlisting}

The average expected payoff is $-0.83...$, which means that on average, we should expect to lose 83 cents at this game.

\goodbreak\subsection{Continuous random variables}
\index{continuous random variable}
\index{cumulative distribution function}
\index{probability density}
\index{probability}

If $S$ is the space of all possible outcomes of an experiment and we
associate a real number $X$ with each element of $S$, we say that $X$ is a {\it %
continuous random variable}. We also define a {\it cumulative distribution
function} $F(x)$ as the probability that $X\leq x$:
\begin{equation}
F(x)\equiv \textrm{Prob}(X\leq x)
\end{equation}

If $S$ is a continuous set and $X$ is a continuous random variable, then we
define a {\it probability density} or {\it distribution} $p(x)$ as
\begin{equation}
p(x)\equiv \frac{dF(x)}{dx}
\end{equation}
and the probability that $X$ falls into an interval $[a, b]$ can be computed
as
\begin{equation}
\textrm{Prob}(a\leq X\leq b)=\int_a^bp(x)dx
\end{equation}

\index{expectation value}

We also define the {\it expectation value} of any function of a random
variable $f(X)$ as
\begin{equation}
E[f(X)]=\int_{-\infty }^\infty f(x)p(x)dx
\end{equation}

For example, if $X$ is a uniform random variable (probability density $p(x)$ equal to $1$ if
$x\in [0, 1]$, equal to $0$ otherwise)
\begin{equation}
E[X]=\int_{-\infty }^\infty xp(x)dx=\int_0^1xdx=\frac 12
\end{equation}
and
\begin{equation}
E[(X-\frac 12)^2]=\int_{-\infty }^\infty (x-\frac
12)^2p(x)dx=\int_0^1(x^2-x+\frac 14)dx=\frac 1{12}
\end{equation}

We call $E[X]$ the {\bf mean} of $X$ and usually denote it with $\mu _X$.
We call $E[(X-\mu _X)^2]$ the {\bf variance} of $X$ and denote it with $%
\sigma _X^2$. Note that
\begin{equation}
\sigma _X^2=E[X^2]-E[X]^2
\end{equation}

By definition, 
\begin{equation}
F(\infty )\equiv \textrm{Prob}(X\leq \infty )=1
\end{equation}
therefore
\begin{equation}
\textrm{Prob}(-\infty \leq X\leq \infty )=\int_{-\infty }^\infty p(x)dx=1
\end{equation}
The distribution $p$ is always normalized to 1.

Moreover, 

\begin{eqnarray}
E[aX+b] &=&\int_{-\infty }^\infty (ax+b)p(x)dx \\
&=&a\int_{-\infty }^\infty xp(x)dx+b\int_{-\infty }^\infty p(x)dx \\
&=&aE[X]+b
\end{eqnarray}

therefore $E[X]$ is a linear operator.

One important consequence of all these formulas is that if we have a function $f$ and a domain $[a, b]$, we can compute its integral by choosing $p$ to be a uniform distribution with values exclusively between $a$ and $b$:

\begin{equation}
  E[f] = \int_{-\infty }^\infty f(x) p(x) dx = \frac1{b-a}\int_a^b f(x) dx
\end{equation}

We can also compute the same integral by using the definition of expectation value for a discrete distribution:

\begin{equation}
  E[f] = \sum_{x_i} f(x_i) p(x_i) = \frac1N \sum_{x_i} f(x_i)
\end{equation}

where $x_i$ are $N$ random points drawn from the uniform distribution $p$ defined earlier. In fact, in the large $N$ limit, 

\begin{equation}
  \lim_{N\rightarrow \infty}  \frac1N \sum_{x_i} f(x_i) = \int_{-\infty }^\infty f(x) p(x)dx = \frac1{b-a}\int_a^b f(x) dx
\end{equation}

We can verify the preceding relation numerically for a special case:

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
>>> from math import sin, pi
>>> def integrate_mc(f, a, b, N=1000):
...     return sum(f(random.uniform(a, b)) for i in range(N))/N * (b-a)
>>> integrate_mc(sin, 0, pi, N=10000)
2.00....
\end{lstlisting}

This is the simplest case of Monte Carlo integration, which is the subject of a following chapter.

\goodbreak\subsection{Covariance and correlations}

Given two random variables, $X$ and $Y$, we define the covariance (cov)  and the correlation (corr)
between
them as
\begin{eqnarray}
\textrm{cov}(X, Y) &\equiv  &E[(X-\mu _X)(Y-\mu _Y)]=E[XY]-E[X]E[Y] \\
\textrm{corr}(X, Y) &\equiv & \textrm{cov}(X, Y)/(\sigma_X \sigma_Y)
\end{eqnarray}

Applying the definitions:
\begin{eqnarray}
E[XY] &=&\int \int xyp(x, y)dxdy \\
&=&\int \int xyp(x)p(y)dxdy \\
&=&\left[ \int xp(x)dx\right] \left[ \int yp(y)dy\right] \\
&=&E[X]E[Y]
\end{eqnarray}
therefore
\begin{equation}
\textrm{cov}(X, Y) =E[XY]-E[X]E[Y]=0
\end{equation}

Therefore
\begin{equation}
\sigma _{X+Y}^2=\sigma _X^2+\sigma _Y^2+2 \textrm{cov}(X, Y)
\end{equation}
and if $X$ and $Y$ are independent, then $\textrm{cov}(X, Y)=\textrm{corr}(X, Y)=0$.

Notice that the reverse is not true. Even if the correlation and the covariance are zero, $X$ and $Y$ may be dependent.

Moreover, 
\begin{eqnarray}
\textrm{cov}(X, Y) &=&E[(X-\mu _X)(Y-\mu _Y)] \\
&=&E[(X-\mu _X)(\pm X\mp \mu _X)] \\
&=&\pm E[(X-\mu _X)(X-\mu _X)] \\
&=&\pm \sigma _X^2
\end{eqnarray}

Therefore, if $X$ and $Y$ are completely correlated or anti-correlated ($Y=\pm X$), then $\textrm{cov}(X, Y)=\pm \sigma _X^2$ and $\textrm{corr}(X, Y) = \pm 1$.
Notice that the correlation lies always in the range $[-1, 1]$.

Finally, notice that for uncorrelated random variables $X_i$, 
\begin{eqnarray}
E[\sum_ia_iX_i] &=&\sum_ia_iE[X_i] \\
E[(\sum_iX_i)^2] &=&\sum_iE[X_i^2]
\end{eqnarray}


We can define covariance and correlation for discrete distributions:
%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
def covariance(X, Y):
    return sum(X[i] * Y[i] for i in range(len(X)))/len(X) - mean(X) * mean(Y)
def correlation(X, Y):
    return covariance(X, Y)/sd(X)/sd(Y)
\end{lstlisting}

\goodbreak\subsection{Strong law of large numbers}

If $X_1, X_2, ...X_n$ are a sequence of independent and identically
distributed random variables with $E[X_i]=$ $\mu $ and finite variance, then
\begin{equation}
\lim_{n\rightarrow \infty }\frac{X_1+X_2+...+X_n}n=\mu
\end{equation}

This theorem means that ``the average of the results obtained from a large number of trials should be close to the expected value, and will tend to become closer as more trials are performed.'' The name of this law is due to Poisson~\cite{largenumbers}.

\goodbreak\subsection{Central limit theorem}

This is one of the most important theorems concerning distributions~\cite{central}:
if $X_1, X_2, ...X_n$ are a sequence of random variables with finite means, $\mu_i$, and finite variance, $\sigma^2_i$, then
\begin{equation}
Y = \lim_{N\rightarrow\infty}\frac1N \sum_{i=0}^{i<N} X_i
\end{equation}
follows a Gaussian distribution with mean and variance:
\begin{eqnarray}
\mu &=& \lim_{N\rightarrow\infty}\frac1N \sum_{i=0}^{i<N} \mu_i \\
\sigma^2 &=& \lim_{N\rightarrow\infty}\frac1N \sum_{i=0}^{i<N} \sigma^2_i
\end{eqnarray}

We can numerically verify this for the simple case in which $X_i$ are uniform random variables with mean equal to 0:

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
>>> def added_uniform(n): return sum([random.uniform(-1, 1) for i in range(n)])/n
>>> def make_set(n, m=10000): return [added_uniform(n) for j in range(m)]
>>> Canvas(title="Central Limit Theorem", xlab="y", ylab="p(y)"
...       ).hist(make_set(1), legend="N=1").save("images/central1.png")
>>> Canvas(title="Central Limit Theorem", xlab="y", ylab="p(y)"
...       ).hist(make_set(2), legend="N=2").save("images/central3.png")
>>> Canvas(title="Central Limit Theorem", xlab="y", ylab="p(y)"
...       ).hist(make_set(4), legend="N=4").save("images/central4.png")
>>> Canvas(title="Central Limit Theorem", xlab="y", ylab="p(y)"
...       ).hist(make_set(8), legend="N=8").save("images/central8.png")
\end{lstlisting}
\begin{figure}[ht]
\begin{center}
\begin{tabular}{cc}
\includegraphics[width=2in]{images/central1.png} &
\includegraphics[width=2in]{images/central2.png} \\
\includegraphics[width=2in]{images/central4.png} &
\includegraphics[width=2in]{images/central8.png}
\end{tabular}
\end{center}
\caption{Example of distributions for sums of 1, 2, 4, and 8 uniform random variables. The more random variables are added, the better the result approximates a Gaussian distribution.\label{central}}
\end{figure}

This theorem is of fundamental importance for stochastic calculus. Notice that the theorem does not apply when the $X_i$ follow distributions that do not have a finite mean or a finite variance.

\index{Levy distributions}

Distributions that do not follow the central limit are called {\it Levy distributions}.
They are characterized by fat tails for the form

\begin{equation}
p(x) \stackunder{x\rightarrow\infty}{\sim} \frac1{\left|x\right|^{1+\alpha}}, \qquad 0<\alpha<2
\end{equation}

An example if the Pareto distribution.

\goodbreak\subsection{Error in the mean}
\index{error in the mean}

One consequence of the Central Limit Theorem is a useful formula for evaluating the error in the mean.
Let"s consider the case of $N$ repeated experiments with outcomes $X_i$.
Let"s also assume that each $X_i$ is supposed to be equal to an unknown
value $\mu $, but in practice, $X_i=\mu +\varepsilon $, where $\varepsilon $ is
a random variable with Gaussian distribution centered at zero. One could
estimate $\mu $ by $\mu =E[X]=\frac 1N\Sigma _iX_i$.
In this case, statistical error in the mean is given by
\begin{equation}
\delta \mu =\sqrt{\frac{\sigma ^2}{N}}
\label{error}
\end{equation}
where $\sigma ^2=E[(X-\mu )^2]=\frac 1N\Sigma _i(X_i-\mu )^2$.



\goodbreak\section{Combinatorics and discrete random variables}
\index{combinatorics}

Often, to compute the probability of discrete random variables, one
has to confront the problem of calculating the number of possible finite
outcomes of an experiment. Often this problem is solved by combinatorics.

\goodbreak\subsection{Different plugs in different sockets}

If we have $n$ different plugs and $m$ different sockets; in how many ways
can we place the plugs in the sockets?

\begin{itemize}
\item  Case 1, $n\geq m$. All sockets will be filled. We consider the first
socket, and we can select any of the $n$ plugs ($n$ combinations). We
consider the second socket, and we can select any of the remaining $n-1$
plugs ($n-1$ combinations), and so on, until we are left with no free sockets
and $n-m$ unused plugs; therefore there are
\begin{equation}
n!/(n-m)!=n(n-1)(n-2)...(n-m+1)
\end{equation}
combinations.

\item  Case 2, $n\leq m$. All plugs have to be used. We consider the first
plug, and we can select any of the $m$ sockets ($m$ combinations). We
consider the second plug, and we can select any of the remaining $m-1$
sockets ($m-1$ combinations), and so on, until we are left with no spare
plugs and $m-n$ free sockets; therefore there are
\begin{equation}
m!/(m-n)!=m(m-1)(m-2)...(m-n+1)
\end{equation}
combinations. Note that if $m=n\, $ then case 1 and case 2 agree, as
expected.
\end{itemize}

\goodbreak\subsection{Equivalent plugs in different sockets}

If we have $n$ equivalent plugs and $m$ different sockets, in how many ways
can we place the plugs in the sockets?

\begin{itemize}
\item  Case 1, $n\geq m$. All sockets will be filled. We cannot distinguish
one combination from the other because all plugs are the same. There is only
one combination.

\item  Case 2, $n\leq m$. All plugs have to be used but not all sockets.
There are $m!/(m-n)!$ ways to fill the sockets with different plugs, and
there are $n!$ ways to arrange the plugs within the same filled sockets.
Therefore there are
\begin{equation}
\binom mn=\frac{m!}{(m-n)!n!}
\end{equation}
ways to place $n$ equivalent plugs into $m$ different sockets. Note that if $%
m=n$%
\begin{equation}
\binom nn=\frac{n!}{(n-n)!n!}=1
\end{equation}
in agreement with case 1.
\end{itemize}

Here is another example. A club has 20 members and has to elect a president, a vice president, 
a secretary, and a treasurer. In how many different ways can they select the
four officeholders? Think of each office as a socket and each person as a
plug; therefore the number combination is $20!/(20-4)!\simeq \allowbreak
1.\, 2\times 10^5$.

\goodbreak\subsection{Colored cards}

We have 52 cards, 26 black and 26 red. We shuffle the cards and pick three.

\begin{itemize}
\item  What is the probability that they are all red?
\begin{equation}
\textrm{Prob}(3red)=\frac{26}{52}\times \frac{25}{51}\times \frac{24}{50}=\frac{2}{17}
\end{equation}

\item  What is the probability that they are all black?
\begin{equation}
\textrm{Prob}(3black)=\textrm{Prob}(3red)=\frac{2}{17}
\end{equation}

\item  What is the probability that they are not all black or all red?
\begin{eqnarray}
\textrm{Prob}(mixture) &=&1-\textrm{Prob}(3red\cup 3black) \\
&=&1-\textrm{Prob}(3red)-\textrm{Prob}(3black) \\
&=&1-2\frac{2}{17} \\
&=&\frac{13}{17}
\end{eqnarray}
\end{itemize}

Here is an example of how we can simulate the deck of cards using Python to compute an answer to the last questions:

%%% META:FILE:tests.py
\begin{lstlisting}[caption={in file: {\ft tests.py}}]
>>> def make_deck(): return [color for i in range(26) for color in ("red", "black")]
>>> def make_shuffled_deck(): return random.shuffle(make_deck())
>>> def pick_three_cards(): return make_shuffled_deck()[:3]
>>> def simulate_cards(n=1000):
...     counter = 0
...     for k in range(n):
...         c = pick_three_cards()
...         if not (c[0] == c[1] and c[1] == c[2]): counter += 1
...     return float(counter)/n
>>> simulate_cards()
\end{lstlisting}

\goodbreak\subsection{Gambler"s fallacy}

The typical error in computing probabilities is mixing a priori probability
with information about past events.
This error is called the {\it gambler"s fallacy}~\cite{gambler}.
For example, we consider the preceding problem. We see the first two cards, and they are both red. What is the
probability that the third one is also red?

\begin{itemize}
\item  {\bf Wrong answer}: The probability that they are all red is $%
\textrm{Prob}(3red)=2/17$; therefore the probability that the third one is also $2/17$.

\item  {\bf Correct answer}: Because we know that the first two cards are red, the third card must belong to a set of (26 black cards + 24 red cards);
therefore the probability that it is red is
\begin{equation}
\textrm{Prob}(red)=\frac{24}{24+26}=\frac{12}{25}
\end{equation}
\end{itemize}




\chapter{Random Numbers and Distributions}

In the previous chapters, we have seen how using the Python {\ft random} module, we can generate uniform random numbers. This module can also
generate random numbers following other distributions.
The point of this chapter is to understand how random numbers are generated.

\goodbreak\section{Randomness, determinism, chaos and order}
\index{randomness}\index{determinism}\index{chaos}\index{order}

Before we proceed further, there are four important concepts that should be defined because of their implications:

\begin{itemize}
\item  {\bf Randomness} is the characteristic of a process whose outcome is
unpredictable (e.g., at the moment I am writing this sentence, I cannot
predict the exact time and date when you will be reading it).

\item  {\bf Determinism} is the characteristic of a process whose outcome
can be predicted from the initial conditions of the system (e.g., if I throw a
ball from a known position, at a known velocity and in a known direction, I
can predict---calculate---its entire future trajectory).

\item  {\bf Chaos} is the emergence of randomness from order~\cite{lorenz}
(e.g., if I am on the
top of a hill and I throw the ball in a vertical direction, I cannot predict on
which side of the hill it is going to end up). Even if the equations that
describe a phenomenon are known and are deterministic, it may happen that a
small variation in the initial conditions causes a large difference in the
possible deterministic evolution of the system. Therefore the outcome of a
process may depend on a tiny variation of the initial parameters. These
variations may not be measurable in practice, thus making the process
unpredictable and chaotic. Chaos is generally regarded as a characteristic
of some differential equations.

\item  {\bf Order} is the opposite of chaos. It is the emergence of regular
and reproducible patterns from a process that, in itself, may be random or
chaotic (e.g., if I keep throwing my ball in a vertical direction from
the top of a hill and I record the final location of the ball, I eventually
find a regular pattern, a probability distribution associated with my
experiment, which depends on the direction of the wind, the shape of the
hill, my bias in throwing the ball, etc.).
\end{itemize}

These four concepts are closely related, and they do not necessarily come in
opposite pairs as one would expect.

A deterministic process may cause chaos. We can use chaos to generate
randomness (we will see examples when covering random number generation). We
can study randomness and extract its ordered properties (probability
distributions), and we can use randomness to solve deterministic problems
(Monte Carlo) such as computing integrals and simulating a system.

\goodbreak\section{Real randomness}
\index{radioactive decay}

Note that randomness does not necessarily come from chaos.
Randomness exists in nature~\cite{determinism}\cite{decay}.
For example, a radioactive atom ``decays'' into a different atom
at some random point in time. For example, an atom of carbon 14 decays into nitrogen 14 by emitting an electron and a neutrino
\begin{equation}
_6^{14}C\longrightarrow _7^{14}N+e^{-}+\overline{\nu }_e
\end{equation}
at some random time $t$; $t$ is unpredictable. It can be proven that the
randomness in the nuclear decay time is not due to any underlying
deterministic process. In fact, constituents of matter are
described by quantum physics, and randomness is a fundamental characteristic
of quantum systems. Randomness is not a consequence of our ignorance.

This is not usually the case for macroscopic systems. Typically the
randomness we observe in some macroscopic systems is not always a
consequence of microscopic randomness. Rather, order and determinism
emerge from the microscopic randomness, while chaos originates from the complexity of
the system.

Because randomness exists in nature, we can use it to produce random numbers
with any desired distribution. In particular, we want to use the randomness
in the decay time of radioactive atoms to produce random numbers with
uniform distribution. We assemble a system consisting of many
atoms, and we record the time when we observe atoms decay:

\begin{equation}
t_0, t_1, t_2, t_3, t_4, t_5, ...
\end{equation}

One could study the probability distribution of the $t_i$ and find
that it follows an exponential probability distribution like

\begin{equation}
\textrm{Prob}(t_i = t)=\lambda e^{-\lambda t}
\end{equation}

where $t_0=1/\lambda $ is the decay time characteristic of the particular
type of atom. One characteristic of this distribution is that it is a memoryless process: $t_i$ does not depend on $t_{i-1}$ and therefore the probability that $t_i>t_{i-1}$ is the same as the probability that $t_i<t_{i-1}$.

\goodbreak\subsection{Memoryless to Bernoulli distribution}

\index{distribution!memoryless}
\index{distribution!Bernoulli}

Given the sequence $\{t_i\}$ with exponential distribution, we can build a
random sequence of zeros and ones (Bernoulli distribution) by applying the following formula, known as the Von Neumann procedure~\cite{bits}:
\begin{equation}
x_i=\left\{
\begin{array}{ll}
1 & \text{if }t_{i}>t_{i-1} \\
0 & \text{otherwise}
\end{array}
\right.
\end{equation}

Note that the procedure can be applied to map any random sequence into
a Bernoulli sequence even if the numbers in the original sequence do not
follow an exponential distribution, as long as $t_i$ is independent of $t_j$
for any $j<i$ (memoryless distribution).

\goodbreak\subsection{Bernoulli to uniform distribution}

\index{distribution!uniform}

To map a Bernoulli distribution into a uniform distribution, we need
to determine the precision (resolution in number of bits) of the numbers we wish
to generate. In this example, we will assume 8 bits.

We can think of each number as a point in a [0, 1) segment. We generate the
uniform number by making a number of choices: we break the segment in two
and, according to the value of the binary digit (0 or 1), we select the first
part or the second part and repeat the process on the subsegment. Because
at each stage we break the segment into two parts of equal length and we
select one or the other with the same probability, the final distribution of
the selected point is uniform. As an example, we consider the Bernoulli
sequence
\begin{equation}
01011110110101010111011010
\end{equation}
and we perform the following steps:

\begin{itemize}
\item  break the sequence into chunks of 8 bits
\begin{equation}
\text{01011110-11010101-01110110-.....}
\end{equation}

\item  map each chunk $a_0a_1a_2a_3a_4a_5a_6a_7$ into $x=\sum_{k=0}^{k<8}a_k/2^{k+1}$
thus obtaining:

\begin{equation}
0.3671875 - 0.83203125 - 0.4609375 - ...
\end{equation}
\end{itemize}

A uniform random number generator is usually the first step toward building
any other random number generator.

\index{entropy source}

Other physical processes can be used to generate real random numbers using a similar process.
Some microprocessors can generate random numbers from random temperature fluctuations.
An unpredictable source of randomness is called an {\it entropy source}.

\goodbreak\section{Entropy generators}

The Linux/Unix operating system provides its own entropy source accessible via ``/dev/urandom.'' This data source is available in Python via {\ft os.urandom()}.

Here we define a class that can access this entropy source and use it to generate uniform random numbers. It follows the same process outlined for the radioactive days:

\index{class!URANDOM}

%%% META:FILE:test.py
\begin{lstlisting}
class URANDOM(object):
    def __init__(self, data=None):
        if data: open("/dev/urandom", "wb").write(str(data))
    def random(self):
        n = 16
        random_bytes =  os.urandom(n)
        random_integer = sum(ord(random_bytes[k]) * 256 ** k for k in range(n))
        random_float = float(random_integer)/256 ** n
\end{lstlisting}

Notice how the constructor allows us to further randomize the data by contributing input to the entropy source. Also notice how the {\ft random()} method reads 16 bites from the stream (using {\ft os.urandom()}), converts each into $8$-bit integers, combines them into a $128$-bit integer, and then converts it to a float by dividing by $256^{16}$.

\goodbreak\section{Pseudo-randomness}

In many cases we do not have a physical device to generate random numbers, 
and we require a software solution. Software is deterministic, the outcome
is reproducible, therefore it cannot be used to generate randomness, but it
can generate pseudo-randomness. The outputs of pseudo random number
generators are not random, yet they may be considered random for practical purposes.
John von Neumann observed in 1951 that ``anyone who
considers arithmetical methods of producing random digits is, of course, in
a state of sin.'' (For attempts to generate ``truly random'' numbers, see
the article on hardware random number generators.) Nevertheless, 
pseudo random numbers are a critical part of modern computing, from
cryptography to the Monte Carlo method for simulating physical systems.

Pseudo random numbers are relatively easy to generate with software, and they
provide a practical alternative to random numbers. For some applications, 
this is adequate.



\goodbreak\subsection{Linear congruential generator}

Here is probably the simplest possible pseudo random number generator:

\begin{eqnarray}
x_i &=&(a x_{i-1} + c) \textrm{mod}m \\
y_i &=&x_i/m
\end{eqnarray}
With the choice $a=65539$, $c=0$, and $m=2^{31}$, this generator is called RANDU. It is of historical importance
because it is implemented in the C {\ft rand()} function.
The RANDU generator is particularly fast because the modulus can
be implemented using the finite 32-bit precision.

Here is a possible implementation for $c=0$:
%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
class MCG(object):
    def __init__(self, seed, a=66539, m=2 ** 31):
        self.x = seed
        self.a, self.m = a, m
    def next(self):
        self.x = (self.a * self.x) % self.m
        return self.x
    def random(self):
        return float(self.next())/self.m
\end{lstlisting}

which we can test with
\begin{lstlisting}
>>> randu = MCG(seed=1071914055)
>>> for i in range(10): print(randu.random())
...
\end{lstlisting}

The output numbers ``look'' random but are not truly random. Running the same code with the same seed generates the same output. Notice the following:

\begin{itemize}
\item  PRNGs are typically implemented as a recursive expression that, given $%
x_{i-1}$, produces $x_i$.

\index{seed}


\item  PRNGs have to start from an initial value, $x_0$, called the {\it seed}.
A typical choice is to set the seed equal to the number of seconds from the
conventional date and time ``Thu Jan 01 01:00:00 1970.'' This is not always
a good choice.

\item PRNGs are periodic. They generate numbers in a finite set and then they repeat themselves. It is desirable to have this set as large as possible.

\item  PRNGs depend on some parameters (e.g., $a$ and $m$). Some
parameter choices lead to trivial random number generators. In
general, some choices are better than others, and a few are optimal. In
particular, the values of $a$ and $m$ determine the period of the random
number generator. An optimal choice is the one with the longest period.
\end{itemize}

For a linear congruential generator, because of the {\ft mod} operation, the period is always less than or equal to $m$. When $c$ is nonzero, the period is equal to $m$ only if $c$ and $m$ are relatively prime, $a-1$ is divisible by all prime factors of $m$, and $a-1$ is a multiple of 4 when $m$ is a multiple of $4$.

In the case of RANDU, the period is $m/4$. A better choice is using $a=7^5$ and $m=2^{31}-1$ (known as the Marsenne prime number) because it can be proven that $m$ is in fact the period of the generator:
\begin{equation}
x_i=(7^5x_{i-1})\textrm{mod}(2^{31}-1)  \label{Marsenne}
\end{equation}

Here are some examples of MCG used by various systems:

\begin{tabular}{|lrrr|} \hline
Source & $m$ & $a$ & $c$ \\ \hline
Numerical Recipes & $2^{32}$ & 1664525 & 1013904223 \\
glibc (used by GCC) & $2^{32}$ & 1103515245 & 12345 \\
Apple CarbonLib & $2^{31} - 1$ & 16807 & 0 \\
java.util.Random & $2^{48}$ & 25214903917 & 11 \\ \hline
\end{tabular}

When $c$ is set to zero, a linear congruential generator is also called a multiplicative congruential generator.

\goodbreak\subsection{Defects of PRNGs}

The non-randomness of pseudo random number generators manifests itself in at
least two different ways:

\begin{itemize}
\item  The sequence of generated numbers is periodic, therefore only a finite
set of numbers can come out of the generator, and many of the numbers will never be
generated. This is not a major problem if the period is much larger (some
order of magnitude) than the number of random numbers needed in the Monte
Carlo computation.

\item  The sequence of generated numbers presents bias in the form of
``patterns.'' Sometimes
these patterns are evident, sometimes they are not evident. Patterns exist
because the pseudo random numbers are not random but are generated using a
recursive formula. The existence of these patterns may introduce a bias in
Monte Carlo computations that use the generator. This is a nasty problem, and
the implications depend on the specific case.
\end{itemize}

An example of pattern/bias is discussed in ref.~\cite{randu} and can be seen in fig.~\ref{randu}.

\begin{figure}[ht]
  \centering\includegraphics[width=2.5in]{images/randu.png}
\caption{In this plot, each three consecutive random numbers (from RANDU) are interpreted as $(x, y, z)$ coordinates of a random point. The image clearly shows the points are not distributed at random. Image from ref.~\cite{randu}.\label{randu}}
\end{figure}

\goodbreak\subsection{Multiplicative recursive generator}

Another modification of the multiplicative congruential generator is the following:

\begin{equation}
x_i=(a_1x_{i-1}+a_2x_{i-2}+...+a_kx_{i-k})\textrm{mod}m
\end{equation}

The advantage of this generator is that if $m$ is prime, the period of this
type of generator can be as big as $m^k-1$. This is much larger than a
simple multiplicative congruential generator.

An example is $a_1=107374182, $ $a_2=a_3=a_4=0, $ $a_5=104480$, and $m=2^{31}-1$, 
where the period is
\begin{equation}
(2^{31}-1)^5-1\simeq 4.56\times 10^{46}
\end{equation}

\goodbreak\subsection{Lagged Fibonacci generator}

\begin{equation}
x_i=(x_{i-j}+x_{i-k})\textrm{mod}m
\end{equation}

This is similar to the multiplicative recursive generator earlier. If $m$ is
prime and $j\neq k$, the period can be as large as $m^k-1$.

\goodbreak\subsection{Marsaglia"s add-with-carry generator}

\begin{equation}
x_i=(x_{i-j}+x_{i-k}+c_i)\textrm{mod}m
\end{equation}

where $c_1=0$ and $c_i=1$ if $(x_{i-1-j}+x_{i-1-k}+c_{i-1})<m$, $0$

\goodbreak\subsection{Marsaglia"s subtract-and-borrow generator}

\begin{equation}
x_i=(x_{i-j}-x_{i-k}-c_i)\textrm{mod}m
\end{equation}

where $k>j>0$, $c_1=0$, and $c_i=1$ if $(x_{i-1-j}-x_{i-1-k}-c_{i-1})<0$, $0$
otherwise.

\goodbreak\subsection{L\"uscher"s generator}

The Marsaglia"s subtract-and-borrow is a very popular generator, but it is known
to have some problems. For example, if we construct vector
\begin{equation}
v_i=(x_i, x_{i+1}, ..., x_{i+k})
\end{equation}
and the coordinates of the point $v_i$ are numbers closer to each other then
the coordinates of the point $v_{i+k}$ are also close to each other. This
indicates that there is an unwanted correlation between the points $%
x_i, x_{i+1}, ..., x_{i+k}$. L\"uscher observed~\cite{lusher} that the Marsaglia"s
subtract-and-borrow is equivalent to a chaotic discrete dynamic system, and
the preceding correlation dies off for points that distance themselves more than $k$. Therefore
he proposed to modify the generator as follows: instead of taking all $x_i$
numbers, read $k$ successive elements of the sequence, discard $p-k$
numbers, read $k$ numbers, and so on. The number $p$ has to be chosen to be
larger than $k$. When $p=k$, the original Marsaglia generator is recovered.

\goodbreak\subsection{Knuth"s polynomial congruential generator}

\begin{equation}
x_i=(ax_{i-1}^2+bx_{i-1}+c)\textrm{mod}m
\end{equation}

This generator takes the form of a more complex function. It makes it harder to guess one number in the sequence from the following numbers; therefore
it finds applications in cryptography.

Another example is the Blum, Blum, and Shub generator:
\begin{equation}
x_i=x_{i-1}^2\textrm{mod}m
\end{equation}

\goodbreak\subsection{PRNGs in cryptography}

Random numbers find many applications in cryptography. For example, consider
the problem of generating a random password, a digital signature, or random
encryption keys for the Diffie--Hellmann and the RSA encryption schemes.

A cryptographically secure pseudo random number generator (CSPRNG) is a
pseudo random number generator (PRNG) with properties that make it suitable
for use in cryptography.

In addition to the normal requirements for a PRNG (that its output
should pass all statistical tests for randomness) a CSPRNG must have two
additional properties:

\begin{itemize}
\item  It should be difficult to predict the output of the CSPRNG, wholly or
partially, from examining previous outputs.

\item  It should be difficult to extract all or part of the internal state
of the CSPRNG from examining its output.
\end{itemize}

Most PRNGs are not suitable for use as CSPRNGs. They must appear random
in statistical tests, but they are not designed to resist determined
mathematical reverse engineering.

CSPRNGs are designed explicitly to resist reverse engineering. There are a
number of examples of CSPRNGs. Blum, Blum, and Shub has the strongest security
proofs, though it is slow.

Many pseudo random number generators have the form
\begin{equation}
x_i=f(x_{i-1}, x_{i-2}, ..., x_{i-k})
\end{equation}
For example, the next random number depends on the past $k$ numbers. Requirements for CSPRNGs used in cryptography are that

\begin{itemize}
\item  Given $x_{i-1}, x_{i-2}, ..., x_{i-k}$, $x_i$ can be computed in
polynomial time, while

\item  Given $x_i, x_{i-2}, ..., x_{i-k}$, $x_{i-1}$ must not be computable in
polynomial time.
\end{itemize}

The first requirement means that the PRNG must be fast. The second
requirement means that if a malicious agent discovers a random number used
as a key, he or she cannot easily compute all previous keys generated using the
same PRNG.

\goodbreak\subsection{Inverse congruential generator}

\begin{equation}
x_i=(ax_{i-1}^{-1}+c)\textrm{mod}m
\end{equation}

where $x_{i-1}^{-1}$ is the multiplicative inverse of $x_{i-1}$ modulo $m$, 
for example, $x_{i-1}x_{i-1}^{-1}=1\textrm{mod}m$.


\goodbreak\subsection{Marsenne twister}

One of the best PRNG algorithms (because of its long period, uniform distribution, and speed) is the Marsenne twister, which produces a 53-bit random number, 
and it has a period of $2^{19937}-1$ (this number is 6002 digits long!).
The Python {\ft random} module uses the Marsenne twister.
Although discussing the inner working of this algorithm is beyond the scope of these notes, we provide a
pure Python implementation of the Marsenne twister:

\index{class!MarsenneTwister}

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
class MarsenneTwister(object):
    """
    based on:
    Knuth 1981, The Art of Computer Programming
    Vol. 2 (2nd Ed.), pp102]
    """
    def __init__(self, seed=4357):
        self.w = []    # the array for the state vector
        self.w.append(seed & 0xffffffff)
        for i in range(1, 625):
            self.w.append((69069 * self.w[i-1]) & 0xffffffff)
        self.wi = i
    def random(self):
        w = self.w
        wi = self.wi
        N, M, U, L = 624, 397, 0x80000000, 0x7fffffff
        K = [0x0, 0x9908b0df]
        y = 0
        if wi >= N:
            for kk in range((N-M) + 1):
                y = (w[kk]&U)|(w[kk+1]&L)
                w[kk] = w[kk+M] ^ (y >> 1) ^ K[y & 0x1]

            for kk in range(kk, N):
                y = (w[kk]&U)|(w[kk+1]&L)
                w[kk] = w[kk+(M-N)] ^ (y >> 1) ^ K[y & 0x1]
            y = (w[N-1]&U)|(w[0]&L)
            w[N-1] = w[M-1] ^ (y >> 1) ^ K[y & 0x1]
        wi = 0
        y = w[wi]
        wi += 1
        y ^= (y >> 11)
        y ^= (y << 7) & 0x9d2c5680
        y ^= (y << 15) & 0xefc60000
        y ^= (y >> 18)
        return (float(y)/0xffffffff )
\end{lstlisting}

In the above code, numbers starting with \verb!0x! are represented in hexadecimal notation. The symbols \verb!&!, \verb!^!, \verb!<<!, and \verb!>>! are bitwise operators. \verb!&! is a binary AND,  \verb!^! is a binary exclusive XOR,  \verb!<<! shifts all bits to the left and  \verb!>>! shifts all bits to the right. We refer to the Python official documentation for details.

\goodbreak\section{Parallel generators and independent sequences}

It is often necessary to generate many independent sequences.

For example, you may want to generate streams or random numbers in parallel using multiple machines and processes, and you need to ensure that the streams do not overlap.

A common mistake is to generate the sequences using the same
generator with different seeds. This is not a safe procedure because it is
not obvious if the seed used to generate one sequence belongs to the
sequence generated by the other seed. The two
sequences of random numbers are not independent, but they are merely
shifted in respect to each other.

For example, here are two RANDU sequences generated with different but dependent
seeds:
\begin{equation}
\begin{tabular}{lll}
seed & 1071931562 & 50554362 \\
$y_0$ & 0.252659081481 & 0.867315522395 \\
$y_1$ & 0.0235412092879 & 0.992022250779 \\
$y_2$ & 0.867315522395 & 0.146293803118 \\
$y_3$ & 0.992022250779 & 0.949562561698 \\
$y_4$ & 0.146293803118 & 0.380731142126 \\
$y_5$ & ... & ...
\end{tabular}
\end{equation}

Note that the second sequence is the same as the first but shifted by two
lines.

Three standard techniques for generating independent sequences are
non-overlapping blocks, leapfrogging, and Lehmer trees.

\goodbreak\subsection{Non-overlapping blocks}

Let"s consider one sequence of pseudo random numbers:
\begin{equation}
x_0, x_1, ..., x_k, x_{k+1}, ..., x_{2k}, x_{2k+1}, ..., x_{3k}, x_{3k+1}, ..., 
\end{equation}
One can break it into subsequences of $k$ numbers:
\begin{eqnarray}
&&x_0, x_1, ..., x_{k-1} \\
&&x_k, x_{k+1}, ..., x_{2k-1} \\
&&x_{2k}, x_{2k+1}, ..., x_{3k-1} \\
&&...
\end{eqnarray}
If the original sequence is created with a multiplicative congruential
generator
\begin{equation}
x_i=ax_{i-1}\textrm{mod}m
\end{equation}
the subsequences can be generated independently because
\begin{equation}
x_{nk-1}=a^{nk-1}x_0\textrm{mod}m
\end{equation}
if the seed of the arbitrary sequence is $x_{nk}, x_{nk+1}, ..., x_{nk-1}$. This
is particularly convenient for parallel computers where one computer
generates the seeds for the subsequences and the processing nodes, 
independently, generated the subsequences.

\goodbreak\subsection{Leapfrogging}

Another and probably more popular technique is leapfrogging.
Let"s consider one sequence of pseudo random numbers:
\begin{equation}
x_0, x_1, ..., x_k, x_{k+1}, ..., x_{2k}, x_{2k+1}, ..., x_{3k}, x_{3k+1}, ..., 
\end{equation}
One can break it into subsequences of $k$ numbers:
\begin{eqnarray}
&&x_0, x_k, x_{2k}, x_{3k}, ... \\
&&x_1, x_{1+k}, x_{1+2k}, x_{1+3k}, ... \\
&&x_2, x_{2+k}, x_{2+2k}, x_{2+3k}, ... \\
&&...
\end{eqnarray}

The seeds $x_1, x_2, ..x_{k-1}$ are generated from $x_0$, and the independent
sequences can be generated independently using the formula
\begin{equation}
x_{i+k}=a^kx_i\textrm{mod}m
\end{equation}
Therefore leapfrogging is a viable technique for parallel random number
generators.

Here is an example of a usage of {\ft leapfrog}:

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
def leapfrog(mcg, k):
    a = mcg.a ** k % mcg.m
    return [MCG(mcg.next(), a, mcg.m) for i in range(k)]
\end{lstlisting}

Here is an example of usage:
\begin{lstlisting}
>>> generators=leapfrog(MCG(m), 3)
>>> for k in range(3):
...     for i in range(5):
...        x=generators[k].random()
...        print(k, "\t", i, "\t", x)
\end{lstlisting}

The Marsenne twister algorithm implemented in {\ft os.random} has leapfrogging built in. In fact, the module includes a {\ft random.jumpahead(n)} method that allows us to efficiently skip $n$ numbers.

\goodbreak\subsection{Lehmer trees}

Lehmer trees are binary trees, generated recursively, where each node
contains a random number. We start from the root containing the seed, $x_0$, and
we append two children containing, respectively, 
\begin{eqnarray}
x_i^L &=&(a_Lx_{i-1}+c_L)\textrm{mod}m \\
x_i^R &=&(a_Rx_{i-1}+c_R)\textrm{mod}m
\end{eqnarray}
then, recursively, append nodes to the children.

\goodbreak\section{Generating random numbers from a given distribution}

\index{accept-reject}\index{inversion method}

In this section and the next, we provide examples of distributions other than uniform and algorithms to generate numbers using these distributions. The general strategy consists of finding ways to map uniform random numbers into numbers following a different distribution. There are two general techniques for mapping uniform into nonuniform random numbers:

\begin{itemize}
\item accept--reject (applies to both discrete and continuous distributions)
\item inversion methods (applies to continuous distributions only)
\end{itemize}

Consider the problem of generating a random number $x$ from a given distribution $p(x)$. The {\it accept--reject method} consists of generating $x$ using a different distribution, $g(x)$, and a uniform random number, $u$, between 0, 1. If $u<p(x)/Mg(x)$ ($M$ is the max of $p(x)/g(x)$), then $x$ is the desired random number following distribution $p(x)$. If not, try another number.

To visualize why this works, imagine graphing the distribution $p$ of the random variable $x$ onto a large rectangular board and throwing darts at it, the coordinates of the dart being $(x, u)$. Assume that the darts are uniformly distributed around the board. Now take off (reject) all of the darts that are outside the curve. The remaining darts will be distributed uniformly within the curve, and the $x$-positions of these darts will be distributed according to the random variable"s density. This is because there is the most room for the darts to land where the curve is highest and thus the probability density is greatest.

The $g$ distribution is nothing but a shape so that all darts we throw are below it. There are two particular cases. In one case, $g=p$, we only throw darts below the $p$ that we want; therefore we accept them all. This is the most efficient case, but it is not of practical interest because it means the accept--reject is not doing anything, as we already know now to generate numbers according to $p$. The other case is $g(x) = constant$. This means we generate the $x$ uniformly before the accept--reject. This is equivalent to throwing the darts everywhere on the square board, without even trying to be below the curve $p$.

The inversion method instead is more efficient but requires some math. It states that if $F(x)$ is a cumulative distribution function and $u$ is a uniform random number between 0 and 1, then $x = F^{-1}(u)$ is a random number with distribution $p(x)=f'(x)$. For those distributions where $F$ can be expressed in analytical terms and inverted, the inversion method is the best way to generate random numbers. An example is the exponential distribution.

We will create a new class {\ft RandomSource} that includes methods to generate the random number.

\goodbreak\subsection{Uniform distribution}

The uniform distributions are simple probability distributions which, in the
discrete case, can be characterized by saying that all possible values are
equally probable. In the continuous case, one says that all intervals of the
same length are equally probable.

There are two types of uniform distribution: discrete and continuous.

Here we consider the discrete case as we implement it into a {\ft randint} method:

\index{class!RandomSource}

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
class RandomSource(object):
    def __init__(self, generator=None):
        self.generator = generator or random 
    def random(self):
        return self.generator.random()
    def randint(self, a, b):
        return int(a+(b-a+1) * self.random())
\end{lstlisting}

Notice that the random {\ft RandomSource} constructor expects a generator such as {\ft MCG}, {\ft MarsenneTwister}, or simply {\ft random} (default value). The {\ft random()} method is a proxy method for the equivalent method of the underlying generator object.

We can use {\ft randint} to generate a random choice from a finite set when each option has the same probability:

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
    def choice(self, S):
        return S[self.randint(0, len(S)-1)]
\end{lstlisting}

\goodbreak\subsection{Bernoulli distribution}

The Bernoulli distribution, named after Swiss scientist James Bernoulli, is
a discrete probability distribution that takes value 1 with
probability of success $p$ and value 0 with probability of failure $q=1-p$:

\begin{equation}
p(k) \equiv \left\{
\begin{array}{ll}
p & \text{if }k=1 \\
1-p & \text{if }k=0 \\
0 & \text{if not }k \in \{0, 1\}
\end{array}
\right\}
\end{equation}
A Bernoulli random variable has an expected value of $p$ and variance of $pq$.

We implement it by adding a corresponding method to the {\ft RandomSource} class:

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
    def bernoulli(self, p):
        return 1 if self.random()<p else 0
\end{lstlisting}

\goodbreak\subsection{Biased dice and table lookup}

A generalization of the Bernoulli distribution is a distribution in which we have a finite set of choices, each with an associated probability. The table can be a list of tuples {\ft (value, probability)} or a dictionary of {\ft value:probability}:

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
    def lookup(self, table, epsilon=1e-6):
        if isinstance(table, dict): table = table.items()
        u = self.random()
        for key, p in table:
            if u<p+epsilon:
                return key
            u = u - p
        raise ArithmeticError("invalid probability")
\end{lstlisting}

Let"s say we want a random number generator that can only produce the
outcome 0, 1 or 2 with known probabilities:
\begin{eqnarray}
\textrm{Prob}(X &=&0)=0.50 \\
\textrm{Prob}(X &=&1)=0.23 \\
\textrm{Prob}(X &=&2)=0.27
\end{eqnarray}
Because the probability of the possible outcomes are rational numbers
(fractions), we can proceed as follows:
\begin{lstlisting}
>>> def test_lookup(nevents=100, table=[(0, 0.50), (1, 0.23), (2, 0.27)]):
...     g = RandomSource()
...     f=[0, 0, 0]
...     for k in range(nevents):
...         p=g.lookup(table)
...         print(p, end='')
...         f[p]=f[p]+1
...     print
...     for i in range(len(table)):
...         f[i]=float(f[i])/nevents
...         printprint("frequency[%i]=%f" % (i, f[i]))
\end{lstlisting}

which produces the following output:

\begin{lstlisting}
0 1 2 0 0 0 2 2 2 2 2 0 0 0 2 1 1 2 0 0 2 1 2 0 1
0 0 0 0 0 0 0 0 0 0 1 2 2 0 0 1 2 2 0 0 1 0 0 1 0
0 0 0 0 0 2 2 0 2 0 2 0 0 0 0 2 1 2 0 2 0 2 0 0 0
0 0 0 2 2 0 0 0 0 2 1 1 0 2 0 0 0 0 0 1 0 1 0 0 0
frequency[0]=0.600000
frequency[1]=0.140000
frequency[2]=0.260000
\end{lstlisting}

Eventually, by repeating the experiment many more times, the frequencies of
0, 1 and 2 will approach the input probabilities.

Given the output frequencies, what is the probability that they are compatible with the input frequency?
The answer to this question is given by the $\chi^2$ and its distribution. We discuss this later in the chapter.

In some sense, we can think of the table lookup as an application of the
linear search. We start with a segment of length 1, and we break it into smaller
contiguous intervals of length $\textrm{Prob}(X=0), \textrm{Prob}(X=1), ..., \textrm{Prob}(x=n-1)$ so that $\sum
\textrm{Prob}(X=i)=1.$ We then generate a random point on the initial segment, and we ask
in which of the $n$ intervals it falls. The table lookup method linearly
searches the interval.

This technique is $\Theta (n)$, where $n$ is the number of outcomes of the
computation. Therefore it becomes impractical if the number of cases is
large. In this case, we adopt one of the two possible techniques: the
Fishman--Yarberry method or the accept--reject method.

\goodbreak\subsection{Fishman--Yarberry method}

The Fishman--Yarberry~\cite{fishman}  (F-Y) method is an improvement over the naive table
lookup that runs in $O(\left\lceil \log _2n\right\rceil )$. As the naive
table lookup is an application of the linear search, the F-Y is an
application of the binary search.

Let"s assume that $n=2^t$ is an exact power of $2$. If this is not the case, 
we can always reduce to this case by adding new values to the lookup table
corresponding to $0$ probability. The basic data structure behind the F-Y
method is an array of arrays $a_{ij}$ built according to the following rules:

\begin{itemize}
\item  $\forall j\geq 0, a_{0j}=\textrm{Prob}(X=x_j)$

\item  $\forall j\geq 0$ and $i>0$, $a_{ij}=a_{i-1, 2j}+a_{i-1, 2j+1}$
\end{itemize}

Note that $0\leq i<t$ and $\forall i\geq 0$, $0\leq j<2^{t-i}$, where $t=\log
_2n$. The array of arrays $a$ can be represented as follows:

\begin{equation}
a_{ij}=\left(
\begin{array}{lllll}
a_{00} & a_{01} & a_{02} & ... & a_{0, n-1} \\
... & ... & ... & ... &  \\
a_{t-2, 0} & a_{t-2, 1} & a_{t-2, 2} & a_{t-2, 3} &  \\
a_{t-1, 0} & a_{t-1, 1} &  &  &
\end{array}
\right)
\end{equation}
In other words, we can say that

\begin{itemize}
\item  $a_{ij}$ represents the probability
\begin{equation}
\textrm{Prob}(X=x_j)
\end{equation}

\item  $a_{1j}$ represents the probability
\begin{equation}
\textrm{Prob}(X=x_{2j}orX=x_{2j+1})
\end{equation}

\item  $a_{4j}$ represents the probability
\begin{equation}
\textrm{Prob}(X=x_{4j}\text{ or }X=x_{4j+1}\text{ or }X=x_{4j+2}\text{ or }X=x_{4j+3})
\end{equation}

\item  $a_{ij}$ represents the probability
\begin{equation}
\textrm{Prob}(X\in \{x_k|2^ij\leq k<2^i(j+1)\})
\end{equation}
\end{itemize}

This algorithm works like the binary search, and at each step, it confronts the
uniform random number $u$ with $a_{ij}$ and decides if $u$ falls in the
range $\{x_k|2^ij\leq k<2^i(j+1)\}$ or in the complementary range $%
\{x_k|2^i(j+1)\leq k<2^i(j+2)\}$ and decreases $i.$

Here is the algorithm implemented as a class member function. The
constructor of the class creates an array $a$ once and for all. The method
discrete\_map maps a uniform random number $u$ into the desired discrete
integer:

\index{class!FishmanYarberry}

\begin{lstlisting}
class FishmanYarberry(object):
    def __init__(self, table=[[0, 0.2], [1, 0.5], [2, 0.3]]):
        t=log(len(table), 2)
        while t!=int(t):
            table.append([0, 0.0])
            t=log(len(table), 2)
        t=int(t)
        a=[]
        for i in range(t):
            a.append([])
            if i == 0:
                for j in range(2 ** t):
                    a[i].append(table[j, 1])
            else:
                for j in range(2 ** (t-i)):
                    a[i].append(a[i-1][2 * j]+a[i-1][2 * j+1])
        self.table=table
        self.t=t
        self.a=a

    def discrete_map(self, u):
        i=int(self.t)-1
        j=0
        b=0
        while i>0:
            if u>b+self.a[i][j]:
                b=b+self.a[i][j]
                j=2 * j+2
            else:
                j=2 * j
            i=i-1
        if u>b+self.a[i][j]:
            j=j+1
        return self.table[j][0]
\end{lstlisting}


\goodbreak\subsection{Binomial distribution}

\index{distribution!binomial}

The binomial distribution is a discrete probability distribution that
describes the number of successes in a sequence of $n$ independent
experiments, each of which yields success with probability $p$. Such a
success--failure experiment is also called a Bernoulli experiment.

A typical example is the following: 7\% of the population are left-handed.
You pick 500 people randomly. How likely is it that you get 30 or more
left-handed? The number of left-handed you pick is a random variable $X$
that follows a binomial distribution with $n=500$ and $p=0.07$. We are
interested in the probability $\textrm{Prob}(X=30)$.

In general, if the random variable $X$ follows the binomial distribution with
parameters $n$ and $p$, the probability of getting exactly $k$ successes is
given by

\begin{equation}
p(k)=\textrm{Prob}(X=k) \equiv  \binom nkp^k(1-p)^{n-k}
\end{equation}
for $k=0, 1, 2, ..., n$.

The formula can be understood as follows: we want $k$ successes ($p^k$) and $%
n-k$ failures ($(1-p)^{n-k}$). However, the $k$ successes can occur anywhere
among the $n$ trials, and there are $\binom nk$ different ways of distributing
$k$ successes in a sequence of $n$ trials.

The mean is $\mu _X=np$, and the variance is $\sigma _X^2=np(1-p)$.

If $X$ and $Y$ are independent binomial variables, then $X+Y$ is again a
binomial variable; its distribution is
\begin{equation}
p(k)=\textrm{Prob}(X=k)=\binom{n_X+n_Y}kp^k(1-p)^{n-k}
\end{equation}

We can generate random numbers following binomial distribution using a table lookup with table
\begin{equation}
\text{table[}k\text{]}=\textrm{Prob}(X=k)=\binom nkp^k(1-p)^{n-k}
\end{equation}

For large $n$, it may be convenient to avoid storing the table and use the
formula directly to compute its elements on a need-to-know basis.
Moreover, because the table is accessed sequentially by the
table lookup algorithm, one may just notice that the current recursive relation holds:
\begin{eqnarray}
\textrm{Prob}(X &=&0)=(1-p)^n \\
\textrm{Prob}(X &=&k+1)=\frac n{k+1}\frac p{1-p}\textrm{Prob}(X=k)
\end{eqnarray}

This allows for a very efficient implementation:

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
    def binomial(self, n, p, epsilon=1e-6):
        u = self.random()
        q = (1.0-p) ** n
        for k in range(n+1):
            if u<q+epsilon:
                return k
            u = u - q
            q = q * (n-k)/(k+1) * p/(1.0-p)
        raise ArithmeticError("invalid probability")
\end{lstlisting}


\goodbreak\subsection{Negative binomial distribution}

In probability theory, the negative binomial distribution is the probability
distribution of the number of trials $n$ needed to get a fixed
(nonrandom) number of successes $k$ in a Bernoulli process. If the random
variable $X$ is the number of trials needed to get $r$ successes in a series of
trials where each trial has probability of success $p$, then $X$ follows the
negative binomial distribution with parameters $r$ and $p$:
\begin{equation}
p(n)=\textrm{Prob}(X=n)=\binom{n-1}{k-1}p^k(1-p)^{n-k}
\end{equation}

Here is an example:

John, a kid, is required to sell candy bars in his neighborhood to
raise money for a field trip. There are thirty homes in his
neighborhood, and he is told not to return home until he has sold five candy bars.
So the boy goes door to door, selling candy bars. At each home he visits, he
has a 0.4 probability of selling one candy bar and a 0.6 probability of
selling nothing.

\begin{itemize}
\item  What"s the probability of selling the last candy bar at the $n$th house?
\begin{equation}
p(n)=\binom{n-1}40.4^50.6^{n-5}
\end{equation}

\item  What"s the probability that he finishes on the tenth house?
\begin{equation}
p(10)=\binom 940.4^50.6^5=0.10
\end{equation}

\item  What"s the probability that he finishes on or before reaching the
eighth house? Answer: To finish on or before the eighth house, he must
finish at the fifth, sixth, seventh, or eighth house. Sum those
probabilities:
\begin{equation}
\sum_{i=5, 6, 7, 8}p(i)=0.1737
\end{equation}

\item  What"s the probability that he exhausts all houses in the
neighborhood without selling the five candy bars?
\begin{equation}
1-\sum_{i=5, .., 30}p(i)=0.0015
\end{equation}
\end{itemize}

As we the binomial distribution, we can find an efficient recursive formula for the 
negative binomial distribution:

\begin{eqnarray}
\textrm{Prob}(X &=& k) = p^k \\
\textrm{Prob}(X &=& n+1)=\frac{n}{n-k+1}(1-p)\textrm{Prob}(X=n)
\end{eqnarray}

This allows for a very efficient implementation:

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
    def negative_binomial(self, k, p, epsilon=1e-6):        
        u = self.random()
        n = k 
        q = p ** k
        while True:
            if u<q+epsilon:
                return n
            u = u - q
            q = q * n/(n-k+1) * (1-p)
            n = n + 1
        raise ArithmeticError("invalid probability")
\end{lstlisting}

Notice once again that, unlike the binomial case, here $k$ is fixed, not $n$, and the random variable has a minimum value of $k$ but no upper bound.

\goodbreak\subsection{Poisson distribution}

\index{distribution!Poisson}

The Poisson distribution is a discrete probability distribution discovered
by Sim\"{e}on-Denis Poisson. It describes a random variable
$X$ that counts, among other things, the number of
discrete occurrences (sometimes called {\it arrivals}) that take place during
a time interval of given length. The probability that there are exactly $x$
occurrences ($x$ being a natural number including 0, $k=0, 1, 2, ...$) is
\begin{equation}
p(k)=\textrm{Prob}(X=k)=e^{-\lambda }\frac{\lambda ^k}{k!}
\end{equation}

The Poisson distribution arises in connection with Poisson processes. It
applies to various phenomena of discrete nature (i.e., those that may
happen 0, 1, 2, 3, ..., times during a given period of time or in a given
area) whenever the probability of the phenomenon happening is constant in
time or space. The Poisson distribution differs from the other distributions
considered in this chapter because it is different than zero for any natural
number $k$ rather than for a finite set of $k$ values.

Examples include the following:

\begin{itemize}
\item  The number of unstable nuclei that decayed within a given period of
time in a piece of radioactive substance.

\item  The number of cars that pass through a certain point on a road during
a given period of time.

\item  The number of spelling mistakes a secretary makes while typing a
single page.

\item  The number of phone calls you get per day.

\item  The number of times your web server is accessed per minute.

\item  The number of roadkill you find per mile of road.

\item  The number of mutations in a given stretch of DNA after a certain
amount of radiation.

\item  The number of pine trees per square mile of mixed forest.

\item  The number of stars in a given volume of space.
\end{itemize}

The limit of the binomial distribution with parameters $n$ and $p=\lambda /n$, for $n$ approaching infinity, is the Poisson distribution:

\begin{equation}
\frac{n!}{(n-k)!k!}\left( \frac \lambda n\right) ^k\left( 1-\frac \lambda
n\right) ^{n-k}\simeq e^{-\lambda }\frac{\lambda ^k}{k!}+O(\frac 1n)
\end{equation}

\begin{figure}[ht]
\centering\includegraphics[width=4in]{images/poisson.png}
\caption{Example of Poisson distribution.}
\end{figure}

Intuitively, the meaning of $\lambda $ is the following:

Let"s consider a unitary time interval $T$ and divide it into
$n$ subintervals of the same size.
Let $p_n$ be the probability of one success occurring in a single
subinterval. For $T$ fixed when $n\rightarrow \infty , $ $p_n\rightarrow 0$
but the limit
\begin{equation}
\lim_{n\rightarrow \infty }pn
\end{equation}
is finite. This limit is $\lambda $.

We can use the same technique adopted for the
binomial distribution and observe that for Poisson, 
\begin{eqnarray}
\textrm{Prob}(X &=&0)=e^{-\lambda } \\
\textrm{Prob}(X &=&k+1)=\frac{^\lambda }{k+1}\textrm{Prob}(X=k)
\end{eqnarray}
therefore the preceding algorithm can be modified into

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
    def poisson(self, lamb, epsilon=1e-6):
        u = self.random()
        q = exp(-lamb)
        k=0
        while True:
            if u<q+epsilon:
                return k
            u = u - q
            q = q * lamb/(k+1)
            k = k+1
        raise ArithmeticError("invalid probability")
\end{lstlisting}

Note how this algorithm may take an arbitrary amount of time to generate a
Poisson distributed random number, but eventually it stops. If $u$ is very
close to $1$, it is possible that errors due to finite machine precision
cause the algorithm to enter into an infinite loop. The $+\varepsilon $ term
can be used to correct this unwanted behavior by choosing $\varepsilon$ relatively small compared with the precision required in the computation, but
larger than machine precision.

\goodbreak\section{Probability distributions for continuous random variables}

\goodbreak\subsection{Uniform in range}

A typical problem is generating random integers in a given range $[a, b]$, 
including the extreme. We can map uniform random numbers $y_i\in (0, 1)$
into integers by using the formula
\begin{equation}
h_i=a+\left\lfloor (b-a+1)y_i\right\rfloor
\end{equation}

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
    def uniform(self, a, b):
        return a+(b-a) * self.random()
\end{lstlisting}

\goodbreak\subsection{Exponential distribution}
\index{distribution!exponential}

The exponential distribution is used to model Poisson processes, which are
situations in which an object initially in state A can change to state B
with constant probability per unit time $\lambda $. The time at which the
state actually changes is described by an exponential random variable with
parameter $\lambda $. Therefore the integral from $0$ to $T$ over $p(t)$ is
the probability that the object is in state $B$ at time $T$.

The probability mass function is given by

\begin{equation}
p(x)=\lambda e^{-\lambda x}
\end{equation}

The exponential distribution may be viewed as a continuous counterpart of
the geometric distribution, which describes the number of Bernoulli trials
necessary for a discrete process to change state. In contrast, the
exponential distribution describes the time for a continuous process to
change state.

Examples of variables that are approximately exponentially distributed are as follows:

\begin{itemize}
\item  the time until you have your next car accident

\item  the time until you get your next phone call

\item  the distance between mutations on a DNA strand

\item  the distance between roadkill
\end{itemize}

An important property of the exponential distribution is that it is
memoryless: the chance that an event will occur $s$ seconds from now does not depend on the past. In particular, it does not depend on how much time we have been waiting already. In a formula we can write this condition as

\begin{equation}
\textrm{Prob}(X>s+t|X>t)=\textrm{Prob}(X>s)
\end{equation}

Any process satisfying the preceding condition is a Poisson process. The number of events per time unit is given by the Poisson distribution, and the time interval between consecutive events is described by the exponential distribution.

\begin{figure}[ht]
\centering\includegraphics[width=4in]{images/exponential.png}
\caption{Example of exponential distribution.}
\end{figure}

The exponential distribution can be generated using the inversion method.
The scope is to determine a function $x=f(u)$ that maps a uniformly distributed variable $u$
into a continuous random variable $x$ with probability mass function $%
p(x)=\lambda e^{-\lambda x}$.

According to the inversion method, we proceed by computing $F$:
\begin{equation}
F(x) = \int_0^x p(y)dy=1-e^{-\lambda x}
\end{equation}
and we then invert $u=F(x)$, thus obtaining
\begin{equation}
x=-\frac 1\lambda \log (1-u)
\end{equation}
Now notice that if $u$ is uniform, $1-u$ is also uniform; therefore we can further simplify:
\begin{equation}
x=-\frac 1\lambda \log u
\end{equation}

We implement as follows:

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
    def exponential(self, lamb):
        return -log(self.random())/lamb
\end{lstlisting}

This is an important distribution, and Python has a function for it:

\begin{lstlisting}
random.expovariate(lamb)
\end{lstlisting}

\goodbreak\subsection{Normal/Gaussian distribution}
\index{distribution!normal}
\index{distribution!Gaussian}

The normal distribution (also known as {\it Gaussian distribution})
is an extremely important probability distribution
considered in statistics. Here is the probability mass function:
\begin{equation}
p(x)=\frac 1{\sigma \sqrt{2\pi }}e^{-\frac{(x-\mu )^2}{2\sigma ^2}}
\end{equation}
where $E[X]=\mu $ and $E[(x-\mu )^2]=\sigma ^2$.

The standard normal distribution is the normal distribution with a mean of
0 and a standard deviation of 1. Because the graph of its probability
density resembles a bell, it is often called the {\it bell curve}.

The Gaussian distribution has two important properties:
\begin{itemize}
\item The average of many independent random variables with finite mean and finite variance tends to be a Gaussian distribution.
\item The sum of two independent Gaussian random variables with means $\mu_1$ and $\mu_2$ and variances $\sigma_1^2$ and $\sigma_2^2$ is also a Gaussian random variable with mean $\mu = \mu_1+\mu_2$ and variance $\sigma^2 = \sigma_1^2+\sigma_2^2$.
\end{itemize}

\begin{figure}[ht]
\centering\includegraphics[width=4in]{images/gaussian.png}
\caption{Example of Gaussian distribution.}
\end{figure}

There is no way to map a uniform random number into a Gaussian number but there is an algorithm to generate two independent Gaussian random numbers ($y_1$ and $y_2$) using two independent uniform random numbers ($x_1$ and $x_2$):

\begin{itemize}
\item  computing $v_1=2x_1-1, v_2=2x_2-1$ and $s=v_1^2+v_2^2$
\item  if $s>1$ start again
\item  $y_1=v_1\sqrt{(-2/s)\log s}$ and $y_2=v_2\sqrt{(-2/s)\log s}$
\end{itemize}

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
    def gauss(self, mu=0.0, sigma=1.0):
        if hasattr(self, "other") and self.other:
            this, other = self.other, None
        else:
            while True:
                v1 = self.random(-1, 1)
                v2 = self.random(-1, 1)
                r = v1 * v1+v2 * v2
                if r<1: break
            this = sqrt(-2.0 * log(r)/r) * v1
            self.other = sqrt(-2.0 * log(r)/r) * v1
        return mu+sigma * this
\end{lstlisting}

Note how the first time the method next is called, it generates two Gaussian
numbers ($this$ and $other$), stores $other$, and returns $this$. Every other
time, the method next is called if $other$ is stored, and it returns a number;
otherwise it recomputes $this$ and $other$ again.

To map a random Gaussian number $y$ with mean $0$ and standard deviation $1$
into another Gaussian number $y^{\prime }$ with mean $\mu $ and standard
deviation $\sigma $, 
\begin{equation}
y^{\prime }=\mu +y\sigma
\end{equation}
We used this relation in the last line of the code.

This is also an important distribution, and Python has a function for it:

\begin{lstlisting}
random.gauss(mu, sigma)
\end{lstlisting}

Given a Gaussian random variable with mean $\mu$ and standard deviation $\sigma$, it is often useful to know how many standard deviations $a$ correspond to a confidence $c$ defined as

\begin{equation}
c = \int_{\mu-a\sigma}^{\mu+a\sigma} p(x)\textrm{d}x
\end{equation}

The following algorithm generates a table of $a$ versus $c$ given $\mu$ and $\sigma$:

\index{confidence intervals}

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
def confidence_intervals(mu, sigma):
    """Computes the normal confidence intervals"""
    CONFIDENCE=[
        (0.68, 1.0), 
        (0.80, 1.281551565545), 
        (0.90, 1.644853626951), 
        (0.95, 1.959963984540), 
        (0.98, 2.326347874041), 
        (0.99, 2.575829303549), 
        (0.995, 2.807033768344), 
        (0.998, 3.090232306168), 
        (0.999, 3.290526731492), 
        (0.9999, 3.890591886413), 
        (0.99999, 4.417173413469)
        ]
    return [(a, mu-b * sigma, mu+b * sigma) for (a, b) in CONFIDENCE]
\end{lstlisting}


\goodbreak\subsection{Pareto distribution}
\index{distribution!pareto}

The Pareto distribution, named after the economist Vilfredo Pareto, is a power law probability distribution that coincides with social, scientific, geophysical, actuarial, and many other types of observable phenomena. Outside the field of economics, it is sometimes referred to as the Bradford distribution. Its cumulative distribution function is

\begin{equation}
F(x) \equiv  \textrm{Prob}(X<x) = 1 - \left(\frac{x_m}{x}\right)^{\alpha}
\end{equation}

\begin{figure}[ht]
\centering\includegraphics[width=4in]{images/pareto.png}
\caption{Example of Pareto distribution.}
\end{figure}

It can be implemented as follows using the inversion method:

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
    def pareto(self, alpha, xm):
        u = self.random()
        return xm * (1.0-u) ** (-1.0/alpha)
\end{lstlisting}

The Python function to generate Pareto distributed random numbers is

\begin{lstlisting}
xm * random.paretovariate(alpha)
\end{lstlisting}

The Pareto distribution is an example of Levy distribution. The Central Limit theorem does not apply to it.

\goodbreak\subsection{In and on a circle}
\index{distribution!circle}

We can generate a random point $(x, y)$ uniformly distributed on a circle by generating a random angle.
\begin{eqnarray}
x &=&\cos (2\pi u) \\
y &=&\sin (2\pi u)
\end{eqnarray}

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
    def point_on_circle(self, radius=1.0):
        angle = 2.0 * pi * self.random()
        return radius * math.cos(angle), radius * math.sin(angle)
\end{lstlisting}

We can generate a random point uniformly distributed inside a circle by generating, independently, the $x$ and $y$ coordinates of points inside a square and rejecting those outside the circle:

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
    def point_in_circle(self, radius=1.0):
        while True:
            x = self.uniform(-radius, radius)
            y = self.uniform(-radius, radius)
            if x * x+y * y < radius * radius:
                return x, y
\end{lstlisting}

\goodbreak\subsection{In and on a sphere}
\index{distribution!sphere}

A random point $(x, y, z)$ uniformly distributed on a sphere of radius 1 is
obtained by generating three uniform random numbers $u_1, u_2, u_3, $; compute $%
v_i=2u_i-1$, and if $v_1^2+v_2^2+v_3^2\leq 1$, 
\begin{eqnarray}
x &=&v_1/\sqrt{v_1^2+v_2^2+v_3^2} \\
y &=&v_2/\sqrt{v_1^2+v_2^2+v_3^2} \\
z &=&v_3/\sqrt{v_1^2+v_2^2+v_3^2}
\end{eqnarray}
else start again.

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
    def point_in_sphere(self, radius=1.0):
        while True:
            x = self.uniform(-radius, radius)
            y = self.uniform(-radius, radius)
            z = self.uniform(-radius, radius)
            if x * x+y * y * z * z < radius * radius:
                return x, y, z

    def point_on_sphere(self, radius=1.0):
        x, y, z = self.point_in_sphere(radius)
        norm = math.sqrt(x * x+y * y+z * z)
        return x/norm, y/norm, z/norm
\end{lstlisting}

\section{Resampling}
\index{resampling}

So far we always generated random numbers by modeling the random variable (e.g., uniform, or exponential, or Pareto) and using an algorithm to generate possible values of the random variables.

We now introduce a different methodology, which we will need later when talking about the bootstrap method.
If we have a population $S$ of equally distributed events and we need to generate an event from the same distribution as the population, we can simply draw a random element from the population. In Python, this is done with

\begin{lstlisting}
>>> S = [1, 2, 3, 4, 5, 6]
>>> random.choice(S)
\end{lstlisting}

We can therefore generate a sample of random events by repeating this procedure. This is called {\it resampling}~\cite{resampling}:

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
def resample(S, size=None):
    return [random.choice(S) for i in range(size or len(S))]
\end{lstlisting}

\goodbreak\section{Binning}
\index{binning}

Binning is the process of dividing a space of possible events into
partitions and counting how many events fall into each partition. We can bin
the numbers generated by a pseudo random number generator and measure the
distribution of the random numbers.

Let"s consider the following program:
\begin{lstlisting}
def bin(generator, nevents, a, b, nbins):
     # create empty bins
    bins=[]
    for k in range(nbins):
        bins.append(0)
     # fill the bins
    for i in range(nevents):
        x=generator.uniform()
        if x>=a and x<=b:
            k=int((x-a)/(b-a) * nbins)
            bins[k]=bins[k]+1
     # normalize bins
    for i in range(nbins):
        bins[i]=float(bins[i])/nevents
    return bins

def test_bin(nevents=1000, nbins=10):
    bins=bin(MCG(time()), nevents, 0, 1, nbins)
    for i in range(len(bins)):
        print(i, bins[i])

>>> test_bin()
\end{lstlisting}

It produces the following output:
\begin{lstlisting}
i frequency[i]
0 0.101
1 0.117
2 0.092
3 0.091
4 0.091
5 0.122
6 0.096
7 0.102
8 0.090
9 0.098
\end{lstlisting}

Note that

\begin{itemize}
\item  all bins have the same size 1/nbins;

\item  the size of the bins is normalized, and the sum of the values is 1

\item  the distribution of the events into bins approaches the distribution
of the numbers generated by the random number generator
\end{itemize}

As an experiment, we can do the same binning on a larger number of events, 
\begin{lstlisting}
>>> test_bin(100000)
\end{lstlisting}

which produces the following output:
\begin{lstlisting}
i frequency[i]
0 0.09926
1 0.09772
2 0.10061
3 0.09894
4 0.10097
5 0.09997
6 0.10056
7 0.09976
8 0.10201
9 0.10020
\end{lstlisting}

Note that these frequencies differ from 0.1 for less than 3\%, whereas some of
the preceding numbers differ from 0.11 for more than 20\%.

\chapter{Monte Carlo Simulations}
\index{Monte Carlo}

\goodbreak\section{Introduction}

Monte Carlo methods are a class of algorithms that rely on repeated random sampling to compute their results, which are otherwise deterministic.

\goodbreak\subsection{Computing $\pi$}

The standard way to compute $\pi $ is by applying the definition: $\pi $ is
the length of a semicircle with a radius equal to 1. From the definition, one can
derive an exact formula:
\begin{equation}
\pi =4\arctan 1
\end{equation}
The arctan has the following Taylor series expansion:\footnote{%
Taylor expansion:
\begin{equation}
f(x)=f(0)+f^{\prime }(0)x+\frac 1{2!}f^{\prime \prime }(0)x^2+...+\frac
1{i!}f^{(i)}(0)x^2+....
\end{equation}
\par
and if $f(x)=\arctan x$ then:
\begin{eqnarray}
f^{\prime }(x) &=&\frac{d\arctan x}{dx}=\frac 1{1+x^2}\rightarrow f^{\prime
}(0)=1 \\
f^{\prime \prime }(x) &=&\frac{d^2\arctan x}{d^2x}=\frac d{dx}\frac
1{1+x^2}=-\frac{2x}{(1+x^2)^2} \\
&&... \\
f^{(2i+1)}(x) &=&(-1)^i\frac{(2i)!}{(1+x^2)^{2i+1}}+x...\rightarrow
f^{(2i+1)}(0)=(-1)(2i)! \\
f^{(2i)}(x) &=&x...\rightarrow f^{(2i)}(0)=0
\end{eqnarray}
}:

\begin{equation}
\arctan x=\allowbreak \sum_{i=0}(-1)^i\frac{x^{2i+1}}{2i+1}
\end{equation}
and one can approximate $\pi $ to arbitrary precision by computing the sum
\begin{equation}
\pi =\allowbreak \sum_{i=0}(-1)^i\frac 4{2i+1}
\end{equation}

We can use the program
\begin{lstlisting}
def pi_Taylor(n):
    pi=0
    for i in range(n):
        pi=pi+4.0/(2 * i+1) * (-1) ** i
        print(i, pi)

>>> pi_Taylor(1000)
\end{lstlisting}

which produces the following output:
\begin{lstlisting}
0 4.0
1 2.66666...
2 3.46666...
3 2.89523...
4 3.33968...
...
999 3.14..
\end{lstlisting}

A better formula is due to Plauffe, 

\begin{equation}
\pi = \sum_{i=0} \frac{1}{16^i} \left(
\frac{4}{8i+1}-\frac{2}{8i+4}-\frac{1}{8i+5}-\frac{1}{8i+6}
\right)
\end{equation}

which we can implement as follows:
we can use the program
\begin{lstlisting}
from decimal import Decimal

def pi_Plauffe(n):
    pi=Decimal(0)
    a, b, c, d = Decimal(4), Decimal(2), Decimal(1), Decimal(1)/Decimal(16)
    for i in range(n):
        i8 = Decimal(8) * i
        pi=pi+(d ** i) * (a/(i8+1)-b/(i8+4)-c/(i8+5)-c/(i8+6))
    return pi
>>> pi_Plauffe(1000)
\end{lstlisting}

The preceding formula works and converges very fast and already in 100 iterations produces
\begin{equation}
\pi = 3.1415926535897932384626433...
\end{equation}

There is a different approach based on the fact that $\pi$ is also the
area of a circle of radius 1. We can draw a square or area containing
a quarter of a circle of radius 1. We can randomly generate points $(x, y)$
with uniform distribution inside the square and check if the points fall inside
the circle. The ratio between the number of points that fall in
the circle over the total number of points is proportional to the area of
the quarter of a circle ($\pi /4$) divided by the area of the square (1).

Here is a program that implements this strategy:
\begin{lstlisting}
from random import * 

def pi_mc(n):
    pi=0
    counter=0
    for i in range(n):
        x=random()
        y=random()
        if x ** 2 + y ** 2 < 1:
            counter=counter+1
        pi=4.0 * float(counter)/(i+1)
        print(i, pi)

pi_mc(1000)
\end{lstlisting}

The output of the algorithm is shown in fig.~\ref{pi-plot}.

\begin{figure}[ht]
\centering\includegraphics[width=4in]{images/pi.png}
\caption{Convergence of {\bf pi\_mc}.\label{pi-plot}}
\end{figure}

The convergence rate in this case is very slow, and this algorithm is of no practical value, but the methodology is sound, and for some problems, this method is the only one feasible.

Let"s summarize what we have done: we have formulated our problem (compute $%
\pi $) as the problem of computing an area (the area of a quarter of a
circle), and we have computed the area using random numbers. This is a
particular example of a more general technique known as a Monte Carlo
integration. In fact, the computation of an area is equivalent to the problem
of computing an integral.

Sometimes the formula is not known, or it is too complex to compute reliably, hence a Monte Carlo solution becomes preferable.


\goodbreak\subsection{Simulating an online merchant}

Let"s consider an online merchant. A website is visited many times a day.
From the logfile of the web application, we determine
that the average number of visitors in a day is 976, the number of
visitors is Gaussian distributed, and the standard deviation is 352. We also observe that each visitor has a 5\% probability of purchasing an item
if the item is in stock and a 2\% probability to buy an item if the
item is not in stock.

The merchant sells only one type of item that costs \$100 per unit. The
merchant maintains $N$ items in stock. The merchant pays \$30 a day to store
each unit item in stock. What is the optimal $N$ to maximize the average
daily income of the merchant?

This problem cannot easily be formulated analytically or reduced to
the computation of an integral, but it can easily be simulated.

In particular, we simulate many days and, for each day $i$, 
we start with $N$ items
in stock, and we loop over each simulated visitor. If the visitor
finds an item in stock, he buys it with a 5\% probability
(producing an income of \$70), whereas if the item is not in stock, 
 he buys it with 2\% probability (producing an income of \$100).
At the end of each day, we pay \$30 for each item remaining in stock.

Here is a program that takes $N$ (the number of items in stock) and $d$ (the
number of simulated days) and computes the average daily income:
\begin{lstlisting}
def simulate_once(N):
    profit = 0
    loss = 30 * N
    instock = N
    for j in range(int(gauss(976, 352))):
        if instock>0:
            if random()<0.05:
                instock=instock-1
                profit = profit + 100
        else:
            if random()<0.02:
                profit = profit + 100
    return profit-loss

def simulate_many(N, ap=1, rp=0.01, ns=1000):
    s = 0.0
    for k in range(1, ns):
        x = simulate_once(N)
        s += x
        mu = s/k
        if k>10 and mu-mu_old<max(ap, rp * mu):
            return mu
        else:
            mu_old = mu
    raise ArithmeticError("no convergence")
\end{lstlisting}

By looping over different $N$ (items in stock), we can compute the average daily income as a function of $N$:
\begin{lstlisting}
>>> for N in range(0, 100, 10):
>>>     print(N, simulate_many(N, ap=100))
\end{lstlisting}

The program produces the following output:
\begin{lstlisting}
n income
0 1955
10 2220
20 2529
30 2736
40 2838
50 2975
60 2944
70 2711
80 2327
90 2178
\end{lstlisting}

From this we deduce that the optimal number of items to carry in stock is
about 50. We could increase the resolution and precision of the simulation
by increasing the number of simulated days and reducing the step of the
amount of items in stock.

Note that the statement {\ft gauss(976, 352)} generates a random floating
point number with a Gaussian distribution centered at 976 and standard
deviation equal to 352, whereas the statement
\begin{lstlisting}
if random()<0.05:
\end{lstlisting}

ensures that the subsequent block is executed with a probability of 5\%.

The basic ingredients of every Monte Carlo simulation are here: (1) a function that simulates the system once and uses random variables to model unknown quantities; (2) a function that repeats the simulation many times to compute an average.

Any Monte Carlo solver comprises the following parts:

\begin{itemize}
\item A generator of random numbers (such as we have discussed in the previous chapter)
\item A function that uses the random number generator and can simulate the system once (we will call $x$ the result of each simulate once)
\item A function that calls the preceding simulation repeatedly and averages the results until they converge $\mu = \frac1N \sum x_i$
\item A function to estimate the accuracy of the result and determine when to stop the simulation, $\delta\mu < \textrm{precision}$
\end{itemize}

\section{Error analysis and the bootstrap method}

The result of any MC computation is an average:
\begin{equation}
\mu = \frac1N \sum x_i
\end{equation}

The error on this average can be estimated using the formula

\begin{equation}
\delta\mu = \frac{\sigma}{\sqrt{N}} = \sqrt{\frac1{N} \left( {\frac1N \sum x^2_i - \mu^2} \right)}
\end{equation}

This formula assumes the distribution of the $x_i$ is Gaussian. Using this formula, we can compute a 68\% confidence level for the MC computation of $\pi$, shown in fig.~\ref{pi-plot2}.

\begin{figure}[ht]
\centering\includegraphics[width=4in]{images/pi2.png}
\caption{Convergence of $\pi$\label{pi-plot2}.}
\end{figure}

\index{bootstrap}

The purpose of the bootstrap~\cite{bootstrap} algorithm is computing the error in an average $\mu = (1/N) \sum x_i$ without making the assumption that the $x_i$ are Gaussian.

The first step of the bootstrap methodology consists of computing the average not only on the initial sample $\{x_i\}$ but also on many data samples obtained by resampling the original data. If the number of elements $N$ of the original sample were infinity, the average on each other sample would be the same. Because $N$ is finite, each of these means produces slightly different results:

\begin{equation}
\mu_k = \frac1N \sum x^{[k]}_i
\end{equation}

where $x^{[k]}_i$ is the $i$th element of resample $k$ and $\mu_k$ is the average of that resample.

The second step of the bootstrap methodology consists of sorting the $\mu_k$ and finding two values $\mu^-$ and $\mu^+$ that with a given percentage of the means follows in between those two values. The given percentage is the confidence level, and we set it to $68\%$.

Here is the complete algorithm:

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
def bootstrap(x, confidence=0.68, nsamples=100):
    """Computes the bootstrap errors of the input list."""
    def mean(S): return float(sum(x for x in S))/len(S)
    means = [mean(resample(x)) for k in range(nsamples)]
    means.sort()
    left_tail = int(((1.0-confidence)/2) * nsamples)
    right_tail = nsamples-1-left_tail
    return means[left_tail], mean(x), means[right_tail]
\end{lstlisting}

Here is an example of usage:

\begin{lstlisting}
>>> S = [random.gauss(2, 1) for k in range(100)]
>>> bootstrap(S)
(1.7767055865879007, 1.8968778392283303, 2.003420362236985)
\end{lstlisting}

In this example, the output consists of $\mu^-$, $\mu$, and $\mu^+$.

Because $S$ contains 100 random Gaussian numbers, with average 2 and standard deviation 1, we expect $\mu$ to be close to 2. We get $1.89$. The bootstrap tells us that with 68\% probability, the true average of these numbers is indeed between $1.77$ and $2.00$. The uncertainty $(2.00-1.77)/2 = 0.12$ is compatible with $\sigma/\sqrt{100} = 1/10 = 0.10$.

\goodbreak\section{A general purpose Monte Carlo engine}
\index{MCEngine}

We can now combine everything we have seen so far into a generic program that can be used to perform the most generic Monte Carlo computation/simulation:

\index{class!MCEngine}

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
class MCEngine:
    """
    Monte Carlo Engine parent class.
    Runs a simulation many times and computes average and error in average.
    Must be extended to provide the simulate_once method
    """
    def simulate_once(self):
        raise NotImplementedError

    def simulate_many(self, ap=0.1, rp=0.1, ns=1000):
        self.results = []
        s1=s2=0.0
        self.convergence=False
        for k in range(1, ns):
            x = self.simulate_once()
            self.results.append(x)
            s1 += x
            s2 += x * x
            mu = float(s1)/k
            variance = float(s2)/k-mu * mu
            dmu = sqrt(variance/k)
            if k>10:
                if abs(dmu)<max(ap, abs(mu) * rp):
                    self.converence = True
                    break
        self.results.sort()
        return bootstrap(self.results)
\end{lstlisting}

The preceding class has two methods:
\begin{itemize}
\item {\ft simulate\_once} is not implemented because the class is designed to be subclassed, and the method is supposed to be implemented for each specific computation.
\item {\ft simulate\_many} is the part that stays the same; it calls {\ft simulate\_once} repeatedly, computes average and error analysis, checks convergence, and computes bootstrap error for the result.
\end{itemize}

It is also useful to have a function, which we call {\bf var} (aka {\it value at risk}~\cite{wilmott}), which computes a numerical value so that the output of a given percentage of the simulations falls below that value:

%%% META:FILE:nlib.py
\begin{lstlisting}[caption={in file: {\ft nlib.py}}]
    def var(self, confidence=95):
        index = int(0.01 * len(self.results) * confidence+0.999)
        if len(self.results)-index < 5:
            raise ArithmeticError("not enough data, not reliable")
        return self.results[index]
\end{lstlisting}

Now, as a first example, we can recompute $\pi$ using this class:

\index{class!PiSimulator}

\begin{lstlisting}
>>> class PiSimulator(MCEngine):
...     def simulate_once(self):
...         return 4.0 if (random.random() ** 2+random.random() ** 2)<1 else 0.0
...
>>> s = PiSimulator()
>>> s.simulate_many()
(2.1818181818181817, 2.909090909090909, 3.6363636363636362)
\end{lstlisting}

Our engine finds that the value of $\pi$ with 68\% confidence level is between $2.18$ and $3.63$, with the most likely value of $2.90$. Of course, this is incorrect, because it generates too few samples, but the bounds are correct, and that is what matters.

\subsection{Value at risk}\index{value at risk}

Let"s consider a business subject to random losses, for example, a large bank subject to theft from employees.
Here we will make the following reasonable assumptions (which have been verified with data):
\begin{itemize}
\item There is no correlation between individual events.
\item There is no correlation between the time when a loss event occurs and the amount of the loss.
\item The time interval between losses is given by the exponential distribution (this is a Poisson process).
\item The distribution of the loss amount is a Pareto distribution (there is a fat tail for large losses).
\item The average number of losses is 10 per day.
\item The minimum recorded loss is \$5000. The average loss is \$15, 000.
\end{itemize}

Our goal is to simulate one year of losses and to determine

\begin{itemize}
\item The average total yearly loss
\item How much to save to make sure that in 95\% of the simulated scenarios, the losses can be covered without going broke
\end{itemize}

From these assumptions, we determine that the $\lambda=10$ for the exponential distribution and $x_m=3000$ for the Pareto distribution. The mean of the Pareto distribution is $\alpha x_m/(\alpha-1) = 15, 000$, from which we determine that $\alpha = 1.5$.

We can answer the first questions (the average total loss) simply multiplying the average number of losses per year, $52\times5$, by the number of losses in one day, 10, and by the average individual loss, \$15, 000, thus obtaining

\begin{equation}
\textrm{[average yearly loss]} = \$39, 000, 000
\end{equation}

To answer the second question, we would need to study the width of the distribution. The problem is that, for $\alpha=1.5$, the standard deviation of the Pareto distribution is infinity, and analytical methods do not apply. We can do it using a Monte Carlo simulation:


%%% META:FILE:risk.py
\begin{lstlisting}[caption={in file: {\ft risk.py}}]
from nlib import * 
import random

class RiskEngine(MCEngine):
    def __init__(self, lamb, xm, alpha):
        self.lamb = lamb
        self.xm = xm
        self.alpha = alpha
    def simulate_once(self):
        total_loss = 0.0
        t = 0.0
        while t<260:
            dt = random.expovariate(self.lamb)
            amount = self.xm * random.paretovariate(self.alpha)
            t += dt
            total_loss += amount
        return total_loss

def main():
    s = RiskEngine(lamb=10, xm=5000, alpha=1.5)
    print(s.simulate_many(rp=1e-4, ns=1000))
    print(s.var(95))

main()
\end{lstlisting}

This produces the following output:

\begin{lstlisting}
(38740147.179054834, 38896608.25084647, 39057683.35621854)
45705881.8776
\end{lstlisting}

The output of {\ft simulate\_many} should be compatible with the true result (defined as the result after an infinite number of iterations and at infinite precision) within the estimated statistical error.

The output of the {\ft var} function answers our second questions: We have to save \$45, 705, 881 to make sure that in 95\% of cases our losses are covered by the savings.


\subsection{Network reliability}
\index{network reliability}

Let"s consider a network represented by a set of $n_{nodes}$ nodes and $%
n_{links}$ bidirectional links. Information
packets travel on the network. They can
originate at any node ({\ft start}) and be addressed to any other node ({\ft %
stop}). Each link of the network has a probability $p$ of transmitting the
packet (success) and a probability $(1-p)$ of dropping the packet (failure).
The probability $p$ is in general different for each link of the network.

We want to compute the probability that a packet
starting in {\ft start} finds a successful path to reach {\ft stop}. A path
is successful if, for a given simulation, all links in the path succeed in
carrying the packet.

The key trick in solving this problem is in finding the proper
representation for the network. Since we are not requiring to determine the
exact path but only proof of existence, we use the concept of equivalence classes.

We say that two nodes are in the same equivalence class if and only
if there is a successful path that connects the two nodes.

The optimal data structure to implement equivalence classes is {\ft DisjSets}, discussed in chapter 3.

To simulate the system, we create a class {\ft Network} that extends {\ft MCEngine}. It has a {\ft simulate\_once} method that tries to send a packet from {\ft start} to
{\ft stop} and simulates the network once. During the simulation each link of the network may be up or down with given probability. If there is a path connecting the {\ft start} node to the {\ft stop} node in which all links of the network are up, than the packet transfer succeeds. We use the DisjointSets to represent sets of nodes connected together. If there is a link up connecting a node from a set to a node in another set, than the two sets are joined. If, in the end, the {\ft start} and {\ft stop} nodes are found to belong to the same set, then there is a path and {\ft simulate\_once} returns 1, otherwise it returns 0.

\index{class!NetworkReliability}

%%% META:FILE:network.py
\begin{lstlisting}[caption={in file: {\ft network.py}}]
from nlib import * 
import random

class NetworkReliability(MCEngine):
    def __init__(self, n_nodes, start, stop):
        self.links = []
        self.n_nodes = n_nodes
        self.start = start
        self.stop = stop
    def add_link(self, i, j, failure_probability):
        self.links.append((i, j, failure_probability))
    def simulate_once(self):
        nodes = DisjointSets(self.n_nodes)
        for i, j, pf in self.links:
            if random.random()>pf:
                nodes.join(i, j)
        return nodes.joined(i, j)

def main():
    s = NetworkReliability(100, start=0, stop=1)
    for k in range(300):
        s.add_link(random.randint(0, 99), 
                   random.randint(0, 99), 
                   random.random())
    print(s.simulate_many())

main()
\end{lstlisting}

\subsection{Critical mass}
\index{radioactive decays}\index{nuclear reactor}

Here we consider the simulation of a chain reaction in a fissile material, for example, the uranium in a nuclear reactor~\cite{neutron}. We assume a material is in a spherical shape of known radius. At each point there is a probability of a nuclear fission, which we model as the emission of two neutrons. Each of the two neutrons travels and hits an atom, thus causing another fission. The two neutrons are emitted in random opposite directions and travel a distance given by the exponential distribution. The new fissions may occur inside material itself or outside. If outside, they are ignored. If the number of fission events inside the material grows exponentially with time, we have a self-sustained chain reaction; otherwise, we do not.

Fig.~\ref{nuclear} provides a representation of the process.

\begin{figure}[ht]
\centering\includegraphics[width=4in]{images/critical.png}
\caption{Example of chain reaction within a fissile material. If the mass is small, most of the decay products escape (left, sub-criticality), whereas if the mass exceeds a certain critical mass, there is a self-sustained chain reaction (right).\label{nuclear}}
\end{figure}

\begin{figure}[ht]
\centering\includegraphics[width=4in]{images/nuclear.png}
\caption{Probability of chain reaction in uranium.\label{nuclear2}}
\end{figure}

Here is a possible implementation of the process. We store each event that happens inside the material in a queue ({\ft events}). For each simulation, the queue starts with one event, and from it we generate two more, and so on. If the new events happen inside the material, we place the new events back in the queue. If the size of the queue shrinks to zero, then we are subcritical. If the size of the queue grows exponentially, we have a self-sustained chain reaction. We detect this by measuring the size of the queue and wether it exceeds a threshold (which we arbitrarily set to 200). The average free flight distance for a neutron in  uranium is 1.91 cm. We use this number in our simulation. Given the radius of the material, {\ft simulate\_once} returns 1.0 if it detects a chain reaction and 0.0 if it does not. The output of {\ft simulate\_many} is the probability of a chain reaction:

\index{class!NuclearReactor}

%%% META:FILE:nuclear.py
\begin{lstlisting}[caption={in file: {\ft nuclear.py}}]
from nlib import * 
import math
import random

class NuclearReactor(MCEngine):
    def __init__(self, radius, mean_free_path=1.91, threshold=200):
        self.radius = radius
        self.density = 1.0/mean_free_path
        self.threshold = threshold
    def point_on_sphere(self):
        while True:
            x, y, z = random.random(), random.random(), random.random()
            d = math.sqrt(x * x+y * y+z * z)
            if d<1: return (x/d, y/d, z/d)  # project on surface
    def simulate_once(self):
        p = (0, 0, 0)
        events = [p]
        while events:
            event = events.pop()
            v = self.point_on_sphere()
            d1 = random.expovariate(self.density)
            d2 = random.expovariate(self.density)
            p1 = (p[0]+v[0] * d1, p[1]+v[1] * d1, p[2]+v[2] * d1)
            p2 = (p[0]-v[0] * d2, p[1]-v[1] * d2, p[2]-v[2] * d2)
            if p1[0] ** 2+p1[1] ** 2+p1[2] ** 2 < self.radius:
                events.append(p1)
            if p2[0] ** 2+p2[1] ** 2+p2[2] ** 2 < self.radius:
                events.append(p2)
            if len(events) > self.threshold:
                return 1.0
        return 0.0

def main():
    s = NuclearReactor(MCEngine)
    data = []
    s.radius = 0.01
    while s.radius<21:
        r = s.simulate_many(ap=0.01, rp=0.01, ns=1000, nm=100)
        data.append((s.radius, r[1], (r[2]-r[0])/2))
        s.radius *= 1.2
    c = Canvas(title="Critical Mass", xlab="Radius", ylab="Probability Chain Reaction")
    c.plot(data).errorbar(data).save("nuclear.png")

main()
\end{lstlisting}

Fig.~\ref{nuclear2} shows the output of the program, the probability of a chain reaction as function of the size of the uranium mass. We find a critical radius between 2 cm and 10 cm, which corresponds to a critical mass between 0.5 kg and 60 kg. The official number is 15 kg for uranium 233 and  60 kg for uranium 235. The lesson to learn here is that it is not safe to accumulate too much fissile material together. This simulation can be easily tweaked to determine the thickness of a container required to shield a radioactive material.

\section{Monte Carlo integration}
\index{integration!Monte Carlo}

\goodbreak\subsection{One-dimensional Monte Carlo integration}

Let"s consider a one-dimensional integral
\begin{equation}
I=\int_a^bf(x)dx
\end{equation}
Let"s now determine two functions $g(x)$ and $p(x)$ such that
\begin{equation}
p(x)=0\text{ for }x\in [-\infty , a]\cup [n, \infty ]
\end{equation}
and
\begin{equation}
\int_{-\infty }^{+\infty }p(x)dx=1
\end{equation}
and
\begin{equation}
g(x)=f(x)/p(x)
\end{equation}

We can interpret $p(x)$ as a probability mass function and
\begin{equation}
E[g(X)]=\int_{-\infty }^{+\infty }g(x)p(x)dx=\int_a^bf(x)dx=I
\end{equation}
Therefore we can compute the integral by computing the expectation value of
the function $g(X)$, where $X$ is a random variable with a distribution
(probability mass function) $p(x)$ different from zero in $[a, b]$ generated.

An obvious, although not in general an optimal choice, is
\begin{eqnarray}
&&p(x)\equiv \left\{
\begin{array}{ll}
1/(b-a) & \text{if }x\in [a, b] \\
0 & \text{otherwise}
\end{array}
\right\}   \label{defchoice} \\
&&g(x)\equiv (b-a)f(x)  \nonumber
\end{eqnarray}
so that $X$ is just a uniform random variable in $[a, b]$. Therefore
\begin{equation}
I=E\left[ g(X)\right] =\frac1N \sum_{i=0}^{i<N}g(x_i)
\end{equation}
This means that the integral can be evaluated by generating $N$ random
points $x_i$ with uniform distribution in the domain, evaluating the
integrand (the function $f$) on each point, averaging the results, and
multiplying the average by the size of the domain ($b-a$).

Naively, the error on the result can be estimated by computing the variance
\begin{equation}
\sigma ^2 = \frac 1N\sum_{i=0}^{i<N}\left[ g(x_i)-\left\langle
g\right\rangle \right] ^2
\end{equation}
with
\begin{equation}
\left\langle g\right\rangle = \frac 1N\sum_{i=0}^{i<N}g(x_i)
\end{equation}
and the error on the result is given by:
\begin{equation}
\delta I=\sqrt{\frac{\sigma ^2}{N}}
\end{equation}
The larger the set of sample points $N$, the lower the variance and the
error. The larger $N$, the better $E[g(X)]$ approximates the correct result $%
I$.

\index{class!MCIntegrator}

Here is a program in Python:

%%% META:FILE:integrate.py
\begin{lstlisting}[caption={in file: {\ft integrate.py}}]
class MCIntegrator(MCEngine):
    def __init__(self, f, a, b):
        self.f = f
        self.a = a
        self.b = b
    def simulate_once(self):
        a, b, f = self.a, self.b, self.f
        x = a+(b-a) * random.random()
        g = (b-a) * f(x)
        return g

def main():
    s = MCIntegrator(f=lambda x: math.sin(x), a=0, b=1)
    print(s.simulate_many())

main()
\end{lstlisting}

This technique is very general and can be extended to almost any integral
assuming the integrand is smooth enough on the integration domain.

The choice (\ref{defchoice}) is not always optimal because the integrand may
be very small in some regions of the integration domain and very large in
other regions. Clearly some regions contribute more than others to the
average, and one would like to generate points with a probability mass
function that is as close as possible to the original integrand. Therefore
we should choose a $p(x)$ according to the following conditions:

\begin{itemize}
\item  $p(x)$ is very similar and proportional to $f(x)$

\item  given $F(x)=\int_{-\infty }^xp(x)dx$, $F^{-1}(x)$ can be computed
analytically.
\end{itemize}

Any choice for $p(x)$ that makes the integration algorithm converge faster with less calls to {\ft simulate\_once} is called a {\it variance reduction technique}.

\goodbreak\subsection{Two-dimensional Monte Carlo integration}

The technique described earlier can easily be extended to two-dimensional integrals:
\begin{equation}
I=\int_{{\mathfrak D}}f(x_0, x_1)dx_0dx_1
\end{equation}
where ${\mathfrak D}$ is some two-dimensional domain. We determine two functions
$g(x_0, x_1)$ and $p_0(x_0), p_1(x_1)$ such that
\begin{equation}
p_0(x_0)=0\text{ or }p_1(x_1)=0\text{ for }x\notin {\mathfrak D}
\end{equation}
and
\begin{equation}
\int p_0(x_0)p_1(x_1)dx_0dx_1=1
\end{equation}
and
\begin{equation}
g(x_0, x_1)=\frac{f(x_0, x_1)}{p_0(x_0)p_1(x_1)}
\end{equation}

We can interpret $p(x_0, x_1)$ as a probability mass function for two
independent random variables $X_0$ and $X_1$ and
\begin{equation}
E[g(X_0, X_1)]=\int g(x_0, x_1)p_0(x_0)p_1(x_1)dx=\int_{{\mathfrak D}%
}f(x_0, x_1)dx_0dx_1=I
\end{equation}
Therefore
\begin{equation}
I = E[g(X_0, X_1)] = \frac 1N\sum_{i=0}^{i<N}g(x_{i0}, x_{i1})
\end{equation}

\goodbreak\subsection{$n$-dimensional Monte Carlo integration}

The technique described earlier can also be extended to $n$-dimensional integrals
\begin{equation}
I=\int_{{\mathfrak D}}f(x_0, ..., x_{n-1})dx_0...dx_{n-1}
\end{equation}
where ${\mathfrak D}$ is some $n$-dimensional domain identified by a function $%
domain(x_0, ..., x_{n-1})$ equal to 1 if ${\bf x}=(x_0, ..., x_{n-1})$ is in the
domain, 0 otherwise. We determine two functions $g(x_0, ..., x_{n-1})$ and $%
p(x_0, ..., x_{n-1})$ such that
\begin{equation}
p(x_0, ..., x_{n-1})=0\text{ for }x\notin {\mathfrak D}
\end{equation}
and
\begin{equation}
\int p(x_0, ..., x_{n-1})dx_0...dx_{n-1}=1
\end{equation}
and
\begin{equation}
g(x_0, ..., x_{n-1})=f(x_0, ..., x_{n-1})/p(x_0, ..., x_{n-1})
\end{equation}

We can interpret $p(x_0, ..., x_{n-1})$ as a probability mass function for $n$
independent random variables $X_0$...$X_{n-1}$ and
\begin{eqnarray}
E[g(X_0, ..., X_{n-1})] &=&\int g(x_0, ..., x_{n-1})p(x_0, ..., x_{n-1})dx \\
&=&\int_{{\mathfrak D}}f(x_0, ..., x_{n-1})dx_0...dx_{n-1}=I
\end{eqnarray}
Therefore
\begin{equation}
I=E[g(X_0, .., X_{n-1})] = \frac 1N\sum_{i=0}^{i<N}g({\bf x}_i)
\end{equation}
where for every point ${\bf x}_i$ is a tuple $(x_{i0}, x_{i1}, ..., x_{i, n-1})$.

As an example, we consider the integral
\begin{equation}
I = \int_0^1 dx_0 \int_0^1 dx_1 \int_0^1 dx_2 \int_0^1 dx_3 sin(x_0+x_1+x_2+x_3)
\end{equation}

Here is the Python code:
\begin{lstlisting}
>>> class MCIntegrator(MCEngine):
...     def simulate_once(self):
...         volume =  1.0
...         while True:
...             x = [random.random() for d in range(4)]
...             if sum(xi ** 2 for xi in x)<1: break
...         return volume * self.f(x)
>>> s = MCIntegrator()
>>> s.f = lambda x: math.sin(x[0]+x[1]+x[2]+x[3])
>>> s.simulate_many()
\end{lstlisting}

\goodbreak\section{Stochastic, Markov, Wiener, and processes}

\index{stochastic process}
\index{Markov process}
\index{Wiener process}

A {\it stochastic process}~\cite{stochastic} is a random function, 
for example, a function that maps a
variable $n$ with domain $D$ into $X_n$, where $X_n$ is a random variable
with domain $R$. In practical applications, the domain $D$ over which the
function is defined can be a time interval (and the stochastic is called a
{\it time series}) or a region of space (and the stochastic process is
called a {\it random field}). Familiar examples of time series include {\it %
random walks}~\cite{rwalk}; stock market and exchange rate fluctuations; signals such as
speech, audio, and video; or medical data such as a patient"s EKG, EEG, blood
pressure, or temperature. Examples of random fields include static images, 
random topographies (landscapes), or composition variations of an
inhomogeneous material.

Let"s consider a grasshopper moving on a straight line, and let $X_n$ be the
position of the grasshopper at time $t=n\Delta _t$. Let"s also assume that at time 0, 
$X_0=0$. The position of the grasshopper at each future ($t>0$) time is unknown.
Therefore it is a random variable.

We can model the movements of the grasshopper as follows:

\begin{equation}
X_{n+1}=X_n + \mu + \varepsilon _n\Delta _x  \label{markov1}
\end{equation}
where $\Delta _x$ is a fixed step and $\varepsilon _n$ is a random variable
whose distribution depends on the model; $\mu$ is a constant drift term
(think of wind pushing the grasshopper in one direction).
It is clear that $X_{n+1}$ only
depends on $X_n$ and $\varepsilon _n$; therefore the probability distribution
of $X_{n+1}$ only depends on $X_n$ and the probability distribution of $%
\varepsilon _n$, but it does not depend on the past history of the grasshopper"s movements at
times $t<n\Delta _t$. We can write the statement by saying that
\begin{equation}
\textrm{Prob}(X_{n+1}=x|\{X_i\}\text{ for }i\leq n)=\textrm{Prob}(X_{n+1}=x|X_n)  \label{markov2}
\end{equation}

A process in which the probability distribution of its future state only
depends on the present state and not on the past is called a
{\it Markov process}~\cite{markov}.

To complete our model, we need to make additional assumptions about the
probability distribution of $\varepsilon _n$. We consider the two following cases:

\begin{itemize}
\item  $\varepsilon _n$ is a random variable with a Bernoulli distribution ($%
\varepsilon _n=+1$ with probability $p$ and $\varepsilon _n=-1$ with
probability $1-p$).

\item  $\varepsilon _n$ is a random variable with a normal (Gaussian)
distribution with probability mass function $p(\varepsilon
)=e^{-\varepsilon ^2/2}$. Notice that the previous case (Bernoulli) is equivalent to this case (Gaussian) over long time intervals because the sum of many independent Bernoulli variables approaches a Gaussian distribution.
\end{itemize}

A continuous time stochastic process (when
$\varepsilon _n$ is a continuous random number)
is called a {\it Wiener process}~\cite{wiener}.

The specific case when $\varepsilon _n$ is a Gaussian random variable is called an {\it Ito process}~\cite{ito}. An Ito process is also a Wiener process.

\goodbreak\subsection{Discrete random walk (Bernoulli process)}
\index{random walk}
\index{Bernoulli process}

Here we assume a discrete  random walk: $\varepsilon _n$ equal to
$+1$ with probability $p$ and equal to $-1$ with probability $1-p.$ We
consider discrete time intervals of equal length $\Delta _t$; at each time
step, if $\varepsilon _n=+1$, the grasshopper moves forward one unit ($\Delta _x$)
with probability $p$, and if $\varepsilon _n=-1$, he moves backward one
unit ($-\Delta _x$) with probability $1-p$.

For a total $n$ steps, the probability of moving $n_{+}$ steps in a positive
direction and $n_{-}=n-n_{+}$ in a negative direction is given by
\begin{equation}
\frac{n!}{n_{+}!(n-n_{+})!}p^{n_{+}}(1-p)^{n-n_{+}}
\end{equation}

The probability of going from $a=0$ to $b=k\Delta _x>0$ in a time $t=n\Delta
_t>0$ corresponds to the case when
\begin{eqnarray}
n &=&n_{+}+n_i \\
k &=&n_{+}-n_{-}
\end{eqnarray}
that solved in $n_{+}$ gives $n_{+}=(n+k)/2$, and therefore the probability
of going from $0$ to $k$ in time $t=n\Delta _t$ is given by
\begin{equation}
\textrm{Prob}(n, k)=\frac{n!}{((n+k)/2)!((n-k)/2)!}p^{(n+k)/2}(1-p)^{(n-k)/2}
\end{equation}

Note that $n+k$ has to be even, otherwise it is not possible for the
grasshopper to reach $k\Delta _x$ in exactly $n$ steps.

For large $n$, the following distribution in $k/n$ tends to a Gaussian distribution.

\goodbreak\subsection{Random walk: Ito process}
\index{Ito process}

Let"s assume an Ito process for our random walk: $\varepsilon _n$ is normally
(Gaussian) distributed. We consider discrete time intervals of equal length $%
\Delta _t$, at each time step if $\varepsilon _n=\varepsilon $ with
probability mass function $p(\varepsilon )=e^{-\varepsilon ^2/2}$. It turns
out that eq.(\ref{markov1}) gives
\begin{equation}
X_n = n \mu + \Delta _x\sum_{i=0}^{i<n}\varepsilon _i
\end{equation}
Therefore the location of the random walker at time $t=n\Delta _t$ is given
by the sum of $n$ normal (Gaussian) random variables:
\begin{equation}
p(X_n)=\frac 1{\sqrt{2\pi n\Delta _x^2}}e^{-(X_n - n\mu)^2/(2n\Delta _x^2)}
\end{equation}
Notice how the mean and the variance of $X_n$ are both proportional
to $n$, whereas the standard deviation is proportional to $\sqrt{n}$.

\begin{eqnarray}
\textrm{Prob}(a &\leq &X_n\leq b)=\frac 1{\sqrt{2\pi n\Delta _x^2}}\int_a^be^{-(X_n - n\mu)^2/(2n%
\Delta _x^2)}dx \\
&=&\frac 1{\sqrt{2\pi }}\int_{(a-n\mu)/(\sqrt{n}\Delta _x)}^{(b-n\mu)/(\sqrt{n}\Delta
_x)}e^{-x^2/2}dx \\
&=&\textrm{erf}(\frac {b-n\mu}{\sqrt{n}\Delta _x})-\textrm{erf}(\frac {a-n\mu}{\sqrt{n}\Delta
_x})
\end{eqnarray}

\goodbreak\section{Option pricing}
\index{Options}

A European call option is a contract that depends on an asset $S$. The contract gives the buyer of the contract the right (the option) to buy $S$ at a fixed price $A$ some time in the future, even if the actual price $S$ may be different. The actual current price of the asset is called the {\it spot price}. The buyer of the option hopes that the price of the asset, $S_t$, will exceed $A$, so that he will be able to buy it at a discount, sell it at market price, and make a profit. The seller of the option hopes this does not happen, so he earns the full sale price. For the buyer of the option, the worst case scenario is not to be able to recover the price paid for the option, but there is no best case because, hypothetically, he can make an arbitrarily large profit. For the seller, it is the opposite. He has an unlimited liability.

In practice, a call option allows a buyer to sell risk (the risk of the price of $S$ going up) to the seller. He pays a price for it, the cost of the option. This is a form of insurance. There are two types of people who trade options: those who are willing to pay to get rid of risk (because they need the underlying asset and want it at a guaranteed price) and those who simply speculate (buy risk and sell insurance). On average, speculators make money because, if they sell many options, risk averages out, and they collect the premiums (the cost of the options).

The European option has a term or expiration, $\tau$. It can only be exercised at expiration. The amount $A$ is called the {\it strike price}.

The value at expiration of a European call option is
\begin{equation}
\max (S_\tau -A, 0)
\end{equation}

Its present value is therefore

\begin{equation}
\max (S_\tau -A, 0) e^{-r\tau}
\end{equation}

where $r$ is the risk-free interest rate. This value corresponds to how much we would have to borrow today from a bank so that we can repay the bank at time $\tau$ with the profit from the option.

All our knowledge about the future spot price $x=S_\tau $ of the underlying
asset can be summarized into a probability mass function $p_\tau (x)$. Under
the assumption that $p_\tau (x)$ is known to both the buyer and the seller
of the option, it has to be that the averaged net present value of the
option is zero for any of the two parties to want to enter into the contract.
Therefore
\begin{equation}
C_{call}=e^{-r\tau }\int_{-\infty }^{+\infty }\max (x-A, 0)p_\tau (x)dx
\label{call_option}
\end{equation}


Similarly, we can perform the same computations for a put option. A put option gives the buyer the option to sell the asset on a given day at a fixed price. This is an insurance against the price going down instead of going up. The value of this option at expiration is

\begin{equation}
\max (A-S_\tau, 0)
\end{equation}

and its pricing formula is

\begin{equation}
C_{put}=e^{-r\tau }\int_{-\infty }^{+\infty }\max (A-x, 0)p_\tau (x)dx
\label{put_option}
\end{equation}

Also notice that $C_{call}-C_{put} = S_0 - A e^{-r\tau }$.
This relation is called the {\it call-put parity}.

Our goal is to model $p_\tau(x)$, the distribution of possible prices for the underlying asset at expiration of the option, and compute the preceding integrals using Monte Carlo.

\goodbreak\subsection{Pricing European options: Binomial tree}
\index{binomial tree}

To price an option, we need to know $p_\tau (S_\tau )$. This means we need to
know something about the future behavior of the price $S_\tau $ of the
underlying asset $S$ (a stock, an index, or something else). In absence of
other information (crystal ball or illegal insider"s information), one may
try to gather information from a statistical analysis of the past historic
data combined with a model of how the price $S_\tau $ evolves as a function of
time. The most typical model is the binomial model, which is a Wiener
process. We assume that the time evolution of the price of the asset $X$ is a
stochastic process similar to a random walk. We divide time into
intervals of size $\Delta _t$, and we assume that in each time interval $\tau
=n\Delta _t$, the variation in the asset price is
\begin{eqnarray}
S_{n+1} &=&S_nu\text{ with probability }p \\
S_{n+1} &=&S_nd\text{ with probability }1-p
\end{eqnarray}
where $u>1$ and $0<d<1$ are measures for historic data. It follows that for $%
\tau =n\Delta _t$, the probability that the spot price of the asset at
expiration is $S_uu^id^{n-i}$ is given by

\begin{equation}
\textrm{Prob}(S_\tau =S_uu^id^{n-i})=\binom nip^i(1-p)^{n-i}
\end{equation}
and therefore
\begin{equation}
C_{call}=e^{-r\tau }\frac 1n\sum_{i=0}^{i\leq n}\binom nip^i(1-p)^{n-i}\max
(S_uu^id^{n-i}-A, 0)  \label{bincall}
\end{equation}
and
\begin{equation}
C_{put}=e^{-r\tau }\frac 1n\sum_{i=0}^{i\leq n}\binom nip^i(1-p)^{n-i}\max
(A-S_uu^id^{n-i}, 0)  \label{binput}
\end{equation}

The parameters of this model are $u, d$ and $p$, and they must be determined
from historical data. For example, 

\begin{eqnarray}
p &=& \frac{e^{r\Delta_t} - d}{u-d} \\
u &=& e^{\sigma\sqrt{\Delta_t}} \\
d &=& e^{-\sigma\sqrt{\Delta_t}}
\end{eqnarray}

where $\Delta_t$ is the length of the time interval, $r$ is the risk-free rate, and $\sigma$ is the volatility of the asset, that is, the standard deviation of the log returns.

Here is a Python code to simulate an asset price using a binomial tree:
\begin{lstlisting}
def BinomialSimulation(S0, u, d, p, n):
    data=[]
    S=S0
    for i in range(n):
        data.append(S)
        if uniform()<p:
            S=u * S
        else:
            S=d * S
    return data
\end{lstlisting}

The function takes the present spot value, $S_0$, of the asset, the values
of $u, d$ and $p$, and the number of simulation steps and returns a list
containing the simulated evolution of the stock price. Note that because of
the exact formulas, eqs.(\ref{bincall}) and (\ref{binput}), one does not need
to perform a simulation unless the underlying asset is a stock that pays
dividends or we want to include some other variable in the model.

This method works fine for European call options, but the method is not easy to
generalize to other options, when its depends on the path of
the asset (e.g., the asset is a stock that pays dividends). Moreover, 
to increase precision, one has to decrease $\Delta _t$ or redo the
computation from the beginning.

The Monte Carlo method that we see next is slower in the simple cases but is
more general and therefore more powerful.

\goodbreak\subsection{Pricing European options: Monte Carlo}

Here we adopt the Black--Scholes model assumptions.
We assume that the time evolution of the price of the asset $X$ is
a stochastic process similar to a random walk~\cite{shreve}. We divide time into
intervals of size $\Delta _t$, and we assume that in each time interval $%
t=n\Delta _t$, the log return is a Gaussian random variable:
\begin{equation}
\log \frac{S_{n+1}}{S_n} = \textrm{gauss}(\mu\Delta_t, \sigma\sqrt{\Delta_t}) \label{BS}
\end{equation}

There are three parameters in the preceding equation:

\begin{itemize}
\item  $\Delta _t$ is the time step we use in our discretization. $\Delta _t$
is not a physical parameter; it has nothing to do with the asset. It has to
do with the precision of our computation. Let"s assume that $\Delta _t=1$ day.

\item  $\mu $ is a drift term, and it represents the expected rate of return
of the asset over a time scale of one year. It is usually set equal to the risk-free rate.

\item  $\sigma $ is called volatility, and it represents the number of
stochastic fluctuations of the asset over a time interval of one year.
\end{itemize}

Notice that this model is equivalent to the previous binomial model for large time intervals, in the same sense as the binomial distribution for large values of $n$ approximates the Gaussian distribution. For large $T$, converge to the same result.

Notice how our assumption that log-return is Gaussian is different and not compatible with Markowitz"s assumption of modern portfolio theory (the arithmetic return is Gaussian). In fact, log returns and arithmetic returns cannot both be Gaussian. It is therefore incorrect to optimize a portfolio using MPT when the portfolio includes options priced using Black--Scholes. The price of an individual asset cannot be negative, therefore its arithmetic return cannot be negative and it cannot be Gaussian. Conversely, a portfolio that includes both short and long positions (the holder is the buyer and seller of options) can have negative value. A change of sign in a portfolio is not compatible with the Gaussian log-return assumption.

If we are pricing a European call option, we are only interested in $S_T$ and not in $S_t$ for $0<t<T$; therefore we can choose $\Delta_t = T$. In this case, we obtain

\begin{equation}
S_T = S_0 exp(r_T)
\end{equation}

and

\begin{equation}
p(r_T) \propto \exp\left(-\frac{(r_T-\mu T)^2}{2\sigma^2 T}\right)
\end{equation}

This allows us to write the following:

%%% META:FILE:options.py
\begin{lstlisting}[caption={in file: {\ft options.py}}]
from nlib import * 

class EuropeanCallOptionPricer(MCEngine):
    def simulate_once(self):
        T = self.time_to_expiration
        S = self.spot_price
        R_T = random.gauss(self.mu * T, self.sigma * sqrt(T))
        S_T = S * exp(r_T)
        payoff = max(S_T-self.strike, 0)
        return self.present_value(payoff)

    def present_value(self, payoff):
        daily_return = self.risk_free_rate/250
        return payoff * exp(-daily_return * self.time_to_expiration)

def main():
    pricer = EuropeanCallOptionPricer()
     # parameters of the underlying
    pricer.spot_price = 100  # dollars
    pricer.mu = 0.12/250  # daily drift term
    pricer.sigma = 0.30/sqrt(250)  # daily variance
     # parameters of the option
    pricer.strike = 110  # dollars
    pricer.time_to_expiration = 90  # days
     # parameters of the market
    pricer.risk_free_rate = 0.05  # 5% annual return

    result = pricer.simulate_many(ap=0.01, rp=0.01)  # precision: 1c or 1%
    print(result)

main()
\end{lstlisting}

\goodbreak\subsection{Pricing any option with Monte Carlo}

An option is a contract, and one can write a contract with many different clauses. Each of them can be implemented into an algorithm. Yet we can group them into three different categories:
\begin{itemize}
\item Non-path-dependent: They depend on the price of the underlying asset at expiration but not on the intermediate prices of the asset (path).
\item Weakly path-dependent: They depend on the price of the underlying asset and events that may happen to the price before expiration, but they do not depend on when the events exactly happen.
\item Strongly path-dependent: They depend on the details of the time variation of price of the underlying asset before expiration.
\end{itemize}

 Because non-path-dependent options do not depend on details, it is often possible to find approximate analytical formulas for pricing the option. For weakly path-dependent options, usually the binomial tree approach of the previous section is a preferable approach. The Monte Carlo approach applies to the general case, for example, that of strongly path-dependent options.

We will use our {\ft MCEngine} to implement a generic option pricer.

First we need to recognize the following:\index{payoff}

\begin{itemize}
\item  The value of an option at expiration is defined by a payoff function
$f(x)$ of the spot price of the asset at the expiration date. The fact that
a call option has payoff $f(x)=\max (x-A, 0)$ is a convention that defined the European call option.
A different type of option will have a different payoff function $f(x)$.

\item  The more accurately we model the underlying asset, the more accurate will be the computed value of the option. Some options are more sensitive than others to our modeling details.
\end{itemize}

Note one never model the option. One only model the underlying asset. The option payoff is given. We only choose the most efficient algorithm based on the model and the option:

%%% META:FILE:options.py
\begin{lstlisting}[caption={in file: {\ft options.py}}]
from nlib import * 

class GenericOptionPricer(MCEngine):
    def simulate_once(self):
        S = self.spot_price
        path = [S]
        for t in range(self.time_to_expiration):
            r = self.model(dt=1.0)
            S = S * exp(r)
            path.append(S)
        return self.present_value(self.payoff(path))

    def model(self, dt=1.0):
        return random.gauss(self.mu * dt, self.sigma * sqrt(dt))

    def present_value(self, payoff):
        daily_return = self.risk_free_rate/250
        return payoff * exp(-daily_return * self.time_to_expiration)

    def payoff_european_call(self, path):
        return max(path[-1]-self.strike, 0)
    def payoff_european_put(self, path):
        return max(path[-1]-self.strike, 0)
    def payoff_exotic_call(self, path):
        last_5_days = path[-5]
        mean_last_5_days = sum(last_5_days)/len(last_5_days)
        return max(mean_last_5_days-self.strike, 0)

def main():
    pricer = GenericOptionPricer()
     # parameters of the underlying
    pricer.spot_price = 100  # dollars
    pricer.mu = 0.12/250  # daily drift term
    pricer.sigma = 0.30/sqrt(250)  # daily variance
     # parameters of the option
    pricer.strike = 110  # dollars
    pricer.time_to_expiration = 90  # days
    pricer.payoff = pricer.payoff_european_call
     # parameters of the market
    pricer.risk_free_rate = 0.05  # 5% annual return

    result = pricer.simulate_many(ap=0.01, rp=0.01)  # precision: 1c or 1%
    print(result)

main()
\end{lstlisting}

This code allows us to price any option simply by changing the payoff function.

One can also change the model for the underlying using different assumptions. For example, a possible choice is that of including a model for market crashes, and on random days, separated by intervals given by the exponential distribution, assume a negative jump that follows the Pareto distribution (similar to the losses in our previous risk model). Of course, a change of the model requires a recalibration of the parameters.

\begin{figure}[ht]
\centering\includegraphics[width=4in]{images/option.png}
\caption{Price for a European call option for different spot prices and different values of $\sigma$.\label{options}}
\end{figure}

\section{Markov chain Monte Carlo (MCMC) and Metropolis}
\index{Markov chain}
\index{Metropolis algorithm}

Until this point, all-out simulations were based on independent random
variables. This means that we were able to generate each random number
independently of the others because all the random variables were
uncorrelated. There are cases when we have the following problem.

We have to generate ${\bf x}=x_0, x_1, ..., x_{n-1}$, where $x_0, x_1, ..., x_{n-1}$
are $n$ correlated random variables whose probability mass function
\begin{equation}
p({\bf x})=p(x_0, x_1, ..., x_{n-1})
\end{equation}
cannot be factored, as in $p(x_0, x_1, ..., x_{n-1})=p(x_0)p(x_1)...p(x_{n-1})$. Consider for example the simple case of generating two random numbers $x_0$
and $x_1$ both in $[0, 1]$ with probability mass function $%
p(x_0, x_1)=6(x_0-x_1)^2$ (note that $\int_0^1\int_0^16p(x_0, x_1)dx_0dx_1=1$, 
as it should be).

In the case where each of the $x_i$ has a Gaussian distribution and the only dependence between $x_i$ and $x_j$ is their correlation, the solution was already examined in a previous section about the Cholesky algorithm. Here we examine the most general case.

The Metropolis algorithm provides a general and simpler solution to this problem. It is not always the most efficient, but more sophisticated algorithms are nothing but refinements and extensions of its simple idea.

Let"s formulate the problem once more: we want to generate ${\bf x}%
=x_0, x_1, ..., x_{n-1}$ where $x_0, x_1, ..., x_{n-1}$ are $n$ correlated random
variables whose probability mass function is given by
\begin{equation}
p({\bf x})=p(x_0, x_1, ..., x_{n-1})
\end{equation}

The procedure works as follows:

\begin{description}
\item[1]  Start with a set of independent random numbers ${\bf x}%
^{(0)}=(x_0^{(0)}, x_1^{(0)}, ..., x_{n-1}^{(0)})$ in the domain.

\item[2]  Generate another set of independent random numbers ${\bf x}%
^{(i+1)}=(x_0^{(i+1)}, x_1^{(i+1)}, ..., x_{n-1}^{(i+1)})$ in the domain. This can be done by an arbitrary random function $Q({\bf x}^{(i)})$. The only requirement for this function $Q$ is that the probability of moving from a current point $x$ to a new point $y$ be the same as that of moving from a current point $y$ to a new point $x$.

\item[3]  Generate a uniform random number $z$.

\item[4]  If $p({\bf x}^{(i+1)})/p({\bf x}^{(i)})<z$, then ${\bf x}^{(i+1)}=%
{\bf x}^{(i)}$.

\item[5]  Go back to step 2.
\end{description}

The set of random numbers ${\bf x}^{(i)}$ generated in this way for large
values of $i$ will have a probability mass function given by $p({\bf x})$.

Here is a possible implementation in Python:
\begin{lstlisting}
def metropolis(p, q, x=None):
    while True:
        x_old=x
        x = q(x)
        if p(x)/p(x_old)<random.random()
            x=x_old
        yield x

def P(x):
    return 6.0 * (x[0]-x[1]) ** 2

def Q(x):
    return [random.random(), random.random()]

for i, x in enumerate(metropolis(P, Q)):
    print(x)
    if i == 100: break
\end{lstlisting}

In this example, {\ft Q} is the function that generates random points in the domain (in the example, $[0, 1]\times[0, 1]$), and ${\ft P}$ is an example probability $p(x) = 6(x_0-x_1)^2$. Notice we used the Python {\ft yield} function instead of {\ft return}. This means the function is a generator and we can loop over its returned (yielded) values without having to generate all of them at once. They are generated as needed.

\index{decorrelation}

Notice that the Metropolis algorithm can generate (and will generate) repeated values. This is because the next random vector $x$ is highly correlated with the previous vector. For this reason, it is often necessary to de-correlate metropolis values by skipping some of them:

\begin{lstlisting}
def metropolis_decorrelate(p, q, x=None, ds=100):
    k = 0
    for x in metropolis(p, q, x):
        k += 1
        if k % ds == ds-1:
             yield x
\end{lstlisting}

The value of {\ft ds} must be fixed empirically. The value of {\ft ds} which is large enough to make the next vector independent from the previous one is called {\it decorrelation length}. This generator works as the previous one. For example:

\begin{lstlisting}
for i, x in enumerate(metropolis_decorrelate(P, Q)):
    print(x)
    if i == 100: break
\end{lstlisting}


\subsection{The Ising model}
\index{Ising model}

A typical example of application of the Metropolis is the Ising model. This model describes a spin system, for example, a ferromagnet. A spin system consists of a regular crystalline structure, and each vertex is an atom. Each atom is a small magnet, and its magnetic orientation can be +1 or $-$1. Each atom interacts with the external magnetic field and with the magnetic field of its six neighbors (think about the six faces of a cube). We use the index $i$ to label an atom and $s_i$ its spin.

The entire system has a total energy given by

\begin{equation}
E(s) = - \sum_i s_i h - \sum_{ij|dist_{ij}=1} s_i s_j
\end{equation}

where $h$ is the external magnetic field, the first sum is over all spin sites, and the second is about all couples of next neighbor sites. In the absence of spin-spin interaction, only the first term contributes, and the energy is lower when the direction of the $s_i$ (their sign) is the same as $h$. In absence of $h$, only the second term contributes. The contribution to each couple of spins is positive if their sign is the opposite, and negative otherwise.

In the absence of external forces, each system evolves toward the state of minimum energy, and therefore, for a spin system, each spin tends to align itself in the same direction as its neighbors and in the same direction as the external field $h$.

Things change when we turn on heat. Feeding energy to the system makes the atoms vibrate and the spins randomly flip. The higher the temperature, the more they randomly flip.

The probability of finding the system in a given state $s$ at a given temperature $T$ is given by the Boltzmann distribution:

\begin{equation}
p(s) = \exp\left(-\frac{E(s)}{KT}\right)
\end{equation}
where $K$ is the Boltzmann constant.

We can now use the Metropolis algorithm to generate possible states of the system $s$ compatible with a given temperature $T$ and measure the effects on the average magnetization (the average spin) as a function of $T$ and possibly an external field $h$.

Also notice that in the case of the Boltzmann distribution, 

\begin{equation}
\frac{p(s")}{p(s)} = exp\left(\frac{E(s)-E(s")}{KT}\right)
\end{equation}

only depends on the change in energy. The Metropolis algorithm gives us the freedom to choose a function {\ft Q} that changes the state of the system and depends on the current state. We can choose such a function so that we only try to flip one spin at a time. In this case, the {\ft P} algorithm simplifies because we no longer need to compute the total energy of the system at each iteration, but only the variation of energy due to the flipping of that one spin.

Here is the code for a three-dimensional spin system:

\index{class!Ising}

%%% META:FILE:ising.py
\begin{lstlisting}[caption={in file: {\ft ising.py}}]
import random
import math
from nlib import Canvas, mean, sd

class Ising:
    def __init__(self, n):
        self.n = n
        self.s = [[[1 for x in range(n)] for y in range(n)]
                  for z in range(n)]
        self.magnetization = n ** 3

    def __getitem__(self, point):
        n = self.n
        x, y, z = point
        return self.s[(x+n)%n][(y+n)%n][(z+n)%n]

    def __setitem__(self, point, value):
        n = self.n
        x, y, z = point
        self.s[(x+n)%n][(y+n)%n][(z+n)%n] = value

    def step(self, t, h):
        n = self.n
        x, y, z = random.randint(0, n-1), random.randint(0, n-1), random.randint(0, n-1)
        neighbors = [(x-1, y, z), (x+1, y, z), (x, y-1, z), (x, y+1, z), (x, y, z-1), (x, y, z+1)]
        dE = -2.0 * self[x, y, z] * (h+sum(self[xn, yn, zn] for xn, yn, zn in neighbors))
        if dE > t * math.log(random.random()):
            self[x, y, z] = -self[x, y, z]
            self.magnetization += 2 * self[x, y, z]
        return self.magnetization

def simulate(steps=100):
    ising = Ising(n=10)
    data = {}
    for h in range(0, 11):  # external magnetic field
        data[h] = []
        for t in range(1, 11):  # temperature, in units of K
            m = [ising.step(t=t, h=h) for k in range(steps)]
            mu = mean(m)  # average magnetization
            sigma = sd(m)
            data[h].append((t, mu, sigma))
    return data

def main(name="ising.png"):
    data = simulate(steps = 10000)
    canvas = Canvas(xlab="temperature", ylab="magnetization")
    for h in data:
        color = "#%.2x0000" % (h * 25)
        canvas.errorbar(data[h]).plot(data[h], color=color)
    canvas.save(name)

main()
\end{lstlisting}


Fig.~\ref{ising-mag} shows how the spins tend to align in the direction of the external magnetic field, but the larger the temperature (left to right), the more random they are, and the average magnetization tends to zero. The higher the external magnetic field (bottom to top curves), the longer it takes for the transition from order (aligned spins) to chaos (random spins).

\begin{figure}[ht]
\centering\includegraphics[width=4in]{images/ising.png}
\caption{Average magnetization as a function of the temperature for a spin system.\label{ising-mag}}
\end{figure}

Fig.~\ref{ising-state} shows the two-dimensional section of some random three-dimensional states for different values of the temperature. One can clearly see that the lower the temperature, the more the spins are aligned, and the higher the temperature, the more random they are.

\begin{figure}[ht]
\centering\includegraphics[width=4in]{images/ising2.png}
\caption{Random Ising states (2D section of 3D) for different temperatures.\label{ising-state}}
\end{figure}

\section{Simulated annealing}
\index{simulate annealing}\index{protein folding}

Simulated annealing is an application of Monte Carlo to solve optimization problems. It is best understood within the context of the Ising model. When the temperature is lowered, the system tends toward the state of minimum energy. At high temperature, the system fluctuates randomly and moves in the space of all possible states. This behavior is not specific to the Ising model. Hence, for any system for which we can define an energy, we can find its minimum energy state, by starting in a random state and slowly lowering the temperature as we evolve the simulation. The system will find a minimum. There may be more than one minimum, and one may need to repeat the procedure multiple times from different initial random states and compare the solutions. This process takes the name of annealing in analogy with the industrial process for removing impurities from metals: heat, cool slowly, repeat.

We can apply this process to any system for which we want to minimize a function $f(x)$ of multiple variables. We just have to think of $x$ as the state $s$ and of $f$ as the energy $E$. This analogy is purely semantic because the quantity we want to minimize is not necessarily an energy in the physical sense.

Simulated annealing does not assume the function is differentiable or continuous in its variables.

\subsection{Protein folding}

In the following we apply simulated annealing to the problem of folding of a protein.
A protein is a sequence of amino-acids. It is normally unfolded, and amino-acids are on a line. When placed in water, it folds. This is because some amino-acids are hydrophobic (repel water) and some are hydrophilic (like contact with water), therefore the protein tries to acquire a three-dimensional shape that minimizes the surface of hydrophobic amino-acids in contact with water~\cite{folding}. This is represented graphically in fig.~\ref{folding}.

\begin{figure}[ht]
\centering\includegraphics[width=2in]{images/folding.png}
\caption{Schematic example of protein folding. The white circles are hydrophilic amino-acids. The black ones are hydrophobic.\label{folding}}
\end{figure}

Here we assume only two types of amino-acids (H for hydrophobic and P for hydrophilic), and we assume each amino acid is a cube, that all cubes have the same size, and that each two consecutive amino-acids are connected at a face. These assumptions greatly simplify the problem because they limit the possible solid angles to six possible values (0: up, 1: down, 2: right, 3: left, 4: front, 5: back). Our goal is arranging the cubes to minimize the number of faces of hydrophobic cubes that are exposed to water:

\index{protein folding}\index{class!Protein}

%%% META:FILE:folding.py
\begin{lstlisting}[caption={in file: {\ft folding.py}}]
import random
import math
import copy
from nlib import * 

class Protein:

    moves = {0:(lambda x, y, z: (x+1, y, z)), 
             1:(lambda x, y, z: (x-1, y, z)), 
             2:(lambda x, y, z: (x, y+1, z)), 
             3:(lambda x, y, z: (x, y-1, z)), 
             4:(lambda x, y, z: (x, y, z+1)), 
             5:(lambda x, y, z: (x, y, z-1))}

    def __init__(self, aminoacids):
        self.aminoacids = aminoacids
        self.angles = [0] * (len(aminoacids)-1)
        self.folding = self.compute_folding(self.angles)
        self.energy = self.compute_energy(self.folding)

    def compute_folding(self, angles):
        folding = {}
        x, y, z = 0, 0, 0
        k = 0
        folding[x, y, z] = self.aminoacids[k]
        for angle in angles:
            k += 1
            xn, yn, zn = self.moves[angle](x, y, z)
            if (xn, yn, zn) in folding: return None  # impossible folding
            folding[xn, yn, zn] = self.aminoacids[k]
            x, y, z = xn, yn, zn
        return folding

    def compute_energy(self, folding):
        E = 0
        for x, y, z in folding:
            aminoacid = folding[x, y, z]
            if aminoacid == "H":
                for face in range(6):
                    if not self.moves[face](x, y, z) in folding:
                        E = E + 1
        return E

    def fold(self, t):
        while True:
            new_angles = copy.copy(self.angles)
            n = random.randint(1, len(self.aminoacids)-2)
            new_angles[n] = random.randint(0, 5)
            new_folding = self.compute_folding(new_angles)
            if new_folding: break  # found a valid folding
        new_energy = self.compute_energy(new_folding)
        if (self.energy-new_energy) > t * math.log(random.random()):
            self.angles = new_angles
            self.folding = new_folding
            self.energy = new_energy
        return self.energy

def main():
    aminoacids = ''.join(random.choice("HP") for k in range(20))
    protein = Protein(aminoacids)
    t = 10.0
    while t>1e-5:
        protein.fold(t = t)
        print(protein.energy, protein.angles)
        t = t * 0.99  # cool

main()
\end{lstlisting}

The {\ft moves} dictionary is a dictionary of functions. For each solid angle (0--5), {\ft moves[angle]} is a function that maps {\ft x, y, z}, the coordinates of an amino acid, to the coordinates of the cube at that solid angle.

The annealing procedure is performed in the {\ft main} function. The {\ft fold} procedure is the same step as the Metropolis step. The purpose of the {\ft while} loop in the {\ft fold} function is to find a valid fold for the accept--reject step. Some folds are invalid because they are not physical and would require two amino-acids to occupy the same portion of space. When this happens, the {\ft compute\_folding} method returns {\ft None}, indicating that one must try a different folding.

\chapter{Parallel Algorithms}
\index{parallel algorithms}

Consider a program that performs the following computation:
\begin{lstlisting}
y = f(x)
z = g(x)
\end{lstlisting}
In this example, the function $g(x)$ does not depend on the result of the function $f(x)$, and therefore the two functions could be computed independently and in parallel.

Often large problems can be divided into smaller computational problems, which can be solved concurrently (``in parallel'') using different processing units (CPUs, cores). This is called {\it parallel computing}. Algorithms designed to work in parallel are called {\it parallel algorithms}.

In this chapter, we will refer to a processing unit as a node and to the code running on a node as a process. A parallel program consists of many processes running on as many nodes. It is possible for multiple processes to run on one and the same computing unit (node) because of the multitasking capabilities of modern CPUs, but that is not true parallel computing. We will use an emulator, {\ft PSim}, which does exactly that.

Programs can be parallelized at many levels: bit level, instruction level, data, and task parallelism. Bit-level parallelism is usually implemented in hardware. Instruction-level parallelism is also implemented in hardware in modern multi-pipeline CPUs.  Data parallelism is usually referred to as SIMD. Task parallelism is also referred to as MIMD.

Historically, parallelism was found in applications in high-performance computing, but today it is employed in many devices, including common cell phones. The reason is heat dissipation. It is getting harder and harder to improve speed by increasing CPU frequency because there is a physical limit to how much we can cool the CPU. So the recent trend is keeping frequency constant and increasing the number of processing units on the same chip.

Parallel architectures are classified according to the level at which the hardware supports parallelism, with multicore and multiprocessor computers having multiple processing elements within a single machine, while clusters, MPPs, and grids use multiple computers to work on the same task. Specialized parallel computer architectures are sometimes used alongside traditional processors for accelerating specific tasks.

Optimizing an algorithm to run on a parallel architecture is not an easy task. Details depend on the type of parallelism and details of the architecture.

In this chapter, we will learn how to classify architectures, compute running times of parallel algorithms, and measure their performance and scaling.

We will learn how to write parallel programs using standard programming patterns, and we will use them as building blocks for more complex algorithms.

For some parts of this chapter, we will use a simulator called {\ft PSim}, which is written in Python. Its performances will only scale on multicore machines, but it will allow us to emulate various network topologies.

\section{Parallel architectures}

\goodbreak\subsection{Flynn taxonomy}

\index{parallel architectures}\index{Flynn classification}\index{SISD}\index{SIMD}\index{MIMD}


Parallel computer architecture classifications are known as Flynn"s taxonomy~\cite{flynn} and are due to the work of Michael J. Flynn in 1966.

Flynn identified the following architectures:

\begin{itemize}
\item {\bf Single instruction, single data stream (SISD)}

A sequential computer that exploits no parallelism in either the instruction or data streams. A single control unit (CU) fetches a single instruction stream (IS) from memory. The CU then generates appropriate control signals to direct single processing elements (PE) to operate on a single data stream (DS), for example, one operation at a time.

Examples of SISD architecture are the traditional uniprocessor machines like a PC (currently manufactured PCs have multiple processors) or old mainframes.

\item {\bf Single instruction, multiple data streams (SIMD)}
A  computer  that   exploits   multiple  data   streams   against  a  single instruction stream  to perform operations that  may be naturally parallelized (e.g., an array processor or GPU).

\item {\bf Multiple instruction, single data stream (MISD)}

Multiple instructions operate on a single data stream. This is an uncommon architecture that is generally used for fault tolerance. Heterogeneous systems operate on the same data stream and must agree on the result. Examples include the now retired Space Shuttle flight control computer.

\item {\bf Multiple instruction, multiple data streams (MIMD)}
Multiple autonomous processors simultaneously executing different instructions on different data. Distributed systems are generally recognized to be MIMD architectures, either exploiting a single shared memory space (using threads) or a distributed memory space (using a message-passing protocol such as MPI).
\end{itemize}

\index{SPMD}\index{MPMD}

MIMD can be further subdivided into the following:
\begin{itemize}

\item {\bf Single program, multiple data (SPMD)}
Multiple autonomous processors simultaneously executing the same program but at independent points not synchronously (as in the SIMD case). SPMD is the most common style of parallel programming.

\item {\bf Multiple program, multiple data (MPMD)}
Multiple autonomous processors simultaneously operating at least two independent programs. Typically such systems pick one node to be the ``host'' (``the explicit host/node programming model'') or ``manager'' (the ``manager--worker'' strategy), which runs one program that farms out data to all the other nodes, which all run a second program. Those other nodes then return their results directly to the manager. The Map-Reduce pattern also falls under this category.
\end{itemize}

An embarrassingly parallel workload (or embarrassingly parallel problem) is one for which little or no effort is required to separate the problem into a number of parallel tasks. This is often the case where there exists no dependency (or communication) between those parallel tasks.

The manager--worker node strategy, when workers do not need to communicate with each other, is an example of an ``embarrassingly parallel'' problem.


\goodbreak\subsection{Network topologies}

\index{network topologies}\index{switch network}\index{bus network}\index{mesh network}\index{hypercube network}\index{tree network}

In the MIMD case, multiple copies of the same problem run concurrently (on different data subsets and branching differently, thus performing different instructions) on different processing units, and they exchange information using a network. How fast they can communicate depends on the network characteristics identified by the network topology and the latency and bandwidth of the individual links of the network.

Normally we classify network topologies based on the following taxonomy:

\begin{itemize}
\item {\bf Completely connected:}
Each node is connected by a directed link to each other node.
\item {\bf Bus topology:}
All nodes are connected to the same single cable. Each computer can therefore communicate with each other computer using one and the same bus cable. The limitation of this approach is that the communication bandwidth is limited by the bandwidth of the cable. Most bus networks only allow two machines to communicate with each other at one time (with the exception of one too many broadcast messages). While two machines communicate, the others are stuck waiting.
The bus topology is the most inexpensive but also slow and constitutes a single point of failure.
\item {\bf Switch topology (star topology):}
In local area networks with a switch topology, each computer is connected via a direct link to a central device, usually a switch, and it resembles a star. Two computers can communicate using two links (to the switch and from the switch). The central point of failure is the switch. The switch is usually intelligent and can reroute the messages from any computer to any other computer. If the switch has sufficient bandwidth, it can allow multiple computers to talk to each other at the same time. For example, for a 10 Gbit/s links and an 80 Gbit/s switch, eight computers can talk to each other (in pairs) at the same time.
\item {\bf Mesh topology:}
In a mesh topology, computers are assembled into an array (1D, 2D, etc.), and each computer is connected via a direct link to the computers immediately close (left, right, above, below, etc.). Next neighbor communication is very fast because it involves a single link and therefore low latency. For two computers not physically close to communicate, it is necessary to reroute messages. The latency is proportional to the distance in links between the computers. Some meshes do not support this kind of rerouting because the extra logic, even if unused, may be cause for extra latency. Meshes are ideal for solving numerical problems such as solving differential equations because they can be naturally mapped into this kind of topology.
\item {\bf Torus topology:}
Very similar to a mesh topology (1D, 2D, 3D, etc.), except that the network wraps around the edges. For example, in one dimension node, $i$ is connected to $(i+1) \% p$, where $p$ is the total number of nodes. A one-dimensional torus is called a {\it ring network}.
\item {\bf Tree network:}
The tree topology looks like a tree where the computer may be associated with every tree node or every leaf only. The tree links are the communication link. For a binary tree, each computer only talks to its parent and its two children nodes. The root node is special because it has no parent node.

Tree networks are ideal for global operations such as broadcasting and for sharing IO devices such as disks. If the IO device is connected to the root node, every other computer can communicate with it using only $\log p$ links (where $p$ is the number of computers connected). Moreover, each subset of a tree network is also a tree network. This makes it easy to distribute subtasks to different subsets of the same architecture.

\item{\bf Hypercube:}
This network assumes $2^d$ nodes, and each node corresponds to a vertex of a hypercube. Nodes are connected by direct links, which correspond to the edges of the hypercube. Its importance is more academical than practical, although some ideas from hypercube networks are implemented in some algorithms.
\end{itemize}

If we identify each node on the network with a unique integer number called its rank, we write explicit code to determine if two nodes $i$ and $j$ are connected for each network topology:

\index{PSim emulator}

%%% META:FILE:psim.py
\begin{lstlisting}[caption={in file: {\ft psim.py}}]
import math
import functools
import os
import pickle
import time

def BUS(i, j):
    return True

def SWITCH(i, j):
    return True

def MESH1(p):
    return lambda i, j, p=p: (i - j) ** 2 == 1

def TORUS1(p):
    return lambda i, j, p=p: (i - j + p) % p == 1 or (j - i + p) % p == 1

def MESH2(p):
    q = int(math.sqrt(p) + 0.1)
    return lambda i, j, q=q: (
        (i % q - j % q) ** 2, (i / q - j / q) ** 2) in [(1, 0), (0, 1)]

def TORUS2(p):
    q = int(math.sqrt(p) + 0.1)
    return lambda i, j, q=q: (
        ((i % q - j % q + q) % q, (i / q - j / q + q) % q)
        in [(0, 1), (1, 0)]
        or
        ((j % q - i % q + q) % q, (j / q - i / q + q) % q)
        in [(0, 1), (1, 0)]
    )

def TREE(i, j):
    return i == int((j - 1) / 2) or j == int((i - 1) / 2)
\end{lstlisting}

\goodbreak\subsection{Network characteristics}

\index{diameter of network}\index{bisection width}\index{arc connectivity}

\begin{itemize}
\item {\bf Number of links}

\item {\bf Diameter:} The max distance between any two nodes measured as a minimum number of links connecting them. Smaller diameter means smaller latency. The diameter is proportional to the maximum time it takes for a message go from one node to another.

\item {\bf Bisection width:} The minimum number of links one has to cut to turn the network into two disjoint networks. Higher bisection width means higher reliability of the network.

\item {\bf Arc connectivity:} The number of different paths (non-overlapping and of minimal length) connecting any two nodes. Higher connectivity means higher bandwidth and higher reliability.
\end{itemize}

Here are values of this parameter for each type of network:

\begin{tabular}{|l|lll|} \hline
Network              & Links & Diameter & Width \\ \hline
completely connected & $p(p-1)/2$   & $1$   & $p-1$ \\
switch               & $p$          & $2$   & $1$ \\
1D mesh              & $p-1$        & $p-1$ & $1$ \\
nD mesh              & $n(p^{\frac1n}-1)p^{\frac{n-1}n}$ & $n$ & $p^{\frac23}$ \\
1D torus             & $p$          & $\frac{p}2$ & $2$ \\
nD torus             & $np$         & $\frac{n}2 p^{\frac1n}$ & $2n$ \\
hypercube            & $\frac{p}2 \log_2 p$ & $\log_2 p$ & $log_2 p$ \\
tree                 & $p-1$        & $\log_2 p$ & $1$ \\ \hline
\end{tabular}

\begin{figure}[ht]
\centering\includegraphics[width=4in]{images/network_topologies.png}
\caption{Examples of network topologies.}
\end{figure}

Most actual supercomputers implement a variety of taxonomies and topologies simultaneously. A modern supercomputer has many nodes, each node has many CPUs, each CPU has many cores, and each core implements SIMD instructions. Each core has it own cache, each CPU has its own cache, and each node has its own memory shared by all threads running on that one node. Nodes communicate with each other using multiple networks (typically a multidimensional mesh for point-to-point communications and a tree network for global communication and general disk IO).

This makes writing parallel programs very difficult. Parallel programs must be optimized for each specific architecture.

\goodbreak\section{Parallel metrics}

\goodbreak\subsection{Latency and bandwidth}

\index{latency}\index{bandwidth}

The time it takes for a message of size $m$ (in bytes) over a wire can be broken into two components: a fixed overall time that does not depend on the size of the message, called {\it latency} (and indicated with $t_s$), and a time proportional to the message size, called {\it inverse bandwidth} (and indicated with $t_w$).

Think of a pipe of length $L$ and section $s$, and you want to pump $m$ liters of water through the pipe at velocity $v$. From the moment you start pumping, it takes $L/v$ seconds before the water starts arriving at the other end of the pipe. From that moment, it will take $m / sv$ for all the water to arrive at its destination. In this analogy, $L/v$ is the latency $t_s$, $sv$ is the bandwidth, and $t_w = 1/sv$.

The total time to send the message (or the water) is

\begin{equation}
T(m) = t_s + t_w m
\end{equation}

From now on, we will use $T_1(n)$ to refer to the nonparallel running time of an algorithm as a function of its input $m$. We will use $T_p(n)$ to refer to its running time with $p$ parallel processes.

As a practical case, in the following example, we consider a generic algorithm with the following parallel and nonparallel running times:

\begin{eqnarray}
T_1(n) &=& t_a n^2 \\
T_p(n) &=& t_a n^2 / p + 2p (t_s+t_w n/p)
\end{eqnarray}

These formulas may come from example from the problem of multiplying a matrix times a vector.

Here $t_a$ is the time to perform one elementary instruction; $t_s$ and $t_w$ are the latency and inverse bandwidth. The first term of $T_p$ is nothing but $T_1/p$, while the second term is an overhead due to communications.

Typically $t_s >> t_w >> t_a$. In the following plots, we will always assume $t_a=1$, $t_s=0.2$, and $t_w=0.1$. With these assumptions, fig.~\ref{Tp} shows how $T_p$ changes with input size and number of parallel processes. Notice that while for small $p$, $T_p$ decreases $\propto 1/p$, for large $p$, the communication overhead dominates over computation. This overhead is our example and is dominated by the latency contribution, which grows with $p$.

\begin{figure}[ht]
\centering\includegraphics[width=4in]{images/Tp.png}
\caption{$T_p$ as a function of input size $n$ and number of processes $p$.\label{Tp}}
\end{figure}

\goodbreak\subsection{Speedup}\index{speedup}

The {\it speedup} is defined as

\begin{equation}
S_p(n) = \frac{T_1(n)}{T_p(n)}
\end{equation}
where $T_1$ is the time it takes to run the algorithm on an input of size $n$ on one processing unit (e.g., node), and $T_p$ is the time it takes to run the same algorithm on the same input using $p$ nodes in parallel. Fig.~\ref{Sp} shows an example of speedup. When communication overhead dominates, speedup decreases.

\begin{figure}[ht]
\centering\includegraphics[width=4in]{images/Sp.png}
\caption{$S_p$ as a function of input size $n$ and number of processes $p$.\label{Sp}}
\end{figure}

\goodbreak\subsection{Efficiency}\index{efficiency}

The {\it efficiency} is defined as

\begin{equation}
E_p(n) = \frac{S_p(n)}{p} = \frac{T_1(n)}{p T_p(n)}
\end{equation}
Notice that in case of perfect parallelization (impossible), $T_p=T_1/p$, and therefore $E_p(n)=1$. Fig.~\ref{Ep} shows an example of efficiency. When communication overhead dominates, efficiency drops. Notice efficiency is always less than 1. We do not write parallel algorithms because they are more efficient. They are always less efficient and more costly than the nonparallel ones. We do it because we want the result sooner, and there is an economic value in it.

\begin{figure}[ht]
\centering\includegraphics[width=4in]{images/Ep.png}
\caption{$E_p$ as a function of input size $n$ and number of processes $p$.\label{Ep}}
\end{figure}

\goodbreak\subsection{Isoefficiency}\index{isoefficiency}

Given a value of efficiency that we choose as target, $E$, and a given number of nodes, $p$, we ask what is the maximum size of a problem that we can solve. The answer is found by solving $n$ the following equation:

\begin{equation}
E_p(n) = E
\end{equation}
For example $T_p$, we obtain
\begin{equation}
E_p = \frac1{1 + 2p^2(t_s + t_w n/p)/(n^2 t_a)} = E
\end{equation}
which solved in $n$ yields
\begin{equation}
n \simeq 2 \frac{t_w}{t_a} \frac{E}{1-E} p
\end{equation}
Isoefficiency curves for different values of $E$ are shown in fig.~\ref{Ip}.
For our example problem, $n$ is proportional to $p$. In general, this is not true, but $n$ is monotonic in $p$.

\begin{figure}[ht]
\centering\includegraphics[width=4in]{images/Ip.png}
\caption{Isoefficiency curves for different values of the target efficiency.\label{Ip}}
\end{figure}

\goodbreak\subsection{Cost}\index{cost of computation}

The cost of a computation is equal to the time it takes to run on each node, multiplied by the number of nodes involved in the computation:

\begin{equation}
C_p(n) = p T_p(n)
\end{equation}

Notice that in general

\begin{equation}
\frac{\textrm{d}C_p(n)}{\textrm{d}p} = \alpha T_1(n) > 0
\end{equation}

This means that for a fixed problem size $n$, the more an algorithm is parallelized, the more it costs to run it (because it gets less and less efficient).

\begin{figure}[ht]
\centering\includegraphics[width=4in]{images/Cp.png}
\caption{$C_p$ as a function of input size $n$ and a number of processes $p$.\label{Cp}}
\end{figure}

\goodbreak\subsection{Cost optimality}\index{cost optimality}

With the preceding disclaimer, we define cost optimality as the choice of $p$ (as a function of $n$), which makes the cost scale proportional to $T_1(n)$:

\begin{equation}
p T_p(n) \propto T_1(n)
\end{equation}

Or in other words, looking for the $p(n)$ such that

\begin{equation}
\lim_{n\rightarrow\infty} p(n) T_{p(n)}(n) / T_1(n) = const. \ne 0
\end{equation}

\goodbreak\subsection{Admahl"s law}\index{Admahl"s law}

Consider an algorithm that can be parallelized, but one faction $\alpha$ of its total sequential running time $\alpha T_1$ cannot be parallelized. That means that $T_p = \alpha T_1 + (1-\alpha) T_1/p$, and this yields~\cite{admhal}

\begin{equation}
S_p = \frac{1}{\alpha+(1-\alpha)/p} < \frac{1}{\alpha}
\end{equation}

Therefore the speedup is theoretically limited.

\goodbreak\section{Message passing}\index{message passing}

Consider the following Python program:
\begin{lstlisting}
def f():
    if os.fork(): print(True)
    else: print(False)
f()
\end{lstlisting}
The output of the current program is
\begin{lstlisting}
True
False
\end{lstlisting}

The function {\ft fork} creates a copy of the current process (a child). The parent process returns the ID of the child process, and the child process returns 0. Therefore the {\ft if} condition is both true and false, just on different processes.

The source of {\ft PSim} is include in the {\ft psim.py} file.

\index{PSim emulator}\index{class!PSim}\index{send}\index{recv}\index{point-to-point}

%%% META:FILE:psim.py
\begin{lstlisting}[caption={in file: {\ft psim.py}}]
class PSim(object):
    def __init__(self, p, topology=SWITCH, logfilename=None):
        """
        forks p-1 processes and creates p * p
        """
        self.logfile = logfilename and open(logfilename, "w")
        self.topology = topology
        self.log("START: creating %i parallel processes\n" % p)
        self.nprocs = p
        self.pipes = {}
        for i in range(p):
            for j in range(p):
                self.pipes[i, j] = os.pipe()
        self.rank = 0
        for i in range(1, p):
            if not os.fork():
                self.rank = i
                break
        self.log("START: done.\n")

    def log(self, message):
        """
        logs the message into self._logfile
        """
        if self.logfile != None:
            self.logfile.write(message)

    def send(self, j, data):
        """
        sends data to process #j
        """
        if not self.topology(self.rank, j):
            raise RuntimeError("topology violation")
        self._send(j, data)

    def _send(self, j, data):
        """
        sends data to process #j ignoring topology
        """
        if j < 0 or j >= self.nprocs:
            self.log("process %i: send(%i, ...) failed!\n" %
                     (self.rank, j))
            raise Exception
        self.log("process %i: send(%i, %s) starting...\n" %
                 (self.rank, j, repr(data)))
        s = pickle.dumps(data)
        os.write(self.pipes[self.rank, j][1], str.zfill(str(len(s)), 10))
        os.write(self.pipes[self.rank, j][1], s)
        self.log("process %i: send(%i, %s) success.\n" %
                 (self.rank, j, repr(data)))

    def recv(self, j):
        """
        returns the data received from process #j
        """
        if not self.topology(self.rank, j):
            raise RuntimeError("topology violation")
        return self._recv(j)

    def _recv(self, j):
        """
        returns the data received from process #j ignoring topology
        """
        if j < 0 or j >= self.nprocs:
            self.log("process %i: recv(%i) failed!\n" % (self.rank, j))
            raise RuntimeError
        self.log("process %i: recv(%i) starting...\n" % (self.rank, j))
        try:
            size = int(os.read(self.pipes[j, self.rank][0], 10))
            s = os.read(self.pipes[j, self.rank][0], size)
        except Exception as e:
            self.log("process %i: COMMUNICATION ERROR!!!\n" % (self.rank))
            raise e
        data = pickle.loads(s)
        self.log("process %i: recv(%i) done.\n" % (self.rank, j))
        return data
\end{lstlisting}

\index{communicator}

An instance of the class {\ft PSim} is an object that can be used to determine the total number of parallel processes, the rank of each running process, to send messages to other processes, and to receive messages from them. It is usually called a {\it communicator}; {\ft send} and {\ft recv} represent the simplest type of communication pattern, point-to-point communication.

A PSim program starts by importing and creating an instance of the {\ft PSim} class. The constructor takes two arguments, the number of parallel processes you want and the network topology you want to emulate. Before returning the {\ft PSim} instance, the constructor makes $p-1$ copies of the running process and creates sockets connecting each two of them. Here is a simple example in which we make two parallel processes and send a message from process 0 to process 1:

\begin{lstlisting}
from psim import * 

comm = PSim(2, SWITCH)
if comm.rank == 0:
    comm.send(1, "Hello World")
elif comm.rank == 1:
    message = comm.recv(0)
    print(message)
\end{lstlisting}

Here is a more complex example that creates $p=10$ parallel processes, and node 0 sends a message to each one of them:


\begin{lstlisting}
from psim import * 

p = 10

comm = PSim(p, SWITCH)
if comm.rank == 0:
    for other in range(1, p):
       comm.send(other, "Hello %s" % p)
else:
    message = comm.recv(0)
    print(message)
\end{lstlisting}

 Following is a more complex example that implements a parallel scalar product. The process with rank 0 makes up two vectors and distributes pieces of them to the other processes. Each process computes a part of the scalar product. Of course, the scalar product runs in linear time, and it is very inefficient to parallelize it, yet we do it for didactic purposes.

\index{parallel!scalar product}

%%% META:FILE:psim_scalar.py
\begin{lstlisting}[caption={in file: {\ft psim\_scalar.py}}]
import random
from psim import PSim

def scalar_product_test1(n, p):
    comm = PSim(p)
    h = n/p
    if comm.rank == 0:
        a = [random.random() for i in range(n)]
        b = [random.random() for i in range(n)]
        for k in range(1, p):
            comm.send(k, a[k * h:k * h+h])
            comm.send(k, b[k * h:k * h+h])
    else:
        a = comm.recv(0)
        b = comm.recv(0)
    scalar = sum(a[i] * b[i] for i in range(h))
    if comm.rank == 0:
        for k in range(1, p):
            scalar += comm.recv(k)
        print(scalar)
    else:
        comm.send(0, scalar)

scalar_product_test(10, 2)
\end{lstlisting}

Most parallel algorithms follow a similar pattern. One process has access to IO. That process reads and scatters the data. The other processes perform their part of the computation; the results are reduced (aggregated) and sent back to the root process. This pattern may be repeated by multiple functions, perhaps in loops. Different functions may handle different data structure and may have different communication patterns. The one thing that must be constant throughout the run is the number of processes because one wants to pair each process with one computing unit.

 In the following, we implement a parallel version of the {\ft mergesort}. At each step, the code splits the problem into two smaller problems. Half of the problem is solved by the process that performed the split and assigns the other half to an existing free process. When there are no more free processes, it reverts to the nonparallel {\ft mergesort} step. The {\ft merge} function here is the same as the nonparallel {\ft mergesort} of chapter 3.

\index{mergesort!parallel}

%%% META:FILE:psim_mergesort.py
\begin{lstlisting}[caption={in file: {\ft psim\_mergesort.py}}]
import random
from psim import PSim

def mergesort(A, x=0, z=None):
    if z is None: z = len(A)
    if x<z-1:
        y = int((x+z)/2)
        mergesort(A, x, y)
        mergesort(A, y, z)
        merge(A, x, y, z)

def merge(A, x, y, z):
    B, i, j = [], x, y
    while True:
        if A[i]<=A[j]:
            B.append(A[i])
            i=i+1
        else:
            B.append(A[j])
            j=j+1
        if i == y:
            while j<z:
                B.append(A[j])
                j=j+1
            break
        if j == z:
            while i<y:
                B.append(A[i])
                i=i+1
            break
    A[x:z]=B

def mergesort_test(n, p):
    comm = PSim(p)
    if comm.rank == 0:
        data = [random.random() for i in range(n)]
        comm.send(1, data[n/2:])
        mergesort(data, 0, n/2)
        data[n/2:] = comm.recv(1)
        merge(data, 0, n/2, n)
        print(data)
    else:
        data = comm.recv(0)
        mergesort(data)
        comm.send(0, data)

mergesort_test(20, 2)
\end{lstlisting}

More interesting patterns are global communication patterns implemented on top of {\ft send} and {\ft recv}. Subsequently, we discuss the most common: broadcast, scatter, collect, and reduce. Our implementation is not the most efficient, but it is the simplest. In principle, there should be a different implementation for each type of network topology to take advantage of its features.


\goodbreak\subsection{Broadcast}\index{broadcast}

The simplest type of broadcast is the one-2-all, which consists of one process (source) sending a message (value) to every other process. A more complex broadcast is when each process broadcasts a message simultaneously and each node receives the list of values ordered by the rank of the sender:

%%% META:FILE:psim.py
\begin{lstlisting}[caption={in file: {\ft psim.py}}]

    def one2all_broadcast(self, source, value):
        self.log(
            "process %i: BEGIN one2all_broadcast(%i, %s)\n"
            % (self.rank, source, repr(value))
        )
        if self.rank == source:
            for i in range(0, self.nprocs):
                if i != source:
                    self._send(i, value)
        else:
            value = self._recv(source)
        self.log(
            "process %i: END one2all_broadcast(%i, %s)\n"
            % (self.rank, source, repr(value))
        )
        return value

    def all2all_broadcast(self, value):
        self.log("process %i: BEGIN all2all_broadcast(%s)\n" %
                 (self.rank, repr(value)))
        vector = self.all2one_collect(0, value)
        vector = self.one2all_broadcast(0, vector)
        self.log("process %i: END all2all_broadcast(%s)\n" %
                 (self.rank, repr(value)))
        return vector
\end{lstlisting}

We have implemented the all-to-all broadcast using a trick. We send collected all values to node with rank 0 (via a function collect), and then we did a one-to-all broadcast of the entire list from node 0. In general, the implementation depends on the topology of the available network.

Here is an example of an application of broadcasting:

\begin{lstlisting}
from psim import * 

p = 10

comm = PSim(p, SWITCH)
message = "Hello World" if comm.rank == 0 else None
message = comm.one2all_broadcast(0, message)
print(message)
\end{lstlisting}

Notice how before the broadcast, only the process with rank 0 has knowledge of the message. After broadcast, all nodes are aware of it. Also notice that {\ft one2all\_broadcast} is a global communication function, and all processes must call it. Its first argument is the rank of the broadcasting process (0), while the second argument is the message to be broadcasted (only the value from node 0 is actually used).

\goodbreak\subsection{Scatter and collect}\index{scatter}\index{collect}

The all-to-one collect pattern works as follows. Every process sends a value to process {\ft destination}, which receives the values in a list ordered according to the rank of the senders:

%%% META:FILE:psim.py
\begin{lstlisting}[caption={in file: {\ft psim.py}}]

    def one2all_scatter(self, source, data):
        self.log(
            "process %i: BEGIN all2one_scatter(%i, %s)\n"
            % (self.rank, source, repr(data))
        )
        if self.rank == source:
            h, remainder = divmod(len(data), self.nprocs)
            if remainder:
                h += 1
            for i in range(self.nprocs):
                self._send(i, data[i * h : i * h + h])
        vector = self._recv(source)
        self.log(
            "process %i: END all2one_scatter(%i, %s)\n"
            % (self.rank, source, repr(data))
        )
        return vector

    def all2one_collect(self, destination, data):
        self.log(
            "process %i: BEGIN all2one_collect(%i, %s)\n"
            % (self.rank, destination, repr(data))
        )
        self._send(destination, data)
        if self.rank == destination:
            vector = [self._recv(i) for i in range(self.nprocs)]
        else:
            vector = []
        self.log(
            "process %i: END all2one_collect(%i, %s)\n"
            % (self.rank, destination, repr(data))
        )
        return vector
\end{lstlisting}

Here is a revised version of the previous scalar product example using scatter:

%%% META:FILE:psim_scalar2.py
\begin{lstlisting}[caption={in file: {\ft psim\_scalar2.py}}]
import random
from psim import PSim

def scalar_product_test2(n, p):
    comm = PSim(p)
    a = b = None
    if comm.rank == 0:
        a = [random.random() for i in range(n)]
        b = [random.random() for i in range(n)]
    a = comm.one2all_scatter(0, a)
    b = comm.one2all_scatter(0, b)

    scalar = sum(a[i] * b[i] for i in range(len(a)))

    scalar = comm.all2one_reduce(0, scalar)
    if comm.rank == 0:
        print(scalar)

scalar_product_test2(10, 2)
\end{lstlisting}

\goodbreak\subsection{Reduce}\index{reduce}

The all-to-one reduce pattern is very similar to the collect, except that the {\ft destination} does not receive the entire list of values but some aggregated information about the values. The aggregation must be performed using a commutative binary function $f(x, y)=f(y, x)$. This guarantees that the reduction from the values go down in any order and thus are optimized for different network topologies.

The all-to-all reduce is similar to reduce, but every process will get the result of the reduction, not just one {\ft destination} node. This may be achieved by an all-to-one reduce followed by a one-to-all broadcast:

%%% META:FILE:psim.py
\begin{lstlisting}[caption={in file: {\ft psim.py}}]

    def all2one_reduce(self, destination, value, op=lambda a, b: a + b):
        self.log("process %i: BEGIN all2one_reduce(%s)\n" %
                 (self.rank, repr(value)))
        self._send(destination, value)
        if self.rank == destination:
            result = functools.reduce(
                op, [self._recv(i) for i in range(self.nprocs)])
        else:
            result = None
        self.log("process %i: END all2one_reduce(%s)\n" %
                 (self.rank, repr(value)))
        return result

    def all2all_reduce(self, value, op=lambda a, b: a + b):
        self.log("process %i: BEGIN all2all_reduce(%s)\n" %
                 (self.rank, repr(value)))
        result = self.all2one_reduce(0, value, op)
        result = self.one2all_broadcast(0, result)
        self.log("process %i: END all2all_reduce(%s)\n" %
                 (self.rank, repr(value)))
        return result
\end{lstlisting}

And here are some examples of a reduce operation that can be passed to the {\ft op} argument of the {\ft all2one\_reduce} and {\ft all2all\_reduce} methods:

%%% META:FILE:psim.py
\begin{lstlisting}[caption={in file: {\ft psim.py}}]
    @staticmethod
    def sum(x, y):
        return x + y

    @staticmethod
    def mul(x, y):
        return x * y

    @staticmethod
    def max(x, y):
        return max(x, y)

    @staticmethod
    def min(x, y):
        return min(x, y)
\end{lstlisting}

Graph algorithms can also be parallelized, for example, the Prim algorithm. One way to do it is to represent the graph using an adjacency matrix where term $i, j$ corresponds to the link between vertex $i$ and vertex $j$. The term can be {\ft None} if the link does not exist. Any graph algorithm, in some order, loops over the vertices and over the neighbors. This step can be parallelized by assigning different columns of the adjacency matrix to different computing processes. Each process only loops over some of the neighbors of the vertex being processed. Here is an example of the Prim algorithm:

%%% META:FILE:psim_prim.py
\begin{lstlisting}[caption={in file: {\ft psim\_prim.py}}]
from psim import PSim
import random

def random_adjacency_matrix(n):
    A = []
    for r in range(n):
        A.append([0] * n)
    for r in range(n):
        for c in range(0, r):
            A[r][c] = A[c][r] = random.randint(1, 100)
    return A

class Vertex(object):
    def __init__(self, path=[0, 1, 2]):
        self.path = path

def weight(path=[0, 1, 2], adjacency=None):
    return sum(adjacency[path[i-1]][path[i]] for i in range(1, len(path)))

def bb(adjacency, p=1):
    n = len(adjacency)
    comm = PSim(p)
    Q = []
    path = [0]
    Q.append(Vertex(path))
    bound = float("inf')
    optimal = None
    local_vertices = comm.one2all_scatter(0, range(n))
    while True:
        if comm.rank == 0:
            vertex = Q.pop() if Q else None
        else:
            vertex = None
        vertex = comm.one2all_broadcast(0, vertex)
        if vertex is None:
            break
        P = []
        for k in local_vertices:
            if not k in vertex.path:
                new_path = vertex.path+[k]
                new_path_length = weight(new_path, adjacency)
                if new_path_length<bound:
                    if len(new_path) == n:
                        new_path.append(new_path[0])
                        new_path_length = weight(new_path, adjacency)
                        if new_path_length<bound:
                            bound = new_path_length  # bcast
                            optimal = new_path       # bcast
                    else:
                        new_vertex = Vertex(new_path)
                        P.append(new_vertex)  # fix this
                print(new_path, new_path_length)
        x = (bound, optimal)
        x = comm.all2all_reduce(x, lambda a, b: min(a, b))
        (bound, optimal) = x

        P = comm.all2one_collect(0, P)
        if comm.rank == 0:
            for item in P:
                Q+=item
    return optimal, bound


m = random_adjacency_matrix(5)
print(bb(m, p=2))
\end{lstlisting}

\goodbreak\subsection{Barrier}\index{barrier}

Another global communication pattern is the barrier. It forces all processes when they reach the barrier to stop and wait until all the other processes have reached the barrier. Think of runners gathering at the  starting line  of a race; when  all the runners are there, the race can start.

Here we implement it using a simple all-to-all broadcast:

%%% META:FILE:psim.py
\begin{lstlisting}[caption={in file: {\ft psim.py}}]
    def barrier(self):
        self.log("process %i: BEGIN barrier()\n" % (self.rank))
        self.all2all_broadcast(0)
        self.log("process %i: END barrier()\n" % (self.rank))
        return
\end{lstlisting}

The use of {\ft barrier} is usually a symptom of bad code because it forces parallel processes to wait for other processes without data actually being transferred.

\goodbreak\subsection{Global running times}

In the following table, we compute the order of growth or typical running times for the most common network topologies for typical communication algorithms:

\begin{tabular}{|l|lll|} \hline
Network & Send/Recv & One2All Bcast & Scatter \\ \hline
completely connected & $1$ & $1$ & $1$ \\
switch  & $2$ & $\log p$ & $2p$ \\
1D mesh  & $p-1$ & $p-1$ & $p^2$ \\
2D mesh  & $2(p^{\frac12}-1)$ & $\sqrt{p}$ & $p^2$ \\
3D mesh  & $3(p^{\frac13}-1)$ & $p^{1/3}$ & $p^2$ \\
1D torus  & $p/2$ & $p/2$ & $p^2$ \\
2D torus  & $2p^{\frac12}$ & $\sqrt{p}/2$ & $p^2$ \\
3D torus  & $3/2 p^{\frac13}$ & $p^{1/3}/2$ & $p^2$ \\
hypercube  & $\log p$ & $\log_2 p$ & $p$ \\
tree  & $\log p$ & $\log p$ & $p$
\\ \hline
\end{tabular}

It is obvious that the completely connected is the fastest network but also the most expensive to build. The tree is a cheap compromise. The switch tends to be faster for arbitrary point-to-point communication, but the switch comes to a premium. Multidimensional meshes and toruses become cost-effective when solving problems that are naturally defined on a grid because they only require next neighbor interaction.

\goodbreak\section{mpi4py}\index{mpi4py}

The Psim emulator does not provide any actual speedup unless you have multiple cores or processors to execute the forked processes. A better approach would be to use {\ft mpi4py}~\cite{mpi4py} because it allows running different processes on different machines on a network. {\ft mpi4py} is a Python interface to the message passing interface (MPI). MPI is a standard protocol and API for interprocess communications. Its API are equivalent one by one to those of {\ft PSim}, except that they have different names and different signatures.

Here is an example of using mpi4py:

\begin{lstlisting}
from mpi4py import MPI

comm = MPI.COMM_WORLD
rank = comm.Get_rank()

if rank == 0:
   message = "Hello World"
   comm.send(message, dest=1, tag=11)
elif rank == 1:
   message = comm.recv(source=0, tag=11)
   print(message)
\end{lstlisting}

The {\ft comm} object of class {\ft MPI.COMM\_WORLD} plays a similar role as the {\ft PSim} object of the previous section. The MPI {\ft send} and {\ft recv} functions are very similar to the {\ft PSim} equivalent ones, except that they require details about the type of the data being transferred and a communication tag. The tag allows node A to send multiple messages to B and allows B to receive them out of order. PSim does not allow tags.

\goodbreak\section{Master-Worker and Map-Reduce}\index{map-reduce}\index{master}\index{worker}\index{asynchat}\index{asyncore}

Map-Reduce~\cite{mapreduce} is a framework for processing highly distributable problems across huge data sets using a large number of computers (nodes). The group of computers is collectively referred to as a cluster (if all nodes use the same hardware) or a grid (if the nodes use different hardware). It comprises two steps:

``Map'' (implemented here in a function {\ft mapfn}): The master node takes the input data, partitions it into smaller subproblems, and distributes individual pieces of the data to worker nodes. A worker node may do this again in turn, leading to a multilevel tree structure. The worker node processes the smaller problem, computes a result, and passes that result back to its master node.

``Reduce'' (implemented here in a function {\ft reducefn}): The master node collects the partial results from all the subproblems and combines them in some way to compute the answer to the problem it needs.

Map-Reduce allows for distributed processing of the map and reduction operations. Provided each mapping operation is independent of the others, all maps can be performed in parallel---though in practice, it is limited by the number of independent data sources and/or the number of CPUs near each source. Similarly, a set of ``reducers'' can perform the reduction phase, provided all outputs of the map operation that share the same key are presented to the same reducer at the same time.

While this process can often appear inefficient compared to algorithms that are more sequential, Map-Reduce can be applied to significantly larger data sets than ``commodity'' servers can handle---a large server farm can use Map-Reduce to sort a petabyte of data in only a few hours, which would require much longer in a monolithic or single process system.

Parallelism also offers some possibility of recovering from partial failure of servers or storage during the operation: if one mapper or reducer fails, the work can be rescheduled---assuming the input data are still available.

Map-Reduce comprises of two main functions: {\ft mapfn} and {\ft reducefn}. {\ft mapfn} takes a (key, value) pair of data with a type in one data domain and returns a list of (key, value) pairs in a different domain:
\begin{equation}
\textrm{mapfn}(k1, v1) \rightarrow (k2, v2)
\end{equation}
The {\ft mapfn} function is applied in parallel to every item in the input data set. This produces a list of (k2, v2) pairs for each call. After that, the Map-Reduce framework collects all pairs with the same key from all lists and groups them together, thus creating one group for each one of the different generated keys.
The {\ft reducefn} function is then applied in parallel to each group, which in turn produces a collection of values in the same domain:
\begin{equation}
\textrm{reducefn}(k2, [\textrm{list of }v2]) \rightarrow (k2, v3)
\end{equation}
The values returned by {\ft reducefn} are then collected into a single list. Each call to {\ft reducefn} can produce one, none, or multiple partial results.
Thus the Map-Reduce framework transforms a list of (key, value) pairs into a list of values.
It is necessary but not sufficient to have implementations of the map and reduce abstractions to implement Map-Reduce. Distributed implementations of Map-Reduce require a means of connecting the processes performing the {\ft mapfn} and {\ft reducefn} phases.

Here is a nonparallel implementation that explains the data workflow better:

%%% META:FILE:mapreduce.py
\begin{lstlisting}
def mapreduce(mapper, reducer, data):
    """
    >>> def mapfn(x): return x%2, 1
    >>> def reducefn(key, values): return len(values)
    >>> data = list(range(100))
    >>> mapreduce(mapfn, reducefn, data)
    {0: 50, 1: 50}
    """
    partials = {}
    results = {}
    for item in data:
        key, value = mapper(item)
        if not key in partials:
            partials[key]=[value]
        else:
            partials[key].append(value)
    for key, values in partials.items():
        results[key] = reducer(key, values)
    return results
\end{lstlisting}

And here is an example we can use to find how many random DNA strings contain the subsequence ``ACTA'':

%%% META:FILE:mapreduce.py
\begin{lstlisting}
>>> from random import choice
>>> strings = [''.join(choice("ATGC") for i in range(10))
...            for j in range(100)]
>>> def mapfn(string): return ("ACCA" in string, 1)
>>> def reducefn(check, values): return len(values)
>>> print(mapreduce(mapfn, reducefn, strings))
{False: ..., True: ...}
\end{lstlisting}

The important thing about the preceding code is that there are two loops in Map-Reduce. Each loop consists of executing tasks (map tasks and reduce tasks) which are independent from each other (all the maps are independent, all the reduce are independent, but the reduce depend on the maps). Because they are independent, they can be executed in parallel and by different processes.

A simple and small library that implements the map-reduce algorithm in Python is {\ft mincemeat}~\cite{mincemeat}. The workers connect and authenticate to the server using a password and request tasks to executed. The server accepts connections and assigns the map and reduce tasks to the workers.

The communication is performed using asynchronous sockets, which means neither workers nor the master is ever in a wait state. The code is event based, and communication only happens when a socket connecting the master to a worker is ready for a write (task assignment) or a read (task completed).

The code is also failsafe because if a worker closes the connection prematurely, the task is reassigned to another worker.

Function {\ft mincemeat} uses the python libraries {\ft asyncore} and {\ft asynchat} to implement the communication patterns, for which we refer to the Python documentation.

Here is an example of a {\ft mincemeat} program:

%%% META:FILE:mincemeat_example.py
\begin{lstlisting}
import mincemeat
from random import choice

strings = [''.join(choice("ATGC") for i in range(10)) for j in range(100)]
def mapfn(k1, string): yield ("ACCA" in string, 1)
def reducefn(k2, values): return len(values)

s = mincemeat.Server()
s.mapfn = mapfn
s.reducefn = reducefn
s.datasource = dict(enumerate(strings))
results = s.run_server(password="changeme")
print(results)
\end{lstlisting}

Notice that in {\ft mincemeat}, the data source is a list of key value dictionaries where the values are the ones to be processed. The key is also passed to the {\ft mapfn} function as first argument. Moreover, the {\ft mapfn} function can return more than one value using {\ft yield}. This syntactical notation makes {\ft minemeat} more flexible.

Execute this script on the server:
\begin{lstlisting}
> python mincemeat_example.py
\end{lstlisting}
Run mincemeat.py as a worker on a client:
\begin{lstlisting}
> python mincemeat.py -p changeme [server address]
\end{lstlisting}
You can run more than one worker, although for this example the server will terminate almost immediately.

Function {\ft mincemeat} works fine for many applications, but sometimes one wishes for a more powerful tool that provides faster communications, support for arbitrary languages, and better scalability tools and monitoring tools. An example in Python is {\ft disco}. A standard tool, written in Java but supporting Python, is {\bf Hadoop}.

\goodbreak\section{pyOpenCL}\index{CUDA}\index{OpenCL}

Nvidia should be credited for bringing GPU computing to the mass market. They have developed the CUDA~\cite{cuda} framework for GPU programming. CUDA programs consist of two parts: a host and a kernel. The host deploys the kernel on the available GPU core, and multiple copies of the kernel run in parallel.

Nvidia, AMD, Intel, and ARM have created the Kronos Group, and together they have developed the Open Common Language framework (OpenCL~\cite{opencl}), which borrows many ideas from CUDA and promises more portability. OpenCL supports
Intel/AMD CPUs, Nvidia/ATI GPU, ARM chips, and the LLVM virtual machine.

OpenCL is a C99 dialect. In OpenCL, like in CUDA, there is a host program and a kernel. Multiple copies of the kernel are queued and run in parallel on available devices. Kernels running on the same device have access to a shared memory area as well as local memory areas.

A typical OpenCL program has the following structure:
\begin{lstlisting}
find available devices (GPUs, CPUs)
copy data from host to device
run N copies of this kernel code on the device
copy data from device to host
\end{lstlisting}

Usually the kernel is written in C99, while the host is written in C++. It is also possible to write the host code in other languages, including Python. Here we will use the {\ft pyOpenCL}~\cite{pyopencl} module for programming the host using Python. This produces no significative loss of performance compared to C++ because the actual computation is performed by kernel, not by the host. It is also possible to write the kernels using Python using a library called Clyther~\cite{clyther} but this is not discussed here.

\index{class!Device}

First of all we implement a class {\ft Device} class in terms of {\ft pyOpenCL} API which will make our later code more readable.

%%% META:FILE:device.py
\begin{lstlisting}[caption={in file: {\ft device.py}}]
import numpy
import pyopencl as pcl

class Device(object):
    flags = pcl.mem_flags
    def __init__(self):
        self.ctx = pcl.create_some_context()
        self.queue = pcl.CommandQueue(self.ctx)
    def buffer(self, source=None, size=0, mode=pcl.mem_flags.READ_WRITE):
        if source is not None: mode = mode|pcl.mem_flags.COPY_HOST_PTR
        buffer = pcl.Buffer(self.ctx, mode, size=size, hostbuf=source)
        return buffer
    def retrieve(self, buffer, shape=None, dtype=numpy.float32):
        output = numpy.zeros(shape or buffer.size//4, dtype=dtype)
        pcl.enqueue_copy(self.queue, output, buffer)
        return output
    def compile(self, kernel):
        return pcl.Program(self.ctx, kernel).build()
\end{lstlisting}

Here {\ft self.ctx} is the device context, {\ft self.queue} is the device queue. The functions {\ft buffer}, {\ft retrieve}, and {\ft compile} map onto the corresponding pyOpenCL functions {\ft Buffer}, {\ft enqueue\_copy}, and {\ft Program} but use a simpler syntax. For more details, we refer to the official {\ft pyOpenCL} documentation.

\subsection{A first example with PyOpenCL}

{\ft pyOpenCL} uses {\ft numpy} multidimensional arrays to store data. For example, here is a {\ft numpy} example that performs the scalar product between two vectors, $u$ and $v$:

\begin{lstlisting}
import numpy as npy

size = 10000
u = npy.random.rand(size).astype(npy.float32)
v = npy.random.rand(size).astype(npy.float32)
w = npy.zeros(n, dtype=numpy.float32)

for i in range(0, n):
    w[i] = u[i] + v[i];

assert npy.linalg.norm(w - (u + v)) == 0
\end{lstlisting}

The program works as follows:
\begin{itemize}
\item It creates a two {\ft numpy} arrays $u$ and $v$ of given size and filled with random numbers.
\item It creates another {\ft numpy} array $w$ of the same size filled with zeros.
\item It loops over all indices of $w$ and adds, term by term, $u$ and $v$ storing the result into $w$.
\item It checks the result using the {\ft numpy} {\ft linalg} submodule.
\end{itemize}

Our goal is to parallelize the part of the computation performed in the loop. Notice that our parallelization will not make the code faster because this is a linear algorithm, and algorithms linear in the input are never faster when parallelized because the communication has the same order of growth as the algorithm itself:

%%% META:FILE:opencl_example1.py
\begin{lstlisting}[caption={in file: {\ft opencl\_example1.py}}]
import numpy as npy
from device import Device

n = 100000
u = npy.random.rand(n).astype(npy.float32)
v = npy.random.rand(n).astype(npy.float32)

device = Device()
u_buffer = device.buffer(source=u)
v_buffer = device.buffer(source=v)
w_buffer = device.buffer(size=v.nbytes)

kernels = device.compile(
    """
    __kernel void sum(__global const float * u,
                      __global const float * v,
                      __global float * w) {
      int i = get_global_id(0);
      w[i] = u[i] + v[i];
    }
    """
)

kernels.sum(device.queue, [n], None, u_buffer, v_buffer, w_buffer)
w = device.retrieve(w_buffer)

assert npy.linalg.norm(w - (u + v)) == 0
\end{lstlisting}

This program performs the following steps in addition to the original non-OpenCL code:
it declares a {\ft device} object; it declares a buffer for each of the vectors $u$, $v$, and $w$; it declares and compiles the kernel; it runs the kernel; it retrieves the result.

The {\ft device} object encapsulate the kernel(s) and a queue for kernel submission.

The line:
\begin{lstlisting}
kernels.sum(..., [n], ...)
\end{lstlisting}

submits to the queue {\ft n} instances of the {\ft sum} kernel. Each kernel instance can retrieve its own ID using the function {\ft get\_global\_id(0)}. Notice that a kernel must be declared with the {\ft \_\_kernel} prefix. Arguments that are to be shared by all kernels must be {\ft \_\_global}.

\subsection{Laplace solver}

In this section we implement a two-dimensional Laplace solver. A three-dimensional generalization is straightforward. In particular, we want to solve the following differential equation known as a Laplace equation:

\begin{equation}
(\partial_x^2 + \partial_y^2) u(x, y) = q(x, y)
\label{nabla}
\end{equation}
Here $q$ is the input and $u$ is the output.

This equation originates, for example, in electrodynamics. In this case, $q$ is the distribution of electric charge in space and $u$ is the electrostatic potential.

As we did in chapter 3, we proceed by discretizing the derivatives:

\begin{eqnarray}
\partial_x^2 u(x, y) &=& (u(x-h, y)-2 u(x, y)+u(x+h, y))/h^2 \\
\partial_y^2 u(x, y) &=& (u(x, y-h)-2 u(x, y)+u(x, y+h))/h^2
\end{eqnarray}
Substitute them into eq.~\ref{nabla} and solve the equation in $u(x, y)$. We obtain
\begin{equation}
u(x, y) = 1/4 (u(x-h, y)+u(x+h, y)+u(x, y-h)+u(x, y+h)-h^2 q(x, y))
\label{nabla2}
\end{equation}

We can therefore solve eq.~\ref{nabla} by iterating eq.~\ref{nabla2} until convergence. The initial value of $u$ will not affect the solution, but the closer we can pick it to the actual solution, the faster the convergence.

The procedure we utilized here for transforming a differential equation into an iterative procedure is a general one and applies to other differential equations as well. The iteration proceeds very much as the fixed point solver also examined in chapter 3.

Here is an implementation using {\ft ocl}:

%%% META:FILE:opencl_laplace.py
\begin{lstlisting}[caption={in file: {\ft opencl\_laplace.py}}]
from random import randint, choice
import numpy
from canvas import Canvas
from device import Device

n = 300
q = numpy.zeros((n, n), dtype=numpy.float32)
u = numpy.zeros((n, n), dtype=numpy.float32)
w = numpy.zeros((n, n), dtype=numpy.float32)

for k in range(n):
    q[randint(1, n - 1), randint(1, n - 1)] = choice((-1, +1))

device = Device()
q_buffer = device.buffer(source=q, mode=device.flags.READ_ONLY)
u_buffer = device.buffer(source=u)
w_buffer = device.buffer(source=w)


kernels = device.compile(
    """
       __kernel void solve(__global float * w, 
                           __global const float * u, 
                           __global const float * q) {
          int x = get_global_id(0);
          int y = get_global_id(1);
          int xy = y * WIDTH + x, up, down, left, right;
          if(y!=0 && y!=WIDTH-1 && x!=0 && x!=WIDTH-1) {
             up=xy+WIDTH; down=xy-WIDTH; left=xy-1; right=xy+1;
             w[xy] = 1.0/4.0 * (u[up]+u[down]+u[left]+u[right] - q[xy]);
          }
       }
    """.replace(
        "WIDTH", str(n)
    )
)

for k in range(1000):
    kernels.solve(device.queue, [n, n], None, w_buffer, u_buffer, q_buffer)
    (u_buffer, w_buffer) = (w_buffer, u_buffer)

u = device.retrieve(u_buffer, shape=(n, n))

Canvas().imshow(u).save(filename="plot.png")
\end{lstlisting}

\begin{figure}[ht]
\begin{center}
\centering\includegraphics[width=4in]{images/plot.png}
\end{center}
\caption{The image shows the output of the Laplace program and represents the two-dimensional electrostatic potential for a random charge distribution.\label{fig_u}}
\end{figure}

\chapter{Appendices}

\goodbreak\section{Appendix A: Math Review and Notation}

\goodbreak\subsection{Symbols}

\begin{equation}
\begin{tabular}{|l|l|}
\hline
$\infty $ & infinity \\ \hline
$\wedge $ & and \\ \hline
$\vee $ & or \\ \hline
$\cap $ & intersection \\ \hline
$\cup $ & union \\ \hline
$\in $ & element or In \\ \hline
$\forall $ & for each \\ \hline
$\exists $ & exists \\ \hline
$\Rightarrow $ & implies \\ \hline
: & such that \\ \hline
iff & if and only if \\ \hline
\end{tabular}
\end{equation}

\goodbreak\subsection{Set theory}

\subsubsection{Important sets}

\begin{equation}
\begin{tabular}{|l|l|}
\hline
${\bf 0}$ & empty set \\ \hline
${\Bbb N}$ & natural numbers \{0, 1, 2, 3, ...\} \\ \hline
${\Bbb N}^{+}$ & positive natural numbers \{1, 2, 3, ...\} \\ \hline
${\Bbb Z}$ & all integers \{..., -3, -2, -1, 0, 1, 2, 3, ...\} \\ \hline
${\Bbb R}$ & all real numbers \\ \hline
${\Bbb R}^{+}$ & positive real numbers (not including 0) \\ \hline
${\Bbb R}^{0}$ & positive numbers including 0 \\ \hline
\end{tabular}
\end{equation}

\subsubsection{Set operations}

${\cal A}$, ${\cal B}$ and ${\cal C}$ are some generic sets.

\begin{itemize}
\item  {\bf Intersection}
\begin{equation}
{\cal A}\cap {\cal B}\equiv \{x:x\in {\cal A}\text{ and }x\in
{\cal B}\}
\end{equation}

\item  {\bf Union}
\begin{equation}
{\cal A}\cup {\cal B}\equiv \{x:x\in {\cal A}\text{ or }x\in {\cal %
B}\}
\end{equation}

\item  {\bf Difference}
\begin{equation}
{\cal A}-{\cal B}\equiv \{x:x\in {\cal A}\text{ and }x\notin {\cal %
B}\}
\end{equation}
\end{itemize}

\subsubsection{Set laws}

\begin{itemize}
\item  Empty set laws
\begin{eqnarray}
{\cal A}\cup {\bf 0} &=&{\cal A} \\
{\cal A}\cap {\bf 0} &=&{\bf 0}
\end{eqnarray}

\item  Idempotency laws
\begin{eqnarray}
{\cal A}\cup {\cal A} &=&{\cal A} \\
{\cal A}\cap {\cal A} &=&{\cal A}
\end{eqnarray}

\item  Commutative laws
\begin{eqnarray}
{\cal A}\cup {\cal B} &=&{\cal B}\cup {\cal A} \\
{\cal A}\cap {\cal B} &=&{\cal B}\cap {\cal A}
\end{eqnarray}

\item  Associative laws
\begin{eqnarray}
{\cal A}\cup ({\cal B}\cup {\cal C}) &=&({\cal A}\cup {\cal B})\cup {\cal C}
\\
{\cal A}\cap ({\cal B\cap C}) &=&({\cal A\cap B})\cap {\cal C}
\end{eqnarray}

\item  Distributive laws
\begin{eqnarray}
{\cal A}\cap ({\cal B}\cup {\cal C}) &=&({\cal A}\cap {\cal B})\cup ({\cal A}%
\cap {\cal C}) \\
{\cal A}\cup ({\cal B}\cap {\cal C}) &=&({\cal A}\cup {\cal B})\cap ({\cal A}%
\cup {\cal C})
\end{eqnarray}

\item  Absorption laws
\begin{eqnarray}
{\cal A}\cap ({\cal A}\cup {\cal B}) &=&{\cal A} \\
{\cal A}\cup ({\cal A}\cap {\cal B}) &=&{\cal A}
\end{eqnarray}

\item  DeMorgan laws
\begin{eqnarray}
{\cal A}-({\cal B}\cup {\cal C}) &=&({\cal A}-{\cal B})\cap ({\cal A}-{\cal C%
}) \\
{\cal A}-({\cal B}\cap {\cal C}) &=&({\cal A}-{\cal B})\cup ({\cal A}-{\cal C%
})
\end{eqnarray}
\end{itemize}

\subsubsection{More set definitions}

\begin{itemize}
\item  ${\cal A}$ is a {\bf subset} of ${\cal B}$ iff $\forall x\in {\cal A}%
, x\in {\cal B}$

\item  ${\cal A}$ is a {\bf proper subset} of ${\cal B}$ iff $\forall x\in
{\cal A}, x\in {\cal B}$ and $\exists x\in {\cal B}, x\notin {\cal A}$

\item  $P=\{S_i, i=1, ..., N\}$ (a set of sets $S_i$) is a {\bf partition} of $%
{\cal A}$ iff $S_1\cup S_2\cup ...\cup S_N={\cal A}$ and $\forall
i, j, S_i\cap S_j={\bf 0}$

\item  The number of elements in a set ${\cal A}$ is called the {\bf %
cardinality} of set ${\cal A}.$

\item  cardinality(${\Bbb N}$)=countable infinite ($\infty $)

\item  cardinality(${\Bbb R}$)=uncountable infinite ($\infty $) !!!
\end{itemize}


\subsubsection{Relations}

\begin{itemize}
\item  A {\bf Cartesian Product} is defined as
\begin{equation}
{\cal A}\times {\cal B}=\{(a, b):a\in {\cal A}\text{ and }b\in {\cal B}\}
\end{equation}

\item  A {\bf binary relation} $R$ between two sets ${\cal A}$ and ${\cal B}$
if a subset of their Cartesian product.

\item  A binary relation is {\bf transitive} is $aRb$ and $bRc$ implies $aRc$

\item  A binary relation is {\bf symmetric} if $aRb$ implies $bRa$

\item  A binary relation is {\bf reflexive} if $aRa$ if always true for each
$a.$
\end{itemize}

Examples:

\begin{itemize}
\item
$a<b$ for $a\in {\cal A}$ and $b\in {\cal B}$ is a relation (transitive)
\item
$a>b$ for $a\in {\cal A}$ and $b\in {\cal B}$ is a relation (transitive)
\item
$a=b$ for $a\in {\cal A}$ and $b\in {\cal B}$ is a relation (transitive, 
symmetric and reflexive)
\item
$a\leq b$ for $a\in {\cal A}$ and $b\in {\cal B}$ is a relation (transitive, 
and reflexive)
\item
$a\geq b$ for $a\in {\cal A}$ and $b\in {\cal B}$ is a relation (transitive, 
and reflexive)
\item  A relation $R$ that is transitive, symmetric and reflexive is called
an {\bf equivalence relation} and is often indicated with the notation $a\sim b$.
\end{itemize}

An equivalence relation is the same as a partition.

\subsubsection{Functions}

\begin{itemize}
\item  A {\bf function} between two sets ${\cal A}$ and ${\cal B}$ is a
binary relation on ${\cal A}\times {\cal B}$ and is usually indicated with
the notation $f:{\cal A}\longmapsto {\cal B}$

\item  The set ${\cal A}$ is called {\bf domain} of the function.

\item  The set ${\cal B}$ is called {\bf codomain} of the function.

\item  A function {\bf maps} each element $x\in {\cal A}$ into an element $%
f(x)=y\in {\cal B}$

\item  The {\bf image} of a function $f:{\cal A}\longmapsto {\cal B}$ is the
set ${\cal B}^{\prime }=\{y\in {\cal B}:\exists x\in {\cal A}%
, f(x)=y\}\subseteq {\cal B}$

\item  If ${\cal B}^{\prime }$ is ${\cal B}$ then a function is said to be
{\bf surjective}.

\item  If for each $x$ and $x^{\prime }$ in ${\cal A}$ where $x\neq
x^{\prime }$ implies that $f(x)\neq f(x^{\prime })$ (e.g., if not two
different elements of ${\cal A}$ are mapped into different element in ${\cal B%
}$) the function is said to be a {\bf bijection}.

\item  A function $f:{\cal A}\longmapsto {\cal B}$ is {\bf invertible} if it
exists a function $g:$ ${\cal B}\longmapsto {\cal A}$ such that for each $%
x\in {\cal A}, g(f(x))=x$ and $y\in {\cal B}, f(g(y))=y$. The function $g$ is
indicated with $f^{-1}$.

\item  A function $f:{\cal A}\longmapsto {\cal B}$ is a surjection and a
bijection iff $f$ is an invertible function.
\end{itemize}

Examples:

\begin{itemize}
\item
$f(n)\equiv n\func{mod}2$ with domain ${\Bbb N}$ and codomain $%
{\Bbb N}$ is not a surjection nor a bijection.
\item
$f(n)\equiv n\func{mod}2$ with domain ${\Bbb N}$ and codomain $%
\{0, 1\}$ is a surjection but not a bijection
\item
$f(x)\equiv 2x$ with domain ${\Bbb N}$ and codomain ${\Bbb N}$ is
not a surjection but is a bijection (in fact it is not invertible on odd
numbers)
\item
$f(x)\equiv 2x$ with domain ${\Bbb R}$ and codomain ${\Bbb R}$ is
not a surjection and is a bijection (in fact it is invertible)
\item
\end{itemize}

\goodbreak\subsection{Logarithms}

If $x=a^y$ with $a>0$, then $y=\log _ax$ with domain $x\in (0, \infty )$ and
codomain $y=(-\infty , \infty )$. If the base $a$ is not indicated, the
natural log $a=e=\allowbreak 2.\, 7183...$ is assumed.

Properties of logarithms:
\begin{eqnarray}
\log _ax &=&\frac{\log x}{\log a} \\
\log xy &=&(\log x)+(\log y) \\
\log \frac xy &=&(\log x)-(\log y) \\
\log x^n &=&n\log x
\end{eqnarray}

\goodbreak\subsection{Finite sums}

\subsubsection{Definition}

\begin{equation}
\sum_{i=0}^{i<n}f(i)\equiv f(0)+f(1)+...+f(n-1)
\end{equation}

\subsubsection{Properties}

\begin{itemize}
\item  {\bf Linearity I}
\begin{eqnarray}
\sum_{i=0}^{i\leq n}f(i) &=&\sum_{i=0}^{i<n}f(i)+f(n) \\
\sum_{i=a}^{i\leq b}f(i) &=&\sum_{i=0}^{i\leq b}f(i)-\sum_{i=0}^{i<a}f(i)
\end{eqnarray}

\item  {\bf Linearity II}
\end{itemize}

\begin{equation}
\sum_{i=0}^{i<n}af(i)+bg(i)=a\left( \sum_{i=0}^{i<n}f(i)\right) +b\left(
\sum_{i=0}^{i<n}g(i)\right)
\end{equation}

Proof:
\begin{eqnarray}
\sum_{i=0}^{i<n}af(i)+bg(i) &=&\left( af(0)+bg(0)\right) +...+\left(
af(n-1)+bg(n-1)\right)  \nonumber \\
&=&af(0)+...+af(n-1)+bg(0)+...+bg(n-1)  \nonumber \\
&=&a\left( f(0)+...+f(n-1)\right) +b\left( g(0)+...+g(n-1)\right)  \nonumber
\\
&=&a\left( \sum_{i=0}^{i<n}f(i)\right) +b\left( \sum_{i=0}^{i<n}g(i)\right)
\end{eqnarray}

Examples:

\begin{eqnarray}
\sum_{i=0}^{i<n}c &=&cn\text{ for any constant }c \\
\sum_{i=0}^{i<n}i &=&\frac 12n(n-1) \\
\sum_{i=0}^{i<n}i^2 &=&\frac 16n(n-1)(2n-1) \\
\sum_{i=0}^{i<n}i^3 &=&\frac 14n^2(n-1)^2 \\
\sum_{i=0}^{i<n}x^i &=&\frac{x^n-1}{x-1}\text{ (geometric sum)} \\
\sum_{i=0}^{i<n}\frac 1{i(i+1)} &=&1-\frac 1n\text{ (telescopic sum)}
\end{eqnarray}


\goodbreak\subsection{Limits ($n\rightarrow \infty $)}

In these section we will only deal with limits ($n\rightarrow \infty $) of
positive functions.

\begin{equation}
\lim_{n\rightarrow \infty }\frac{f(n)}{g(n)}=?
\end{equation}

First compute limits of the numerator and denominator separately:
\begin{eqnarray}
\lim_{n\rightarrow \infty }f(n) &=&a \\
\lim_{n\rightarrow \infty }g(n) &=&b
\end{eqnarray}

\begin{itemize}
\item  If $a\in {\Bbb R}$ and $b\in {\Bbb R}^{+}\, $then
\begin{equation}
\lim_{n\rightarrow \infty }\frac{f(n)}{g(n)}=\frac ab
\end{equation}

\item  If $a\in {\Bbb R}$ and $b=\infty $ then
\begin{equation}
\lim_{x\rightarrow \infty }\frac{f(x)}{g(x)}=0
\end{equation}

\item  If $(a\in {\Bbb R}^{+}$ and $b=0)$ or $(a={\Bbb \infty }$ and $b\in
{\Bbb R})$
\begin{equation}
\lim_{n\rightarrow \infty }\frac{f(n)}{g(n)}=\infty
\end{equation}

\item  If $(a=0$ and $b=0)$ or $(a={\Bbb \infty }$ and $b={\Bbb \infty })$
use de l"Hopital rule
\begin{equation}
\lim_{n\rightarrow \infty }\frac{f(n)}{g(n)}=\lim_{n\rightarrow \infty }%
\frac{f^{\prime }(n)}{g^{\prime }(n)}
\end{equation}
and start again!

\item  Else ... the limit does not exist (typically oscillating functions or
non-analytic functions).
\end{itemize}

For any $a\in {\Bbb R}$ or $a=\infty $%
\begin{equation}
\lim_{n\rightarrow \infty }\frac{f(n)}{g(n)}=a\Rightarrow \lim_{n\rightarrow
\infty }\frac{g(n)}{f(n)}=1/a
\end{equation}

\subsubsection{Table of derivatives}

\begin{equation}
\begin{tabular}{|l|l|}
\hline
$f(x)$ & $f^{\prime }(x)$ \\ \hline
$c$ & $0$ \\ \hline
$ax^n$ & $anx^{n-1}$ \\ \hline
$\log x$ & $\frac 1x$ \\ \hline
$e^x$ & $e^x$ \\ \hline
$a^x$ & $a^x\log a$ \\ \hline
$x^n\log x, n>0$ & $x^{n-1}(n\log x+1)$ \\ \hline
\end{tabular}
\end{equation}

\subsubsection{Practical rules to compute derivatives}

\begin{eqnarray}
\frac d{dx}\left( f(x)+g(x)\right) &=&f^{\prime }(x)+g^{\prime }(x) \\
\frac d{dx}\left( f(x)-g(x)\right) &=&f^{\prime }(x)-g^{\prime }(x) \\
\frac d{dx}\left( f(x)g(x)\right) &=&f^{\prime }(x)g(x)+f(x)g^{\prime }(x) \\
\frac d{dx}\left( \frac 1{f(x)}\right) &=&-\frac{f^{\prime }(x)}{f(x)^2} \\
\frac d{dx}\left( \frac{f(x)}{g(x)}\right) &=&\frac{f^{\prime }(x)}{g(x)}-%
\frac{f(x)g^{\prime }(x)}{g(x)^2} \\
\frac d{dx}f(g(x)) &=&f^{\prime }(g(x))g^{\prime }(x)
\end{eqnarray}

\end{fullwidth}
\backmatter

\printindex

\begin{thebibliography}{999}
\bibitem{python} \url{http://www.python.org}
\bibitem{numpy} Travis Oliphant, ``A Guide to NumPy''. Vol.1. USA: Trelgol Publishing (2006)
\bibitem{scipy} \url{http://www.scipy.org/}
\bibitem{pyopencl} Andreas Klckner {\it et al} ``Pycuda and pyopencl: A scripting-based approach to gpu run-time code generation.'' Parallel Computing 38.3 (2012) pp 157-174
\bibitem{ocl} \url{https://github.com/mdipierro/ocl}
\bibitem{guido} \url{http://www.network-theory.co.uk/docs/pytut/}
\bibitem{lutz} \url{http://oreilly.com/catalog/9780596158071}
\bibitem{pydocs} \url{http://www.python.org/doc/}
\bibitem{sqlite} \url{http://www.sqlite.org/}
\bibitem{matplotlib} \url{http://matplotlib.sourceforge.net/}
\bibitem{canvas} \url{https://github.com/mdipierro/canvas}
\bibitem{cython} Stefan Behnel {\it et al.}, ``Cython: The best of both worlds.'' Computing in Science \& Engineering 13.2 (2011) pp 31-39
\bibitem{mergesort} Donald Knuth, ``The Art of Computer Programming, Volume 3'', Addison-Wesley, (1997). ISBN 0-201-89685-0
\bibitem{mastertheorem} Thomas H. Cormen, Charles E. Leiserson, Ronald L. Rivest, and Clifford Stein, ``Introduction to Algorithms'', Second Edition. MIT Press and McGraw-Hill (2001). ISBN 0-262-03293-7
\bibitem{heapsort} J.W.J. Williams, J. W. J. ``Algorithm 232 - Heapsort'', Communications of the ACM 7 (6) (1964) pp 347348
\bibitem{bfs} E. F. Moore, ``The shortest path through a maze'', in Proceedings of the International Symposium on the Theory of Switching, Harvard University Press (1959) pp 285292
\bibitem{dfs} Charles Pierre Trmaux (18591882) cole Polytechnique of Paris (1876). re-published in the Annals academic, March 2011  ISSN: 0980-6032
\bibitem{kruskal} Joseph Kruskal, ``On the Shortest Spanning Subtree of a Graph and the Traveling Salesman Problem'', in Proceedings of the American Mathematical Society, Vol.7, N.1 (1956) pp 4850
\bibitem{prim} R. C. Prim, ``Shortest connection networks and some generalizations'' in Bell System Technical Journal, 36 (1957) pp 13891401
\bibitem{evolutionary} M. Farach-Colton {\it et al.}, ``Mathematical Support for Molecular Biology'', DIMACS: Series in Discrete Mathematics and Theoretical Computer Science (1999) Volume 47. ISBN:0-8218-0826-5
\bibitem{korber} B. Korber {\it et al.}, ``Timing the Ancestor of the HIV-1 Pandemic Strains'', Science (9 Jun 2000) Vol.288 no.5472.
\bibitem{dijkstra} E. W. Dijkstra, ``A note on two problems in connexion with graphs''. Numerische Mathematik 1, 269271 (1959). DOI:10.1007/BF01386390
\bibitem{shannon} C. E. Shannon, ``A Mathematical Theory of Communication''. Bell System Technical Journal 27 (1948) pp 379423
\bibitem{fano} R. M. Fano, ``The transmission of information'', Technical Report No. 65 MIT (1949)
\bibitem{huffman} D. A. Huffman, ``A Method for the Construction of Minimum-Redundancy Codes'', Proceedings of the I.R.E., (1952) pp 10981102
\bibitem{bergroth} Bergroth and H. Hakonen and T. Raita, ``A Survey of Longest Common Subsequence Algorithms''. SPIRE (IEEE Computer Society) 3948 (200). DOI:10.1109/SPIRE.2000.878178. ISBN:0-7695-0746-8
\bibitem{needleman} Saul Needleman and Christian Wunsch, ``A general method applicable to the search for similarities in the amino acid sequence of two proteins''. Journal of Molecular Biology 48 (3) (1970) pp 44353. DOI:10.1016/0022-2836(70)90057-4
\bibitem{knapsack} Tobias Dantzig, ``Numbers: The Language of Science'', 1930.
\bibitem{clustering} V. Estivill-Castro, ``Why so many clustering algorithms'', ACM SIGKDD Explorations Newsletter 4 (2002) pp 65. DOI:10.1145/568574.568575
\bibitem{neural} J. J. Hopfield, ``Neural networks and physical systems with emergent collective computational abilities'', Proc. Natl. Acad. Sci. USA Vol. 79 (1982) pp 2554-2558
\bibitem{barricelli} Nils Aall Barricelli, Nils Aall, ``Symbiogenetic evolution processes realized by artificial methods'', Methodos (1957) pp 143182
\bibitem{pnp} Michael Garey and David Johnson, ``Computers and Intractability: A Guide to the Theory of NP-Completeness'', San Francisco: W. H. Freeman and Company (1979). ISBN:0-7167-1045-5
\bibitem{hofstadter} Douglas R. Hofstadter, ``Gdel, Escher, Bach: An Eternal Golden Braid'', Basic Books 91979). ISBN:0-465-02656-7
\bibitem{mpt} Harry Markowitz, ``Foundations of portfolio theory'', The Journal of Finance 46.2 (2012) pp 469-477
\bibitem{chi2} P. E. Greenwood and M. S. Nikulin, ``A guide to chi-squared testing''. Wiley, New York (1996). ISBN:0-471-55779-X
\bibitem{andrew} Andrew Lo and Jasmina Hasanhodzic, ``The Evolution of Technical Analysis: Financial Prediction from Babylonian Tablets to Bloomberg Terminals'', Bloomberg Press (2010). ISBN:1576603490
\bibitem{minres} Y. Saad and M.H. Schultz, ``GMRES: A generalized minimal residual algorithm for solving nonsymmetric linear systems'', SIAM J. Sci. Stat. Comput. 7 (1986). DOI:10.1137/0907058
\bibitem{bicgstab} H. A. Van der Vorst, ``Bi-CGSTAB: A Fast and Smoothly Converging Variant of Bi-CG for the Solution of Nonsymmetric Linear Systems''. SIAM J. Sci. and Stat. Comput. 13 (2) (1992) pp 631644. DOI:10.1137/0913035
\bibitem{bisection} Richard Burden and Douglas Faires, ``2.1 The Bisection Algorithm'', Numerical Analysis (3rd ed.), PWS Publishers (1985). ISBN:0-87150-857-5
\bibitem{newton} Michiel Hazewinkel, ``Newton method'', Encyclopedia of Mathematics, Springer (2001). ISBN:978-1-55608-010-4
\bibitem{golden} Mordecai Avriel and Douglas Wilde, ``Optimality proof for the symmetric Fibonacci search technique'', Fibonacci Quarterly 4 (1966) pp 265269 MR:0208812
\bibitem{fourier} Loukas Grafakos, ``Classical and Modern Fourier Analysis'', Prentice-Hall (2004). ISBN:0-13-035399-X
\bibitem{largenumbers} S.D. Poisson, ``Probabilit des jugements en matire criminelle et en matire civile, prcdes des rgles gnrales du calcul des probabilitis'', Bachelier (1837)
\bibitem{central} A. W. Van der Vaart, ``Asymptotic statistics'', Cambridge University Press (1998). ISBN:978-0-521-49603-2
\bibitem{gambler} Jonah Lehrer, ``How We Decide'', Houghton Mifflin Harcourt (2009). ISBN:978-0-618-62011-1
\bibitem{lorenz} Edward N. Lorenz, ``Deterministic non-periodic flow''. Journal of the Atmospheric Sciences 20 (2) (1963) pp 130141. DOI:10.1175/1520-0469
\bibitem{determinism} Ian Hacking, ``19th-century Cracks in the Concept of Determinism'', Journal of the History of Ideas, 44 (3) (1983) pp 455-475 JSTOR:2709176
\bibitem{decay} F. Cannizzaro, G. Greco, S. Rizzo, E. Sinagra, ``Results of the measurements carried out in order to verify the validity of the poisson-exponential distribution in radioactive decay events''. The International Journal of Applied Radiation and Isotopes 29 (11) (1978) pp 649. DOI:10.1016/0020-708X(78)90101-1
\bibitem{bits} Yuval Perez, ``Iterating Von Neumann"s Procedure for Extracting Random Bits''. The Annals of Statistics 20 (1) (1992) pp 590597
\bibitem{lusher} Martin Luescher, ``A Portable High-Quality Random Number Generator for Lattice Field Theory Simulations'', Comput. Phys. Commun. 79 (1994) pp 100-110
\bibitem{randu} \url{http://demonstrations.wolfram.com/PoorStatisticalQualitiesForTheRANDURandomNumberGenerator}
\bibitem{fishman} G. S. Fishman, ``Grouping observations in digital simulation'', Management Science 24 (1978) pp 510-521
\bibitem{resampling} P. Good, ``Introduction to Statistics Through Resampling Methods and R/S-PLUS'', Wiley (2005). ISBN:0-471-71575-1
\bibitem{bootstrap} J. Shao and D. Tu, ``The Jackknife and Bootstrap'', Springer-Verlag (1995)
\bibitem{wilmott} Paul Wilmott, ``Paul Wilmott Introduces Quantitative Finance'', Wiley 92005). ISBN:978-0-470-31958-1
\bibitem{neutron} http://www.fas.org/sgp/othergov/doe/lanl/lib-www/la-pubs/00326407.pdf
\bibitem{stochastic} S. M. Ross, ``Stochastic Processes'', Wiley (1995). ISBN:978-0-471-12062-9
\bibitem{rwalk} Rvsz Pal, ``Random walk in random and non random environments'', World Scientific (1990)
\bibitem{markov} A.A. Markov. ``Extension of the limit theorems of probability theory to a sum of variables connected in a chain''. reprinted in Appendix B of R. Howard. ``Dynamic Probabilistic Systems'', Vol.1, John Wiley and Sons (1971)
\bibitem{wiener} W. Vervaat, ``A relation between Brownian bridge and Brownian excursion''. Ann. Prob. 7 (1) (1979) pp 143149 JSTOR:2242845
\bibitem{ito} Kiyoshi Ito, ``On stochastic differential equations'', Memoirs, American Mathematical Society 4, 151 (1951)
\bibitem{shreve} Steven Shreve, ``Stochastic Calculus for Finance II: Continuous Time Models'', Springer (2008) pp 114. ISBN:978-0-387-40101-0
\bibitem{folding} Sorin Istrail and Fumei Lam, ``Combinatorial Algorithms for Protein Folding in Lattice Models: A Survey of Mathematical Results'' (2009)
\bibitem{flynn} Michael Flynn, ``Some Computer Organizations and Their Effectiveness''. IEEE Trans. Comput. C21 (9) (1972) pp 948960. DOI:10.1109/TC.1972.5009071
\bibitem{admhal} Gene Amdahl, ``Validity of the Single Processor Approach to Achieving Large-Scale Computing Capabilities'', AFIPS Conference Proceedings (30) (1967) pp 483485
\bibitem{mpi4py} \url{http://mpi4py.scipy.org/}
\bibitem{mapreduce} Jeffrey Dean and Sanjay Ghemawat. 2008. MapReduce: simplified data processing on large clusters. Commun. ACM 51, 1 (January 2008), 107-113. DOI=10.1145/1327452.1327492 http://doi.acm.org/10.1145/1327452.1327492
\bibitem{mincemeat} \url{https://github.com/ziyuang/mincemeatpy}
\bibitem{cuda} Erik Lindholm {\it et al.}, ``NVIDIA Tesla: A unified graphics and computing architecture.'' Micro, IEEE 28.2 (2008) pp 39-55.
\bibitem{opencl} Aaftab Munshi, ``OpenCL: Parallel Computing on the GPU and CPU.'' SIGGRAPH, Tutorial (2008).
\bibitem{clyther} \url{http://srossross.github.com/Clyther/}
\end{thebibliography}
\end{document}
